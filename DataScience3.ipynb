{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYMUPZ82kEHjlCP94BlWhj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WandersonGustavo/Imersao_Alura/blob/main/DataScience3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2Z6Zjquhp3W"
      },
      "outputs": [],
      "source": [
        "#MACHINE LEARNING 11/01"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.naive_bayes import GaussianNB #ultilizar naive bayse\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from sklearn.metrics import confusion_matrix , accuracy_score\n",
        "from yellowbrick.classifier import ConfusionMatrix #forma da matrix em grafico"
      ],
      "metadata": {
        "id": "YL78Xl1Kh9Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credito=pd.read_csv('Credit.csv')\n",
        "credito.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMr2N5x_FGVK",
        "outputId": "41e751c7-38ed-4746-e916-cef834442eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "credito.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "MVspUE8zFfpp",
        "outputId": "6d65c5c1-86b1-4458-f27c-550f98bd8173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  checking_status  duration                    credit_history  \\\n",
              "0              <0         6  'critical/other existing credit'   \n",
              "1        0<=X<200        48                   'existing paid'   \n",
              "2   'no checking'        12  'critical/other existing credit'   \n",
              "3              <0        42                   'existing paid'   \n",
              "4              <0        24              'delayed previously'   \n",
              "\n",
              "               purpose  credit_amount      savings_status employment  \\\n",
              "0             radio/tv           1169  'no known savings'        >=7   \n",
              "1             radio/tv           5951                <100     1<=X<4   \n",
              "2            education           2096                <100     4<=X<7   \n",
              "3  furniture/equipment           7882                <100     4<=X<7   \n",
              "4            'new car'           4870                <100     1<=X<4   \n",
              "\n",
              "   installment_commitment       personal_status other_parties  ...  \\\n",
              "0                       4         'male single'          none  ...   \n",
              "1                       2  'female div/dep/mar'          none  ...   \n",
              "2                       2         'male single'          none  ...   \n",
              "3                       2         'male single'     guarantor  ...   \n",
              "4                       3         'male single'          none  ...   \n",
              "\n",
              "    property_magnitude age  other_payment_plans     housing existing_credits  \\\n",
              "0        'real estate'  67                 none         own                2   \n",
              "1        'real estate'  22                 none         own                1   \n",
              "2        'real estate'  49                 none         own                1   \n",
              "3     'life insurance'  45                 none  'for free'                1   \n",
              "4  'no known property'  53                 none  'for free'                2   \n",
              "\n",
              "                    job num_dependents  own_telephone foreign_worker class  \n",
              "0               skilled              1            yes            yes  good  \n",
              "1               skilled              1           none            yes   bad  \n",
              "2  'unskilled resident'              2           none            yes  good  \n",
              "3               skilled              2           none            yes  good  \n",
              "4               skilled              2           none            yes   bad  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8cfe3601-452c-4d32-8423-c63d5faa3010\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>checking_status</th>\n",
              "      <th>duration</th>\n",
              "      <th>credit_history</th>\n",
              "      <th>purpose</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>savings_status</th>\n",
              "      <th>employment</th>\n",
              "      <th>installment_commitment</th>\n",
              "      <th>personal_status</th>\n",
              "      <th>other_parties</th>\n",
              "      <th>...</th>\n",
              "      <th>property_magnitude</th>\n",
              "      <th>age</th>\n",
              "      <th>other_payment_plans</th>\n",
              "      <th>housing</th>\n",
              "      <th>existing_credits</th>\n",
              "      <th>job</th>\n",
              "      <th>num_dependents</th>\n",
              "      <th>own_telephone</th>\n",
              "      <th>foreign_worker</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>6</td>\n",
              "      <td>'critical/other existing credit'</td>\n",
              "      <td>radio/tv</td>\n",
              "      <td>1169</td>\n",
              "      <td>'no known savings'</td>\n",
              "      <td>&gt;=7</td>\n",
              "      <td>4</td>\n",
              "      <td>'male single'</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>'real estate'</td>\n",
              "      <td>67</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "      <td>2</td>\n",
              "      <td>skilled</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0&lt;=X&lt;200</td>\n",
              "      <td>48</td>\n",
              "      <td>'existing paid'</td>\n",
              "      <td>radio/tv</td>\n",
              "      <td>5951</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>1&lt;=X&lt;4</td>\n",
              "      <td>2</td>\n",
              "      <td>'female div/dep/mar'</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>'real estate'</td>\n",
              "      <td>22</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "      <td>1</td>\n",
              "      <td>skilled</td>\n",
              "      <td>1</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'no checking'</td>\n",
              "      <td>12</td>\n",
              "      <td>'critical/other existing credit'</td>\n",
              "      <td>education</td>\n",
              "      <td>2096</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>4&lt;=X&lt;7</td>\n",
              "      <td>2</td>\n",
              "      <td>'male single'</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>'real estate'</td>\n",
              "      <td>49</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "      <td>1</td>\n",
              "      <td>'unskilled resident'</td>\n",
              "      <td>2</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>42</td>\n",
              "      <td>'existing paid'</td>\n",
              "      <td>furniture/equipment</td>\n",
              "      <td>7882</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>4&lt;=X&lt;7</td>\n",
              "      <td>2</td>\n",
              "      <td>'male single'</td>\n",
              "      <td>guarantor</td>\n",
              "      <td>...</td>\n",
              "      <td>'life insurance'</td>\n",
              "      <td>45</td>\n",
              "      <td>none</td>\n",
              "      <td>'for free'</td>\n",
              "      <td>1</td>\n",
              "      <td>skilled</td>\n",
              "      <td>2</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>24</td>\n",
              "      <td>'delayed previously'</td>\n",
              "      <td>'new car'</td>\n",
              "      <td>4870</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>1&lt;=X&lt;4</td>\n",
              "      <td>3</td>\n",
              "      <td>'male single'</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>'no known property'</td>\n",
              "      <td>53</td>\n",
              "      <td>none</td>\n",
              "      <td>'for free'</td>\n",
              "      <td>2</td>\n",
              "      <td>skilled</td>\n",
              "      <td>2</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8cfe3601-452c-4d32-8423-c63d5faa3010')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8cfe3601-452c-4d32-8423-c63d5faa3010 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8cfe3601-452c-4d32-8423-c63d5faa3010');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores=credito.iloc[:,0:20].values\n",
        "classe=credito.iloc[:,20].values"
      ],
      "metadata": {
        "id": "6RNr2GIbFZ0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformação dos atributos categóricos em atributos numéricos, passando o índice de cada coluna categórica\n",
        "# Precisamos criar um objeto para cada atributo categórico, pois na sequência vamos executar o processo de encoding novamente para o registro de teste\n",
        "# Se forem utilizados objetos diferentes, o número atribuído a cada valor poderá ser diferente, o que deixará o teste inconsistente\n",
        "labelencoder1 = LabelEncoder()\n",
        "previsores[:,0] = labelencoder1.fit_transform(previsores[:,0])\n",
        "\n",
        "labelencoder2 = LabelEncoder()\n",
        "previsores[:,2] = labelencoder2.fit_transform(previsores[:,2])\n",
        "\n",
        "labelencoder3 = LabelEncoder()\n",
        "previsores[:, 3] = labelencoder3.fit_transform(previsores[:, 3])\n",
        "\n",
        "labelencoder4 = LabelEncoder()\n",
        "previsores[:, 5] = labelencoder4.fit_transform(previsores[:, 5])\n",
        "\n",
        "labelencoder5 = LabelEncoder()\n",
        "previsores[:, 6] = labelencoder5.fit_transform(previsores[:, 6])\n",
        "\n",
        "labelencoder6 = LabelEncoder()\n",
        "previsores[:, 8] = labelencoder6.fit_transform(previsores[:, 8])\n",
        "\n",
        "labelencoder7 = LabelEncoder()\n",
        "previsores[:, 9] = labelencoder7.fit_transform(previsores[:, 9])\n",
        "\n",
        "labelencoder8 = LabelEncoder()\n",
        "previsores[:, 11] = labelencoder8.fit_transform(previsores[:, 11])\n",
        "\n",
        "labelencoder9 = LabelEncoder()\n",
        "previsores[:, 13] = labelencoder9.fit_transform(previsores[:, 13])\n",
        "\n",
        "labelencoder10 = LabelEncoder()\n",
        "previsores[:, 14] = labelencoder10.fit_transform(previsores[:, 14])\n",
        "\n",
        "labelencoder11 = LabelEncoder()\n",
        "previsores[:, 16] = labelencoder11.fit_transform(previsores[:, 16])\n",
        "\n",
        "labelencoder12 = LabelEncoder()\n",
        "previsores[:, 18] = labelencoder12.fit_transform(previsores[:, 18])\n",
        "\n",
        "labelencoder13 = LabelEncoder()\n",
        "previsores[:, 19] = labelencoder13.fit_transform(previsores[:, 19])\n"
      ],
      "metadata": {
        "id": "xEg_CqWtXTI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão da base de dados entre treinamento e teste (30% para testar e 70% para treinar)\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(previsores,\n",
        "                                                                  classe,\n",
        "                                                                  test_size = 0.3,\n",
        "                                                                  random_state = 0)\n",
        "X_teste"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X4TgN8zXVmR",
        "outputId": "5f822546-79da-4d67-f8d6-1bf0b66b67f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 36, 3, ..., 1, 1, 1],\n",
              "       [0, 9, 3, ..., 2, 0, 0],\n",
              "       [0, 18, 3, ..., 1, 1, 1],\n",
              "       ...,\n",
              "       [0, 24, 1, ..., 1, 0, 1],\n",
              "       [1, 27, 4, ..., 1, 1, 1],\n",
              "       [1, 12, 3, ..., 1, 0, 1]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Criação e treinamento do modelo (geração da tabela de probabilidades)\n",
        "naive_bayes = GaussianNB()\n",
        "naive_bayes.fit(X_treinamento, y_treinamento)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGE1EwSQY_0g",
        "outputId": "6d3a47ce-b3ce-4083-d1bc-09ef3052dea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsões utilizando os registros de teste\n",
        "previsoes = naive_bayes.predict(X_teste)\n",
        "previsoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72tFLnLFZJei",
        "outputId": "c19d89ab-3a0a-4056-c3b0-b6b989e6aa8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['bad', 'good', 'good', 'good', 'bad', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'bad', 'bad', 'good', 'bad', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'bad', 'good', 'bad', 'good', 'good', 'bad',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'bad',\n",
              "       'good', 'good', 'good', 'bad', 'bad', 'bad', 'bad', 'bad', 'good',\n",
              "       'bad', 'good', 'good', 'good', 'good', 'bad', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'bad',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'bad', 'good', 'good', 'bad', 'bad', 'good', 'bad', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'bad', 'bad',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'bad', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'bad', 'good', 'good', 'bad',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'bad',\n",
              "       'bad', 'bad', 'good', 'bad', 'good', 'good', 'good', 'bad', 'bad',\n",
              "       'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'bad', 'bad', 'good', 'bad', 'bad',\n",
              "       'good', 'good', 'good', 'good', 'bad', 'good', 'bad', 'bad',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'good',\n",
              "       'bad', 'bad', 'good', 'bad', 'good', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'bad', 'good', 'good', 'good',\n",
              "       'bad', 'good', 'good', 'good', 'bad', 'bad', 'bad', 'good', 'bad',\n",
              "       'good', 'good', 'bad', 'good', 'bad', 'bad', 'good', 'good',\n",
              "       'good', 'good', 'bad', 'good', 'bad', 'bad', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'bad',\n",
              "       'bad', 'good', 'good', 'good', 'good', 'good', 'bad', 'good',\n",
              "       'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'good',\n",
              "       'good', 'good', 'bad', 'good', 'good', 'bad', 'good', 'good',\n",
              "       'good', 'bad', 'bad', 'bad', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'bad', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'bad', 'good'], dtype='<U4')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#geração da matriz de confusão e cálculo da taxa de acerto e erro\n",
        "confusao = confusion_matrix(y_teste, previsoes)\n",
        "confusao"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8AEvJdfZJ0K",
        "outputId": "744b75b7-70b6-43f9-90c0-10414a5721fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 41,  45],\n",
              "       [ 42, 172]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "taxa_acerto = accuracy_score(y_teste, previsoes)\n",
        "taxa_erro = 1 - taxa_acerto\n",
        "taxa_acerto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srsfxcgCZKRe",
        "outputId": "aa85f3ac-c63b-4a00-b2f0-d0d068b0e016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.71"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização da matriz de confusão\n",
        "# Warning interno da biblioteca yellowbrick, já esta na última versão (sem solução para o warning no momento)\n",
        "v = ConfusionMatrix(GaussianNB())\n",
        "v.fit(X_treinamento, y_treinamento)\n",
        "v.score(X_teste, y_teste)\n",
        "v.poof()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "qtEB09q4ZKux",
        "outputId": "176c1a53-9503-4c30-a02e-70b4b0fc7658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd5848f6880>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsão com novo registro, transformando os atributos categóricos em numéricos\n",
        "novo_credito = pd.read_csv('NovoCredit.csv')\n",
        "novo_credito.shape\n",
        "#novo_credito"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0C3WjWqaQfm",
        "outputId": "1ed8aa46-6a39-46ee-b3ac-1545faebcd74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''previsores=novo_credito.iloc[:,0:20].values #pegandos os previsores da classe\n",
        "classe=novo_credito.iloc[:,20].values #classe em registro diferente'''"
      ],
      "metadata": {
        "id": "3XBgiEUxf9Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos o mesmo objeto que foi criado antes, para manter o padrão dos dados\n",
        "# Chamamos somente o método \"transform\", pois a adaptação aos dados (fit) já foi feita anteriormente\n",
        "#novo_credito = novo_credito.iloc[:,0:20].values\n",
        "novo_credito[:,0] = labelEncoder1.transform(novo_credito[:,0])\n",
        "novo_credito[:, 2] = labelEncoder2.transform(novo_credito[:, 2])\n",
        "novo_credito[:, 3] = labelEncoder3.transform(novo_credito[:, 3])\n",
        "novo_credito[:, 5] = labelEncoder4.transform(novo_credito[:, 5])\n",
        "novo_credito[:, 6] = labelEncoder5.transform(novo_credito[:, 6])\n",
        "novo_credito[:, 8] = labelEncoder6.transform(novo_credito[:, 8])\n",
        "novo_credito[:, 9] = labelEncoder7.transform(novo_credito[:, 9])\n",
        "novo_credito[:, 11] = labelEncoder8.transform(novo_credito[:, 11])\n",
        "novo_credito[:, 13] = labelEncoder9.transform(novo_credito[:, 13])\n",
        "novo_credito[:, 14] = labelEncoder10.transform(novo_credito[:, 14])\n",
        "novo_credito[:, 16] = labelEncoder11.transform(novo_credito[:, 16])\n",
        "novo_credito[:, 18] = labelEncoder12.transform(novo_credito[:, 18])\n",
        "novo_credito[:, 19] = labelEncoder13.transform(novo_credito[:, 19])"
      ],
      "metadata": {
        "id": "SQOnlrbEZLAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes.predict(novo_credito)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qiQ3Zi4eetB",
        "outputId": "03945cd4-d1e0-4776-f5a9-d46a2f1fc7cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['good'], dtype='<U4')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#arvore de decisao 12/01"
      ],
      "metadata": {
        "id": "D3LdRU5vmuQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.naive_bayes import GaussianNB #ultilizar naive bayse\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from sklearn.metrics import confusion_matrix , accuracy_score\n",
        "from yellowbrick.classifier import ConfusionMatrix #forma da matrix em grafico\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "jDrnwaITm7Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credito=pd.read_csv('Credit.csv')\n",
        "credito.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YxlDSzIncb-",
        "outputId": "3b490a4b-9a52-41ae-a423-87701888a168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "credito.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "KbfNBH-bnn3N",
        "outputId": "a87db4cb-bee0-4233-ce0b-110b936e7c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  checking_status  duration                    credit_history  \\\n",
              "0              <0         6  'critical/other existing credit'   \n",
              "1        0<=X<200        48                   'existing paid'   \n",
              "2   'no checking'        12  'critical/other existing credit'   \n",
              "3              <0        42                   'existing paid'   \n",
              "4              <0        24              'delayed previously'   \n",
              "\n",
              "               purpose  credit_amount      savings_status employment  \\\n",
              "0             radio/tv           1169  'no known savings'        >=7   \n",
              "1             radio/tv           5951                <100     1<=X<4   \n",
              "2            education           2096                <100     4<=X<7   \n",
              "3  furniture/equipment           7882                <100     4<=X<7   \n",
              "4            'new car'           4870                <100     1<=X<4   \n",
              "\n",
              "   installment_commitment       personal_status other_parties  ...  \\\n",
              "0                       4         'male single'          none  ...   \n",
              "1                       2  'female div/dep/mar'          none  ...   \n",
              "2                       2         'male single'          none  ...   \n",
              "3                       2         'male single'     guarantor  ...   \n",
              "4                       3         'male single'          none  ...   \n",
              "\n",
              "    property_magnitude age  other_payment_plans     housing existing_credits  \\\n",
              "0        'real estate'  67                 none         own                2   \n",
              "1        'real estate'  22                 none         own                1   \n",
              "2        'real estate'  49                 none         own                1   \n",
              "3     'life insurance'  45                 none  'for free'                1   \n",
              "4  'no known property'  53                 none  'for free'                2   \n",
              "\n",
              "                    job num_dependents  own_telephone foreign_worker class  \n",
              "0               skilled              1            yes            yes  good  \n",
              "1               skilled              1           none            yes   bad  \n",
              "2  'unskilled resident'              2           none            yes  good  \n",
              "3               skilled              2           none            yes  good  \n",
              "4               skilled              2           none            yes   bad  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab328875-b3a0-4acd-a9d2-aad840d67adb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>checking_status</th>\n",
              "      <th>duration</th>\n",
              "      <th>credit_history</th>\n",
              "      <th>purpose</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>savings_status</th>\n",
              "      <th>employment</th>\n",
              "      <th>installment_commitment</th>\n",
              "      <th>personal_status</th>\n",
              "      <th>other_parties</th>\n",
              "      <th>...</th>\n",
              "      <th>property_magnitude</th>\n",
              "      <th>age</th>\n",
              "      <th>other_payment_plans</th>\n",
              "      <th>housing</th>\n",
              "      <th>existing_credits</th>\n",
              "      <th>job</th>\n",
              "      <th>num_dependents</th>\n",
              "      <th>own_telephone</th>\n",
              "      <th>foreign_worker</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>6</td>\n",
              "      <td>'critical/other existing credit'</td>\n",
              "      <td>radio/tv</td>\n",
              "      <td>1169</td>\n",
              "      <td>'no known savings'</td>\n",
              "      <td>&gt;=7</td>\n",
              "      <td>4</td>\n",
              "      <td>'male single'</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>'real estate'</td>\n",
              "      <td>67</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "      <td>2</td>\n",
              "      <td>skilled</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0&lt;=X&lt;200</td>\n",
              "      <td>48</td>\n",
              "      <td>'existing paid'</td>\n",
              "      <td>radio/tv</td>\n",
              "      <td>5951</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>1&lt;=X&lt;4</td>\n",
              "      <td>2</td>\n",
              "      <td>'female div/dep/mar'</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>'real estate'</td>\n",
              "      <td>22</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "      <td>1</td>\n",
              "      <td>skilled</td>\n",
              "      <td>1</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'no checking'</td>\n",
              "      <td>12</td>\n",
              "      <td>'critical/other existing credit'</td>\n",
              "      <td>education</td>\n",
              "      <td>2096</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>4&lt;=X&lt;7</td>\n",
              "      <td>2</td>\n",
              "      <td>'male single'</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>'real estate'</td>\n",
              "      <td>49</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "      <td>1</td>\n",
              "      <td>'unskilled resident'</td>\n",
              "      <td>2</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>42</td>\n",
              "      <td>'existing paid'</td>\n",
              "      <td>furniture/equipment</td>\n",
              "      <td>7882</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>4&lt;=X&lt;7</td>\n",
              "      <td>2</td>\n",
              "      <td>'male single'</td>\n",
              "      <td>guarantor</td>\n",
              "      <td>...</td>\n",
              "      <td>'life insurance'</td>\n",
              "      <td>45</td>\n",
              "      <td>none</td>\n",
              "      <td>'for free'</td>\n",
              "      <td>1</td>\n",
              "      <td>skilled</td>\n",
              "      <td>2</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>24</td>\n",
              "      <td>'delayed previously'</td>\n",
              "      <td>'new car'</td>\n",
              "      <td>4870</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>1&lt;=X&lt;4</td>\n",
              "      <td>3</td>\n",
              "      <td>'male single'</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>'no known property'</td>\n",
              "      <td>53</td>\n",
              "      <td>none</td>\n",
              "      <td>'for free'</td>\n",
              "      <td>2</td>\n",
              "      <td>skilled</td>\n",
              "      <td>2</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab328875-b3a0-4acd-a9d2-aad840d67adb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab328875-b3a0-4acd-a9d2-aad840d67adb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab328875-b3a0-4acd-a9d2-aad840d67adb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores=credito.iloc[:,0:20].values\n",
        "classe=credito.iloc[:,20].values"
      ],
      "metadata": {
        "id": "CWryh5PunrUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelencoder1 = LabelEncoder()\n",
        "previsores[:,0] = labelencoder1.fit_transform(previsores[:,0])\n",
        "\n",
        "labelencoder2 = LabelEncoder()\n",
        "previsores[:,2] = labelencoder2.fit_transform(previsores[:,2])\n",
        "\n",
        "labelencoder3 = LabelEncoder()\n",
        "previsores[:, 3] = labelencoder3.fit_transform(previsores[:, 3])\n",
        "\n",
        "labelencoder4 = LabelEncoder()\n",
        "previsores[:, 5] = labelencoder4.fit_transform(previsores[:, 5])\n",
        "\n",
        "labelencoder5 = LabelEncoder()\n",
        "previsores[:, 6] = labelencoder5.fit_transform(previsores[:, 6])\n",
        "\n",
        "labelencoder6 = LabelEncoder()\n",
        "previsores[:, 8] = labelencoder6.fit_transform(previsores[:, 8])\n",
        "\n",
        "labelencoder7 = LabelEncoder()\n",
        "previsores[:, 9] = labelencoder7.fit_transform(previsores[:, 9])\n",
        "\n",
        "labelencoder8 = LabelEncoder()\n",
        "previsores[:, 11] = labelencoder8.fit_transform(previsores[:, 11])\n",
        "\n",
        "labelencoder9 = LabelEncoder()\n",
        "previsores[:, 13] = labelencoder9.fit_transform(previsores[:, 13])\n",
        "\n",
        "labelencoder10 = LabelEncoder()\n",
        "previsores[:, 14] = labelencoder10.fit_transform(previsores[:, 14])\n",
        "\n",
        "labelencoder11 = LabelEncoder()\n",
        "previsores[:, 16] = labelencoder11.fit_transform(previsores[:, 16])\n",
        "\n",
        "labelencoder12 = LabelEncoder()\n",
        "previsores[:, 18] = labelencoder12.fit_transform(previsores[:, 18])\n",
        "\n",
        "labelencoder13 = LabelEncoder()\n",
        "previsores[:, 19] = labelencoder13.fit_transform(previsores[:, 19])"
      ],
      "metadata": {
        "id": "w_hX30D9oW4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão da base de dados entre treinamento e teste (30% para testar e 70% para treinar)\n",
        "X_treinamentoA, X_teste, y_treinamentoA, y_teste = train_test_split(previsores,\n",
        "                                                                  classe,\n",
        "                                                                  test_size = 0.3,\n",
        "                                                                  random_state = 0)\n",
        "X_teste"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivvFHxnnolks",
        "outputId": "99c45269-20c9-4f70-999b-bbe4c54edd51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 15, 0, ..., 2, 1, 1],\n",
              "       [2, 36, 3, ..., 1, 0, 1],\n",
              "       [0, 12, 4, ..., 1, 0, 1],\n",
              "       ...,\n",
              "       [1, 15, 1, ..., 1, 1, 1],\n",
              "       [1, 24, 3, ..., 1, 0, 1],\n",
              "       [1, 9, 1, ..., 2, 0, 1]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#modelo de treino com tree\n",
        "arv=DecisionTreeClassifier()\n",
        "arv.fit(X_treinamentoA,y_treinamentoA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jTIQqzgp9u-",
        "outputId": "3af78a62-7a89-4461-d92c-f7e43dca8393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#exportacao da arv em .dot pra vizualizar\n",
        "export_graphviz(arv, out_file='tree.dot')"
      ],
      "metadata": {
        "id": "wniIsufQqUIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#previsoes\n",
        "previsoe=arv.predict(X_teste)\n",
        "previsoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9va5oQzqlyr",
        "outputId": "5950d830-ee8d-42e0-b59f-0d9b1bc23271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['bad', 'good', 'good', 'good', 'bad', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'bad', 'bad', 'good', 'bad', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'bad', 'good', 'bad', 'good', 'good', 'bad',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'bad',\n",
              "       'good', 'good', 'good', 'bad', 'bad', 'bad', 'bad', 'bad', 'good',\n",
              "       'bad', 'good', 'good', 'good', 'good', 'bad', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'bad',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'bad', 'good', 'good', 'bad', 'bad', 'good', 'bad', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'bad', 'bad',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'bad', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'bad', 'good', 'good', 'bad',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'bad',\n",
              "       'bad', 'bad', 'good', 'bad', 'good', 'good', 'good', 'bad', 'bad',\n",
              "       'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'bad', 'bad', 'good', 'bad', 'bad',\n",
              "       'good', 'good', 'good', 'good', 'bad', 'good', 'bad', 'bad',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'good',\n",
              "       'bad', 'bad', 'good', 'bad', 'good', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'bad', 'good', 'good', 'good',\n",
              "       'bad', 'good', 'good', 'good', 'bad', 'bad', 'bad', 'good', 'bad',\n",
              "       'good', 'good', 'bad', 'good', 'bad', 'bad', 'good', 'good',\n",
              "       'good', 'good', 'bad', 'good', 'bad', 'bad', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'bad',\n",
              "       'bad', 'good', 'good', 'good', 'good', 'good', 'bad', 'good',\n",
              "       'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'good',\n",
              "       'good', 'good', 'bad', 'good', 'good', 'bad', 'good', 'good',\n",
              "       'good', 'bad', 'bad', 'bad', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'bad', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'bad', 'good'], dtype='<U4')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#taxa de acerto\n",
        "taxa_acerto2=accuracy_score(y_teste,previsoes)\n",
        "taxa_acerto2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwvlqM4EqymW",
        "outputId": "439efcb5-9d5a-4581-c8d7-6d12d03b9360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.71"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#erro\n",
        "taxa_erro=1- taxa_acerto2\n",
        "taxa_erro"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeOf5LABrCrK",
        "outputId": "b73bc827-9de0-4d77-dc06-7370b6914cc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29000000000000004"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.naive_bayes import GaussianNB #ultilizar naive bayse\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from sklearn.metrics import confusion_matrix , accuracy_score\n",
        "from yellowbrick.classifier import ConfusionMatrix #forma da matrix em grafico\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n"
      ],
      "metadata": {
        "id": "QFiZnTCfxeP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "credito=pd.read_csv('Credit.csv')\n",
        "credito.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgiF5W5Vx8FO",
        "outputId": "9bd3ac3f-325d-47eb-ad69-55a39ccc7661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pvs=credito.iloc[:,0:20].values\n",
        "classe=credito.iloc[:,20].values"
      ],
      "metadata": {
        "id": "HwYJo9tpyEGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelencoder1 = LabelEncoder()\n",
        "previsores[:,0] = labelencoder1.fit_transform(previsores[:,0])\n",
        "\n",
        "labelencoder2 = LabelEncoder()\n",
        "previsores[:,2] = labelencoder2.fit_transform(previsores[:,2])\n",
        "\n",
        "labelencoder3 = LabelEncoder()\n",
        "previsores[:, 3] = labelencoder3.fit_transform(previsores[:, 3])\n",
        "\n",
        "labelencoder4 = LabelEncoder()\n",
        "previsores[:, 5] = labelencoder4.fit_transform(previsores[:, 5])\n",
        "\n",
        "labelencoder5 = LabelEncoder()\n",
        "previsores[:, 6] = labelencoder5.fit_transform(previsores[:, 6])\n",
        "\n",
        "labelencoder6 = LabelEncoder()\n",
        "previsores[:, 8] = labelencoder6.fit_transform(previsores[:, 8])\n",
        "\n",
        "labelencoder7 = LabelEncoder()\n",
        "previsores[:, 9] = labelencoder7.fit_transform(previsores[:, 9])\n",
        "\n",
        "labelencoder8 = LabelEncoder()\n",
        "previsores[:, 11] = labelencoder8.fit_transform(previsores[:, 11])\n",
        "\n",
        "labelencoder9 = LabelEncoder()\n",
        "previsores[:, 13] = labelencoder9.fit_transform(previsores[:, 13])\n",
        "\n",
        "labelencoder10 = LabelEncoder()\n",
        "previsores[:, 14] = labelencoder10.fit_transform(previsores[:, 14])\n",
        "\n",
        "labelencoder11 = LabelEncoder()\n",
        "previsores[:, 16] = labelencoder11.fit_transform(previsores[:, 16])\n",
        "\n",
        "labelencoder12 = LabelEncoder()\n",
        "previsores[:, 18] = labelencoder12.fit_transform(previsores[:, 18])\n",
        "\n",
        "labelencoder13 = LabelEncoder()\n",
        "previsores[:, 19] = labelencoder13.fit_transform(previsores[:, 19])"
      ],
      "metadata": {
        "id": "jxy1QDLJ3NN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão da base de dados entre treinamento e teste (30% para testar e 70% para treinar)\n",
        "X_treino, X_teste, y_treinamento, y_teste = train_test_split(previsores,\n",
        "                                                                  classe,\n",
        "                                                                  test_size = 0.3,\n",
        "                                                                  random_state = 1)\n",
        "X_teste"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_iEuFuxyZV7",
        "outputId": "da0a2c09-72a0-41b4-a202-4f959f36faa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 15, 0, ..., 2, 1, 1],\n",
              "       [2, 36, 3, ..., 1, 0, 1],\n",
              "       [0, 12, 4, ..., 1, 0, 1],\n",
              "       ...,\n",
              "       [1, 15, 1, ..., 1, 1, 1],\n",
              "       [1, 24, 3, ..., 1, 0, 1],\n",
              "       [1, 9, 1, ..., 2, 0, 1]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#criacao do modelo de treinamento com vetor de suporte\n",
        "svm=SVC()\n",
        "svm.fit(X_treino,y_treinamento)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cT53shUygaB",
        "outputId": "6fd2f335-03a5-4578-cc60-0f3464883f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#previsoes de treino\n",
        "previsores=svm.predict(X_treino)\n",
        "previsores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poMLhlrw0bfc",
        "outputId": "dbe94dda-7114-42a8-b3e9-50a6827932db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'bad', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'bad', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'bad', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'bad', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'bad', 'good', 'good', 'good', 'bad', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'bad',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'bad', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'bad',\n",
              "       'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'bad',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'bad', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'bad', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'bad',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'bad', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good',\n",
              "       'good', 'good', 'good', 'good'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''taxa_acerto = accuracy_score(y_teste, previsoes)\n",
        "taxa_acerto'''"
      ],
      "metadata": {
        "id": "tLE-fslL0nGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest= ExtraTreesClassifier()\n",
        "forest.fit(X_treino, y_treinamento)\n",
        "importancias= forest.feature_importances_\n",
        "importancias"
      ],
      "metadata": {
        "id": "iZXNu5yP1cBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e501c6cb-1a8f-4904-c654-257effe1821b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10279421, 0.0803875 , 0.0670761 , 0.0611044 , 0.0816487 ,\n",
              "       0.05487028, 0.04996379, 0.05453965, 0.04344835, 0.02842405,\n",
              "       0.04816835, 0.0462817 , 0.07072119, 0.0423491 , 0.03476832,\n",
              "       0.03418078, 0.04014703, 0.02168586, 0.03124591, 0.00619471])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_treino=X_treino[:[0,1,2,3]]\n",
        "X_teste"
      ],
      "metadata": {
        "id": "A2hdUQ1Pi-5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import confusion_matrix , accuracy_score\n",
        "from scipy import stats\n",
        "from sklearn import datasets\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "lxLUOBSPk7ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iristemp=pd.read_csv('iris.csv')\n",
        "iristemp.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nmUjuQZxlf65",
        "outputId": "10d9e6cb-6c2e-4ab2-bfe1-73a85135a49b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal length  sepal width  petal length  petal width        class\n",
              "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
              "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
              "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
              "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
              "4           5.0          3.6           1.4          0.2  Iris-setosa"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9282635a-cbc3-443b-abc3-c9512ae5db05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length</th>\n",
              "      <th>sepal width</th>\n",
              "      <th>petal length</th>\n",
              "      <th>petal width</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9282635a-cbc3-443b-abc3-c9512ae5db05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9282635a-cbc3-443b-abc3-c9512ae5db05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9282635a-cbc3-443b-abc3-c9512ae5db05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris=datasets.load_iris()\n",
        "stats.describe(iris.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7CpcI1rluss",
        "outputId": "fa2d5a11-460a-4ede-843b-6e39cd39a46b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DescribeResult(nobs=150, minmax=(array([4.3, 2. , 1. , 0.1]), array([7.9, 4.4, 6.9, 2.5])), mean=array([5.84333333, 3.05733333, 3.758     , 1.19933333]), variance=array([0.68569351, 0.18997942, 3.11627785, 0.58100626]), skewness=array([ 0.31175306,  0.31576711, -0.27212767, -0.10193421]), kurtosis=array([-0.57356795,  0.18097632, -1.39553589, -1.33606741]))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#organizou em nums as classe\n",
        "#iris.data\n",
        "iris.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWiQo8ImmQWx",
        "outputId": "f261aa59-5e02-48c5-9a12-8b92046e7661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#indep é previsoreN , dep é a classe\n",
        "previsoesN=iris.data \n",
        "classe=iris.target"
      ],
      "metadata": {
        "id": "T9Fqvem5l8-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão da base de dados entre treinamento e teste (30% para testar e 70% para treinar)\n",
        "X_treino2, X_teste2, y_treino2, y_teste2 = train_test_split(previsoesN,\n",
        "                                                                  classe,\n",
        "                                                                  test_size = 0.3,\n",
        "                                                                  random_state = 1)\n",
        "len(X_teste2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCXrMM0QmVFo",
        "outputId": "f87aa7ac-1688-4c30-d116-5b4534975438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mtd pra metodo olhar qntos vizinhos + proximos vai relacionar no modelo\n",
        "knn=KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_treino2,y_treino2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81DmK4jWmi7W",
        "outputId": "5a66cb28-e2a9-4fb3-963c-a77e308c4eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#45 previsoes dos registros\n",
        "previsoesN=knn.predict(X_teste2)\n",
        "previsoesN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZKTS6tkm29o",
        "outputId": "f90e0f91-8bfd-4699-8a93-ed7493501255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 1, 2,\n",
              "       1])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#matrix com o y_teste e previsoes #diag principal sao os acertos , houve 1 erro\n",
        "confusaoN=confusion_matrix(y_teste2,previsoesN)\n",
        "confusaoN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlb6cJ7lm_8S",
        "outputId": "158becca-a127-482b-b3e8-cc8d5a44c0d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14,  0,  0],\n",
              "       [ 0, 18,  0],\n",
              "       [ 0,  1, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#taxas de acerto e erro\n",
        "taxa_acertoN = accuracy_score(y_teste2, previsoesN)\n",
        "taxa_erroN = 1 - taxa_acertoN\n",
        "taxa_acertoN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7ocvFX7rWtE",
        "outputId": "0d45b2a6-6e38-421d-8063-2ab1f6995295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ensamble learning com random forest\n",
        "#gera varios modelos(trees conforme parametro definido) variando em termo de config , pra ver qual melhor votando pela performance"
      ],
      "metadata": {
        "id": "GKlGpP7tr-hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "-3IeycAUsDmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "creditorf = pd.read_csv('Credit.csv')\n",
        "creditorf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "8HmgcxVisbQW",
        "outputId": "e63a7551-9b94-49ee-a769-2ae21e8f0a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  checking_status  duration                    credit_history  \\\n",
              "0              <0         6  'critical/other existing credit'   \n",
              "1        0<=X<200        48                   'existing paid'   \n",
              "2   'no checking'        12  'critical/other existing credit'   \n",
              "3              <0        42                   'existing paid'   \n",
              "4              <0        24              'delayed previously'   \n",
              "\n",
              "               purpose  credit_amount      savings_status employment  \\\n",
              "0             radio/tv           1169  'no known savings'        >=7   \n",
              "1             radio/tv           5951                <100     1<=X<4   \n",
              "2            education           2096                <100     4<=X<7   \n",
              "3  furniture/equipment           7882                <100     4<=X<7   \n",
              "4            'new car'           4870                <100     1<=X<4   \n",
              "\n",
              "   installment_commitment       personal_status other_parties  ...  \\\n",
              "0                       4         'male single'          none  ...   \n",
              "1                       2  'female div/dep/mar'          none  ...   \n",
              "2                       2         'male single'          none  ...   \n",
              "3                       2         'male single'     guarantor  ...   \n",
              "4                       3         'male single'          none  ...   \n",
              "\n",
              "    property_magnitude age  other_payment_plans     housing existing_credits  \\\n",
              "0        'real estate'  67                 none         own                2   \n",
              "1        'real estate'  22                 none         own                1   \n",
              "2        'real estate'  49                 none         own                1   \n",
              "3     'life insurance'  45                 none  'for free'                1   \n",
              "4  'no known property'  53                 none  'for free'                2   \n",
              "\n",
              "                    job num_dependents  own_telephone foreign_worker class  \n",
              "0               skilled              1            yes            yes  good  \n",
              "1               skilled              1           none            yes   bad  \n",
              "2  'unskilled resident'              2           none            yes  good  \n",
              "3               skilled              2           none            yes  good  \n",
              "4               skilled              2           none            yes   bad  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-defb72a7-00aa-4c23-9024-d60a59aea96e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>checking_status</th>\n",
              "      <th>duration</th>\n",
              "      <th>credit_history</th>\n",
              "      <th>purpose</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>savings_status</th>\n",
              "      <th>employment</th>\n",
              "      <th>installment_commitment</th>\n",
              "      <th>personal_status</th>\n",
              "      <th>other_parties</th>\n",
              "      <th>...</th>\n",
              "      <th>property_magnitude</th>\n",
              "      <th>age</th>\n",
              "      <th>other_payment_plans</th>\n",
              "      <th>housing</th>\n",
              "      <th>existing_credits</th>\n",
              "      <th>job</th>\n",
              "      <th>num_dependents</th>\n",
              "      <th>own_telephone</th>\n",
              "      <th>foreign_worker</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>6</td>\n",
              "      <td>'critical/other existing credit'</td>\n",
              "      <td>radio/tv</td>\n",
              "      <td>1169</td>\n",
              "      <td>'no known savings'</td>\n",
              "      <td>&gt;=7</td>\n",
              "      <td>4</td>\n",
              "      <td>'male single'</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>'real estate'</td>\n",
              "      <td>67</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "      <td>2</td>\n",
              "      <td>skilled</td>\n",
              "      <td>1</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0&lt;=X&lt;200</td>\n",
              "      <td>48</td>\n",
              "      <td>'existing paid'</td>\n",
              "      <td>radio/tv</td>\n",
              "      <td>5951</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>1&lt;=X&lt;4</td>\n",
              "      <td>2</td>\n",
              "      <td>'female div/dep/mar'</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>'real estate'</td>\n",
              "      <td>22</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "      <td>1</td>\n",
              "      <td>skilled</td>\n",
              "      <td>1</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'no checking'</td>\n",
              "      <td>12</td>\n",
              "      <td>'critical/other existing credit'</td>\n",
              "      <td>education</td>\n",
              "      <td>2096</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>4&lt;=X&lt;7</td>\n",
              "      <td>2</td>\n",
              "      <td>'male single'</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>'real estate'</td>\n",
              "      <td>49</td>\n",
              "      <td>none</td>\n",
              "      <td>own</td>\n",
              "      <td>1</td>\n",
              "      <td>'unskilled resident'</td>\n",
              "      <td>2</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>42</td>\n",
              "      <td>'existing paid'</td>\n",
              "      <td>furniture/equipment</td>\n",
              "      <td>7882</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>4&lt;=X&lt;7</td>\n",
              "      <td>2</td>\n",
              "      <td>'male single'</td>\n",
              "      <td>guarantor</td>\n",
              "      <td>...</td>\n",
              "      <td>'life insurance'</td>\n",
              "      <td>45</td>\n",
              "      <td>none</td>\n",
              "      <td>'for free'</td>\n",
              "      <td>1</td>\n",
              "      <td>skilled</td>\n",
              "      <td>2</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;0</td>\n",
              "      <td>24</td>\n",
              "      <td>'delayed previously'</td>\n",
              "      <td>'new car'</td>\n",
              "      <td>4870</td>\n",
              "      <td>&lt;100</td>\n",
              "      <td>1&lt;=X&lt;4</td>\n",
              "      <td>3</td>\n",
              "      <td>'male single'</td>\n",
              "      <td>none</td>\n",
              "      <td>...</td>\n",
              "      <td>'no known property'</td>\n",
              "      <td>53</td>\n",
              "      <td>none</td>\n",
              "      <td>'for free'</td>\n",
              "      <td>2</td>\n",
              "      <td>skilled</td>\n",
              "      <td>2</td>\n",
              "      <td>none</td>\n",
              "      <td>yes</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-defb72a7-00aa-4c23-9024-d60a59aea96e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-defb72a7-00aa-4c23-9024-d60a59aea96e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-defb72a7-00aa-4c23-9024-d60a59aea96e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsoresrf = creditorf.iloc[:,0:20].values\n",
        "classerf = creditorf.iloc[:,20].values"
      ],
      "metadata": {
        "id": "2W5hUvAXsgQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformação dos atributos categóricos em atributos numéricos, passando o índice de cada atributo categórico\n",
        "labelencoder = LabelEncoder()\n",
        "previsoresrf[:,0] = labelencoder.fit_transform(previsoresrf[:,0])\n",
        "previsoresrf[:,2] = labelencoder.fit_transform(previsoresrf[:,2])\n",
        "previsoresrf[:, 3] = labelencoder.fit_transform(previsoresrf[:, 3])\n",
        "previsoresrf[:, 5] = labelencoder.fit_transform(previsoresrf[:, 5])\n",
        "previsoresrf[:, 6] = labelencoder.fit_transform(previsoresrf[:, 6])\n",
        "previsoresrf[:, 8] = labelencoder.fit_transform(previsoresrf[:, 8])\n",
        "previsoresrf[:, 9] = labelencoder.fit_transform(previsoresrf[:, 9])\n",
        "previsoresrf[:, 11] = labelencoder.fit_transform(previsoresrf[:, 11])\n",
        "previsoresrf[:, 13] = labelencoder.fit_transform(previsoresrf[:, 13])\n",
        "previsoresrf[:, 14] = labelencoder.fit_transform(previsoresrf[:, 14])\n",
        "previsoresrf[:, 16] = labelencoder.fit_transform(previsoresrf[:, 16])\n",
        "previsoresrf[:, 18] = labelencoder.fit_transform(previsoresrf[:, 18])\n",
        "previsoresrf[:, 19] = labelencoder.fit_transform(previsoresrf[:, 19])"
      ],
      "metadata": {
        "id": "AB9ID0ydsss5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão da base de dados entre treinamento e teste (30% para testar e 70% para treinar)\n",
        "X_treinorf, X_testerf, y_treinorf, y_testerf = train_test_split(previsoresrf,\n",
        "                                                                  classerf,\n",
        "                                                                  test_size = 0.3,\n",
        "                                                                  random_state = 0)"
      ],
      "metadata": {
        "id": "VGr7J_oZtMUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação do modelo, treinamento, obtenção das previsões e da taxa de acerto,n_estimators num de arv aleatorias criadas\n",
        "floresta = RandomForestClassifier(n_estimators = 20)\n",
        "floresta.fit(X_treinorf, y_treinorf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y3zCiLOteHc",
        "outputId": "41bd5862-f1b4-4f5d-c5a8-084ba5e5129b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=50)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização dos atributos principais,ver tds as variacoes geradas\n",
        "floresta.estimators_\n",
        "#floresta.estimators_[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKLpbiQlted_",
        "outputId": "77a5cb1b-3a8d-4b53-e09a-d16a4a612cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DecisionTreeClassifier(max_features='auto', random_state=1661209425),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=51720974),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=698629682),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1254391408),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=585904218),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1396742071),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=296186212),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1650825386),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1591366532),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=58187894),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=616070370),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=3419731),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=2036027058),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1877483932),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=236452242),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1705946556),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1947568857),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1760806990),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1959660323),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=165659367),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=2089014257),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1567280408),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1149077177),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1620802664),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=300338402),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1675932469),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=849175816),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=176640358),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1859883910),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=744542359),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1510996836),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1092435193),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1762052262),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1328252639),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=369269421),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1898588513),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1121440578),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=185392236),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=2021505328),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=366486139),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=2057623050),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1866277079),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=987957292),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1663669399),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=486048407),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=898542952),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1184535721),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=651202330),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=2075777357),\n",
              " DecisionTreeClassifier(max_features='auto', random_state=1127390152)]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsoesrf = floresta.predict(X_testerf)\n",
        "confusao = confusion_matrix(y_testerf, previsoesrf)\n",
        "taxa_acertorf = accuracy_score(y_testerf, previsoesrf)\n",
        "taxa_acertorf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4op_i0vtrwY",
        "outputId": "e0532254-4c20-4692-8528-77eb463c95e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#kmeans usa distancia euclidiana para agrupar usuarios , atraves de num de clusters previamente definido"
      ],
      "metadata": {
        "id": "mTBlz2Enwgno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "51DMpySOvZTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregamento da base de dados \n",
        "iris = datasets.load_iris()\n",
        "# visualização de quantos registros existem por classe,tarefa ñ supervisionada\n",
        "unicosk, quantidadek = np.unique(iris.target, return_counts = True) #conta qtd de registros na classe\n",
        "unicosk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OSTqf1xvab9",
        "outputId": "e999e9e8-ef6d-4ea8-b4b8-f4608eb987ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantidadek"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmqkGN-9vdrS",
        "outputId": "b0624caf-8e65-4e77-e1f2-088016a87107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([50, 50, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupamento com k-means, utilizando 3 clusters (de acordo com a base de dados),define aq o num de clusters\n",
        "cluster = KMeans(n_clusters = 3)\n",
        "cluster.fit(iris.data) #ñ usa target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC0DGK_1viYz",
        "outputId": "b382203b-98f3-4a67-f0d3-c9a9f19e4143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=3)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização dos três centroides\n",
        "centroides = cluster.cluster_centers_\n",
        "centroides"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8Q70gOivluQ",
        "outputId": "746c6300-a1f1-4fd2-ca1e-c73bece26d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.9016129 , 2.7483871 , 4.39354839, 1.43387097],\n",
              "       [5.006     , 3.428     , 1.462     , 0.246     ],\n",
              "       [6.85      , 3.07368421, 5.74210526, 2.07105263]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização dos grupos que cada registro foi associado,ñ é previsao é agrupamento\n",
        "previsoesk = cluster.labels_\n",
        "previsoesk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f53MIkJvp44",
        "outputId": "b3024b22-6cec-4a6b-9db5-a0489dc5b0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2,\n",
              "       2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2,\n",
              "       2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contagem dos registros por classe\n",
        "unicosk2, quantidadek2 = np.unique(previsoesk, return_counts = True)\n",
        "unicosk2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajh20cPevuWh",
        "outputId": "885f1104-2ddb-45d6-a9d5-2d0f69eb4a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantidadek2 #mudou agrupamento , ñ coincndo com classes reais"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-S_xYe-vzHB",
        "outputId": "f762d3af-e8a4-42ad-a6d7-bb8100803de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([62, 50, 38])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Geração da matriz de contingência para comparar os grupos com a base de dados\n",
        "resultadosk = confusion_matrix(iris.target, previsoesk)\n",
        "resultadosk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpSY5Nfkv7Lh",
        "outputId": "fa888057-181c-40d4-a550-106a4b6ae712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0, 50,  0],\n",
              "       [48,  0,  2],\n",
              "       [14,  0, 36]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Geração do gráfico com os clusters gerados, considerando para um (previsoes 0, 1 ou 2)\n",
        "# Usamos somente as colunas 0 e 1 da base de dados original para termos 2 dimensões\n",
        "plt.scatter(iris.data[previsoesk == 0, 0], iris.data[previsoesk == 0, 1], \n",
        "            c = 'green', label = 'Setosa')\n",
        "plt.scatter(iris.data[previsoesk == 1, 0], iris.data[previsoesk == 1, 1], \n",
        "            c = 'red', label = 'Versicolor')\n",
        "plt.scatter(iris.data[previsoesk == 2, 0], iris.data[previsoesk == 2, 1], \n",
        "            c = 'blue', label = 'Virgica')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "izQXxgO1v8eA",
        "outputId": "b28a2eed-4018-4375-c3ac-12d7134bcac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdd6f617430>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#C-MEANS=define num de clusters e com dist de euclides ele associa elementos aos centros ajustando-os até forma definitiva \n",
        "#ñ atribui instancia absoluta ao cluster , atribuicao é proporcional(ex:70% ao cluster 1 etc)"
      ],
      "metadata": {
        "id": "iTqv4uJ-4l-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-fuzzy "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVfPFpgD5yVw",
        "outputId": "4d03c5fd-2442-4d59-d97e-e36a77bad4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-fuzzy\n",
            "  Downloading scikit-fuzzy-0.4.2.tar.gz (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m994.0/994.0 KB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from scikit-fuzzy) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from scikit-fuzzy) (1.7.3)\n",
            "Requirement already satisfied: networkx>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from scikit-fuzzy) (2.8.8)\n",
            "Building wheels for collected packages: scikit-fuzzy\n",
            "  Building wheel for scikit-fuzzy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-fuzzy: filename=scikit_fuzzy-0.4.2-py3-none-any.whl size=894088 sha256=13fbed98c71f31620f3c897863c08893d06fe4767bf1d9f5033a818f9196169f\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/04/80/7eefb1a2de7d36aefd06432fab2a1486caf0a0596a7067391a\n",
            "Successfully built scikit-fuzzy\n",
            "Installing collected packages: scikit-fuzzy\n",
            "Successfully installed scikit-fuzzy-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Importação das bibliotecas\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import skfuzzy\n",
        "#"
      ],
      "metadata": {
        "id": "IGE_V3ie4oAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregamento da base de dados iris, que já está disponível no sklearn e coloca obj iris\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "MG9FqtLR4yz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicação do algoritmo definindo três cluster (c = 3) e passando a matriz transposta (iris.data.T). Os outros parâmetros são obrigatórios e são os dc efault indicados na documentação\n",
        "#tem q passar matrix transp pro cluster e c é o num de clusters\n",
        "r = skfuzzy.cmeans(data = iris.data.T, c = 3, m = 2, error = 0.005,\n",
        "                   maxiter = 1000, init = None) "
      ],
      "metadata": {
        "id": "WwqOPhuj42DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtendo as porcentagens de um registros pertencer a um cluster, que está na posição 1 da matriz retornada\n",
        "previsoes_porcentagem = r[1] #posicao 1 da pctg dos clusters"
      ],
      "metadata": {
        "id": "FS3ZR3Gd48CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização da probabilidade de um registro pertencer a cada um dos cluster (o somatório é 1.0 que indica 100%)\n",
        "for x in range(150):\n",
        "  print( previsoes_porcentagem[0][x] ,previsoes_porcentagem[1][x] ,previsoes_porcentagem[2][x] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUT97ly05FaP",
        "outputId": "4f49b93a-8b84-41f9-90a6-c9bc43680758"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.996623648101864 0.0010718900492563868 0.0023044618488795563\n",
            "0.9758344356432936 0.007502469072697833 0.016663095284008313\n",
            "0.9798141251601632 0.006417500964095765 0.013768373875740958\n",
            "0.9674034608869867 0.010113466099689057 0.022483073013324213\n",
            "0.9944699230117076 0.0017678773798651556 0.003762199608427262\n",
            "0.9345353843415768 0.02063001299044063 0.04483460266798255\n",
            "0.9794794116376553 0.006507590200508871 0.014012998161835717\n",
            "0.9995469331641795 0.00014128898194394932 0.0003117778538764827\n",
            "0.9303341119314014 0.021913636722716248 0.04775225134588247\n",
            "0.9827092969520647 0.005344991631333609 0.01194571141660178\n",
            "0.9680254208587454 0.010205329165302354 0.02176924997595208\n",
            "0.9921303838922019 0.0024328111235229154 0.005436804984275196\n",
            "0.9706196151168373 0.009182261960349242 0.02019812292281361\n",
            "0.9229284162421761 0.025246608093456243 0.051824975664367584\n",
            "0.8897142945191054 0.03764507234263659 0.07264063313825804\n",
            "0.841281951111997 0.054326045256094045 0.10439200363190888\n",
            "0.9469013667746619 0.01750219869522746 0.035596434530110736\n",
            "0.9966521843967118 0.0010588367963266794 0.002288978806961407\n",
            "0.9040809459419888 0.030322619903541154 0.06559643415446996\n",
            "0.9791790619190671 0.006656172023661575 0.01416476605727116\n",
            "0.9685797598495411 0.009546459657329968 0.021873780493128964\n",
            "0.9848246475057282 0.004795962615294624 0.010379389878977258\n",
            "0.958641641646663 0.013837033044238969 0.027521325309097965\n",
            "0.9794056731631559 0.006116941675921378 0.014477385160922852\n",
            "0.9668891441723602 0.009845462842064579 0.02326539298557537\n",
            "0.9735441542384434 0.007979316795893966 0.0184765289656626\n",
            "0.9948388284140439 0.0015750597592129574 0.003586111826743016\n",
            "0.9933447124652766 0.0020875880224076673 0.004567699512315574\n",
            "0.9936732103306928 0.0019966030542602604 0.004330186615047072\n",
            "0.9794991045850453 0.006286840794707379 0.014214054620247437\n",
            "0.9787088664048738 0.006478144961281994 0.014812988633844318\n",
            "0.9743462050415718 0.007944109879764705 0.017709685078663714\n",
            "0.9384934005238791 0.020341643309515624 0.0411649561666053\n",
            "0.904130152010835 0.03236009155548383 0.06350975643368113\n",
            "0.9850524662307096 0.004597238928762006 0.010350294840528443\n",
            "0.984986456896406 0.00480690275694158 0.010206640346652439\n",
            "0.9641667398785878 0.011568682673627196 0.024264577447785107\n",
            "0.9908888361289192 0.0029269142431107274 0.00618424962797012\n",
            "0.9396470584486222 0.019241766707713878 0.041111174843663986\n",
            "0.9982878308936649 0.0005335483051538615 0.0011786208011812635\n",
            "0.9947273513101872 0.0016882725331710253 0.003584376156641828\n",
            "0.8506453774665411 0.04701576256523086 0.10233885996822814\n",
            "0.9525876159916756 0.015215377270700511 0.032197006737623816\n",
            "0.9792705353545813 0.006333915775465637 0.01439554886995297\n",
            "0.9452314393805268 0.016610591378284474 0.03815796924118887\n",
            "0.9721252895764393 0.008636711743825312 0.019237998679735448\n",
            "0.9767807238706997 0.007368063917397477 0.015851212211902655\n",
            "0.9742041260148692 0.008130924857774233 0.017664949127356548\n",
            "0.9772088923440465 0.0072624528828419315 0.015528654773111394\n",
            "0.9970710934554846 0.0009196278124686943 0.002009278732046722\n",
            "0.044573209619137494 0.5018899171973891 0.45353687318347347\n",
            "0.02920951051143538 0.2075539093967115 0.763236580091853\n",
            "0.031250535165892296 0.6008808567484342 0.36786860808567345\n",
            "0.04920845000230752 0.08030942705136031 0.8704821229463322\n",
            "0.024155086806449184 0.21804685913849867 0.7577980540550522\n",
            "0.005733697593097065 0.02047442855035685 0.9737918738565461\n",
            "0.02983113745981895 0.29822164351315933 0.6719472190270217\n",
            "0.2848541234129946 0.13227742029108117 0.5828684562959242\n",
            "0.03127061672741217 0.24851592259835373 0.7202134606742341\n",
            "0.07457933529107519 0.09458082336675915 0.8308398413421658\n",
            "0.21815644222517616 0.14501924856050083 0.636824309214323\n",
            "0.009177277575372214 0.02875713723364502 0.9620655851909827\n",
            "0.05552487060518583 0.10104978333099525 0.8434253460638189\n",
            "0.012174414654984034 0.08887446997850665 0.8989511153665093\n",
            "0.09142312293354327 0.09206579621665947 0.8165110808497972\n",
            "0.04174974651209962 0.2690433615831766 0.6892068919047237\n",
            "0.014159564051823835 0.0527857726017546 0.9330546633464216\n",
            "0.02578177523602255 0.0482241721733518 0.9259940525906256\n",
            "0.027163950541146963 0.1377436103905973 0.8350924390682558\n",
            "0.051377259346614954 0.07060651212458884 0.8780162285287962\n",
            "0.02765550231715183 0.2516491650390778 0.7206953326437705\n",
            "0.019442011985670943 0.04617371563199989 0.9343842723823291\n",
            "0.024006073162840973 0.27159849450504336 0.7043954323321155\n",
            "0.013979650834012047 0.08376428479375696 0.902256064372231\n",
            "0.022937765044625535 0.10149460026764748 0.875567634687727\n",
            "0.03397963209141478 0.21189017861915754 0.7541301892894277\n",
            "0.03361255321411439 0.443701049540188 0.5226863972456977\n",
            "0.021155594664279142 0.6736673090792277 0.30517709625649325\n",
            "0.004982938814806435 0.026488490911642983 0.9685285702735505\n",
            "0.12805037850883155 0.10454890311810412 0.7674007183730643\n",
            "0.07759399903086105 0.08974437853491767 0.8326616224342214\n",
            "0.10353648808699172 0.10061438355831168 0.7958491283546966\n",
            "0.030841807825737977 0.050141401997068874 0.9190167901771931\n",
            "0.023998142584497246 0.3208694614719772 0.6551323959435256\n",
            "0.026364320648000684 0.08252147374375163 0.8911142056082476\n",
            "0.03218202070116727 0.17121659712951107 0.7966013821693216\n",
            "0.033466515680659864 0.41215742727754273 0.5543760570417975\n",
            "0.02687600831756594 0.11570367213435513 0.857420319548079\n",
            "0.023996795223743456 0.046864437530523884 0.9291387672457327\n",
            "0.038032788353717026 0.062217174033271344 0.8997500376130116\n",
            "0.01956502094192515 0.04913026448429526 0.9313047145737797\n",
            "0.01167451611246884 0.07323456660966196 0.9150909172778692\n",
            "0.022399582970024565 0.04162312132495608 0.9359772957050193\n",
            "0.26861391324658473 0.13270302115754096 0.5986830655958743\n",
            "0.012595357261017001 0.0282896138170495 0.9591150289219335\n",
            "0.016714698128179894 0.03757567670886264 0.9457096251629575\n",
            "0.009513838353376448 0.022894516806330974 0.9675916448402925\n",
            "0.011427479513579598 0.04488329938677632 0.943689221099644\n",
            "0.3550070294669694 0.12450130853715173 0.5204916619958789\n",
            "0.012599075683140575 0.026582712881924472 0.960818211434935\n",
            "0.019371003986340875 0.8599515734351283 0.12067742257853079\n",
            "0.029313520258518494 0.3561171165121623 0.6145693632293192\n",
            "0.0061089619421927505 0.9555773778532838 0.03831366020452348\n",
            "0.012489076347380165 0.8462313126737878 0.14127961097883204\n",
            "0.004752487745702648 0.9576764972114082 0.03757101504288913\n",
            "0.03551870901012023 0.8116848519400296 0.15279643904985013\n",
            "0.07291429592975869 0.1670967279385723 0.759988976131669\n",
            "0.02194223973890976 0.8628024792102494 0.11525528105084076\n",
            "0.01398535892439789 0.8689018416960239 0.11711279937957828\n",
            "0.024468417704102 0.8608100379911533 0.11472154430474461\n",
            "0.016720538425389134 0.774377721827686 0.2089017397469248\n",
            "0.01571447463686874 0.7622038674691743 0.2220816578939568\n",
            "0.0011560332862278096 0.9889313466924704 0.009912620021301834\n",
            "0.03438179503093827 0.3064067827341786 0.6592114222348832\n",
            "0.038360349723606794 0.5014443822847582 0.46019526799163496\n",
            "0.014028764453585064 0.8504632077654721 0.13550802778094292\n",
            "0.007123055581128068 0.9138312402653996 0.07904570415347249\n",
            "0.05065215074429362 0.7634375004480657 0.1859103488076407\n",
            "0.04923958034654191 0.7574249330344912 0.19333548661896688\n",
            "0.03220905280990958 0.25772358702739034 0.7100673601627001\n",
            "0.003847999868493552 0.9703503989906759 0.025801601140830632\n",
            "0.03366411079238264 0.2600656138388891 0.7062702753687282\n",
            "0.04202766943798257 0.783048208835154 0.17492412172686356\n",
            "0.02281882816089493 0.3828500647346938 0.5943311071044112\n",
            "0.002918852775295018 0.9753296295442783 0.02175151768042673\n",
            "0.01294424081070401 0.9117612191606045 0.07529454002869145\n",
            "0.02101839051922176 0.27250835666847334 0.7064732528123049\n",
            "0.023119589683571105 0.3313467946630493 0.6455336156533795\n",
            "0.008329531276217664 0.9090852354420776 0.08258523328170468\n",
            "0.01446422973846199 0.8907828236965718 0.09475294656496613\n",
            "0.019827696877072743 0.8726126868465771 0.10755961627635005\n",
            "0.05096449939066339 0.7599619596044132 0.18907354100492346\n",
            "0.008931473881149685 0.906595788802186 0.08447273731666434\n",
            "0.023397369854123475 0.43780187706272605 0.5388007530831505\n",
            "0.03117063634135424 0.5769098370485993 0.39191952661004636\n",
            "0.028715971840690434 0.8393819298691259 0.13190209829018376\n",
            "0.017214729167581655 0.8543499273935857 0.12843534343883267\n",
            "0.009743716190868725 0.8808368850856241 0.10941939872350721\n",
            "0.021769865824660572 0.22943708670435392 0.7487930474709855\n",
            "0.0034791360070442648 0.9676878126854523 0.028833051307503445\n",
            "0.005079886565828916 0.957275274015495 0.03764483941867612\n",
            "0.015379265847888327 0.8555254857470432 0.12909524840506836\n",
            "0.029313520258518494 0.3561171165121623 0.6145693632293192\n",
            "0.005276466363538087 0.9608590526301902 0.03386448100627159\n",
            "0.009715884939637594 0.9270878210696774 0.06319629399068509\n",
            "0.01123153334917865 0.8828518449547356 0.10591662169608593\n",
            "0.02579656940768258 0.4679176375902706 0.5062857930020468\n",
            "0.012065368452471095 0.8324550031074268 0.1554796284401021\n",
            "0.02155438307094708 0.7899365059522311 0.1885091109768217\n",
            "0.02693353132645057 0.3925022222511206 0.5805642464224289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Geração de matriz de contingência para comparação com as classes originais da base de dados\n",
        "previsoes = previsoes_porcentagem.argmax(axis = 0)\n",
        "resultados = confusion_matrix(iris.target, previsoes)\n",
        "resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjADwyyb5HEo",
        "outputId": "3751660b-253f-42f2-fe8e-18e96c16324b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[50,  0,  0],\n",
              "       [ 0,  3, 47],\n",
              "       [ 0, 37, 13]])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyclustering"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOzj3Muc7im_",
        "outputId": "6a9880fe-5b42-4012-b2a3-5abd009ccb6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyclustering\n",
            "  Downloading pyclustering-0.10.1.2.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from pyclustering) (1.7.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from pyclustering) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.2 in /usr/local/lib/python3.8/dist-packages (from pyclustering) (1.21.6)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.8/dist-packages (from pyclustering) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->pyclustering) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->pyclustering) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->pyclustering) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.0.0->pyclustering) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.0->pyclustering) (1.15.0)\n",
            "Building wheels for collected packages: pyclustering\n",
            "  Building wheel for pyclustering (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyclustering: filename=pyclustering-0.10.1.2-py3-none-any.whl size=2395121 sha256=9003e0b8787d0621e2a572ab2240acbe8333958ae7e3978e2c76213fdf9aab31\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/25/8b/072b221a5cff4f04e7999d39ca1b6cb5dad702cc3e1da951d4\n",
            "Successfully built pyclustering\n",
            "Installing collected packages: pyclustering\n",
            "Successfully installed pyclustering-0.10.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#centros sao por pontos reais de dados"
      ],
      "metadata": {
        "id": "z4_z833l8MM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "from pyclustering.cluster.kmedoids import kmedoids\n",
        "from pyclustering.cluster import cluster_visualizer\n",
        "#pip install pyclustering (executar no Anaconda Prompt)"
      ],
      "metadata": {
        "id": "Wk1hz8327DgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregamento da base de dados\n",
        "iris = datasets.load_iris()"
      ],
      "metadata": {
        "id": "f9s1FpXh7gZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração dos parâmetros do k-medoids, utilizando somente as duas primeiras colunas da base de dados por causa da visualização apenas\n",
        "# 3, 12 e 20 são índices aleatórios de registros da base de dados (inicialização)\n",
        "cluster = kmedoids(iris.data[:, 0:2], [3, 12, 20])#mdoids definidos , sao os indices dos registros\n",
        "# Visualização dos pontos escolhidos (3, 12 e 20)\n",
        "cluster.get_medoids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU0W8F9E7uNz",
        "outputId": "2796b933-47fe-4056-df84-e1ebc4db3ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 12, 20]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicação do algoritmo para o agrupamento, obtenção dos grupo de cada registro e visualização dos medoides\n",
        "cluster.process()\n",
        "previsoes = cluster.get_clusters()\n",
        "medoides = cluster.get_medoids()\n",
        "#lista de 3 elementos, com os indices dos registros do cluster cada lista é um cluster ,cada indice é um dado\n",
        "previsoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwpTgnh27yRy",
        "outputId": "c8bad451-27c1-4f6b-b174-da47e7391b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[50,\n",
              "  51,\n",
              "  52,\n",
              "  54,\n",
              "  56,\n",
              "  58,\n",
              "  65,\n",
              "  74,\n",
              "  75,\n",
              "  76,\n",
              "  77,\n",
              "  86,\n",
              "  100,\n",
              "  102,\n",
              "  103,\n",
              "  104,\n",
              "  105,\n",
              "  107,\n",
              "  108,\n",
              "  109,\n",
              "  110,\n",
              "  111,\n",
              "  112,\n",
              "  115,\n",
              "  116,\n",
              "  117,\n",
              "  118,\n",
              "  120,\n",
              "  122,\n",
              "  124,\n",
              "  125,\n",
              "  128,\n",
              "  129,\n",
              "  130,\n",
              "  131,\n",
              "  132,\n",
              "  135,\n",
              "  136,\n",
              "  137,\n",
              "  139,\n",
              "  140,\n",
              "  141,\n",
              "  143,\n",
              "  144,\n",
              "  145,\n",
              "  147,\n",
              "  148],\n",
              " [53,\n",
              "  55,\n",
              "  57,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  62,\n",
              "  63,\n",
              "  64,\n",
              "  66,\n",
              "  67,\n",
              "  68,\n",
              "  69,\n",
              "  70,\n",
              "  71,\n",
              "  72,\n",
              "  73,\n",
              "  78,\n",
              "  79,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  83,\n",
              "  84,\n",
              "  85,\n",
              "  87,\n",
              "  88,\n",
              "  89,\n",
              "  90,\n",
              "  91,\n",
              "  92,\n",
              "  93,\n",
              "  94,\n",
              "  95,\n",
              "  96,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  101,\n",
              "  113,\n",
              "  114,\n",
              "  119,\n",
              "  121,\n",
              "  123,\n",
              "  126,\n",
              "  127,\n",
              "  133,\n",
              "  134,\n",
              "  138,\n",
              "  142,\n",
              "  146,\n",
              "  149],\n",
              " [0,\n",
              "  1,\n",
              "  2,\n",
              "  3,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  19,\n",
              "  20,\n",
              "  21,\n",
              "  22,\n",
              "  23,\n",
              "  24,\n",
              "  25,\n",
              "  26,\n",
              "  27,\n",
              "  28,\n",
              "  29,\n",
              "  30,\n",
              "  31,\n",
              "  32,\n",
              "  33,\n",
              "  34,\n",
              "  35,\n",
              "  36,\n",
              "  37,\n",
              "  38,\n",
              "  39,\n",
              "  40,\n",
              "  41,\n",
              "  42,\n",
              "  43,\n",
              "  44,\n",
              "  45,\n",
              "  46,\n",
              "  47,\n",
              "  48,\n",
              "  49,\n",
              "  106]]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização do agrupamento, grafico do cluster com os centoids com tds os dados das 2 primeiras cols\n",
        "v = cluster_visualizer()\n",
        "v.append_clusters(previsoes, iris.data[:,0:2])\n",
        "v.append_cluster(medoides, data = iris.data[:,0:2], marker = '*', markersize = 20)\n",
        "v.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "EnMtpHMK720d",
        "outputId": "c00f7b05-e435-45bb-a5f0-2a34273abf29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Código para criar duas listas, uma com os grupos reais da base de dados e outra com os valores dos grupos\n",
        "# Utilizado posteriormente para visualização da matriz de contingência==matrix de confusao\n",
        "lista_previsoes = []\n",
        "lista_real = []\n",
        "for i in range(len(previsoes)):\n",
        "     for j in range(len(previsoes[i])):\n",
        "        lista_previsoes.append(i)\n",
        "        lista_real.append(iris.target[previsoes[i][j]])"
      ],
      "metadata": {
        "id": "BP_07U4O77j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Geração da matriz de contingência, comparando os grupos reais com os grupos previstos\n",
        "lista_previsoes = np.asarray(lista_previsoes)\n",
        "lista_real = np.asarray(lista_real)\n",
        "resultados = confusion_matrix(lista_real, lista_previsoes)\n",
        "resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciYoikMg8ALr",
        "outputId": "66d4d24a-caf3-4770-85e6-47fcfef930b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0, 50],\n",
              "       [12, 38,  0],\n",
              "       [35, 14,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#REGRAS DE ASSOSIACAO"
      ],
      "metadata": {
        "id": "UGV8IWuq9z4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apyori"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5howhpwfALBr",
        "outputId": "bcc39c0c-24c8-452d-a634-151a378364c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting apyori\n",
            "  Downloading apyori-1.1.2.tar.gz (8.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: apyori\n",
            "  Building wheel for apyori (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apyori: filename=apyori-1.1.2-py3-none-any.whl size=5973 sha256=cd85a8be8cb1a2f6b50cb27552a0198616dc200931081f5cca186e5ed788ed58\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/02/6c/a45230be8603bd95c0a51cd2b289aefdd860c1a100eab73661\n",
            "Successfully built apyori\n",
            "Installing collected packages: apyori\n",
            "Successfully installed apyori-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas\n",
        "import pandas as pd\n",
        "from apyori import apriori\n",
        "#pip install apyori (executar no Anaconda Prompt)"
      ],
      "metadata": {
        "id": "aly1dj4f-Cl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Leitura das trasações \n",
        "dados = pd.read_csv('transacoes.txt', header = None)\n",
        "dados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "vNjTrXQi-T7_",
        "outputId": "c2f68b65-c043-4958-ee73-4eef7fe60708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0        1        2\n",
              "0  Cerveja    Pizza  Sorvete\n",
              "1    Pizza  Sorvete      NaN\n",
              "2  Cerveja    Pizza      NaN\n",
              "3  Cerveja    Pizza  Sorvete\n",
              "4  Cerveja    Pizza      NaN\n",
              "5    Pizza      NaN      NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78192773-c90b-4dc3-9c87-7534793eb954\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cerveja</td>\n",
              "      <td>Pizza</td>\n",
              "      <td>Sorvete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pizza</td>\n",
              "      <td>Sorvete</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cerveja</td>\n",
              "      <td>Pizza</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cerveja</td>\n",
              "      <td>Pizza</td>\n",
              "      <td>Sorvete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cerveja</td>\n",
              "      <td>Pizza</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pizza</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78192773-c90b-4dc3-9c87-7534793eb954')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78192773-c90b-4dc3-9c87-7534793eb954 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78192773-c90b-4dc3-9c87-7534793eb954');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transformação para o formato de lista, que é exigido pela biblioteca apyori - 6 é a quantidade de itens na base de dados\n",
        "#for pra add transacoes na lista\n",
        "transacoes = []\n",
        "for i in range(0,6):\n",
        "    transacoes.append([str(dados.values[i,j]) for j in range(0,3)])\n",
        "transacoes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-r0kO17-aRC",
        "outputId": "6731fc46-1673-48c9-8182-0091d6c1a9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Cerveja', 'Pizza', 'Sorvete'],\n",
              " ['Pizza', 'Sorvete', 'nan'],\n",
              " ['Cerveja', 'Pizza', 'nan'],\n",
              " ['Cerveja', 'Pizza', 'Sorvete'],\n",
              " ['Cerveja', 'Pizza', 'nan'],\n",
              " ['Pizza', 'nan', 'nan']]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Execução do algoritmo apriori para geração das regras de associação, definindo os parâmetros de suporte e confiança\n",
        "regras = apriori(transacoes, min_support = 0.5, min_confidence = 0.5,min_length=2) #valores dependem dos dados"
      ],
      "metadata": {
        "id": "ZfS4gind-gE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação de nova variável para armazenar somente as regras de associação\n",
        "resultados = list(regras)\n",
        "print(resultados[0])\n",
        "resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QF6vZY2-noG",
        "outputId": "be8fadc7-b454-43ba-ecb0-caf8a5184950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RelationRecord(items=frozenset({'Cerveja'}), support=0.6666666666666666, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Cerveja'}), confidence=0.6666666666666666, lift=1.0)])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[RelationRecord(items=frozenset({'Cerveja'}), support=0.6666666666666666, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Cerveja'}), confidence=0.6666666666666666, lift=1.0)]),\n",
              " RelationRecord(items=frozenset({'Pizza'}), support=1.0, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Pizza'}), confidence=1.0, lift=1.0)]),\n",
              " RelationRecord(items=frozenset({'Sorvete'}), support=0.5, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Sorvete'}), confidence=0.5, lift=1.0)]),\n",
              " RelationRecord(items=frozenset({'nan'}), support=0.6666666666666666, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'nan'}), confidence=0.6666666666666666, lift=1.0)]),\n",
              " RelationRecord(items=frozenset({'Pizza', 'Cerveja'}), support=0.6666666666666666, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Pizza', 'Cerveja'}), confidence=0.6666666666666666, lift=1.0), OrderedStatistic(items_base=frozenset({'Cerveja'}), items_add=frozenset({'Pizza'}), confidence=1.0, lift=1.0), OrderedStatistic(items_base=frozenset({'Pizza'}), items_add=frozenset({'Cerveja'}), confidence=0.6666666666666666, lift=1.0)]),\n",
              " RelationRecord(items=frozenset({'Pizza', 'Sorvete'}), support=0.5, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Pizza', 'Sorvete'}), confidence=0.5, lift=1.0), OrderedStatistic(items_base=frozenset({'Pizza'}), items_add=frozenset({'Sorvete'}), confidence=0.5, lift=1.0), OrderedStatistic(items_base=frozenset({'Sorvete'}), items_add=frozenset({'Pizza'}), confidence=1.0, lift=1.0)]),\n",
              " RelationRecord(items=frozenset({'Pizza', 'nan'}), support=0.6666666666666666, ordered_statistics=[OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Pizza', 'nan'}), confidence=0.6666666666666666, lift=1.0), OrderedStatistic(items_base=frozenset({'Pizza'}), items_add=frozenset({'nan'}), confidence=0.6666666666666666, lift=1.0), OrderedStatistic(items_base=frozenset({'nan'}), items_add=frozenset({'Pizza'}), confidence=1.0, lift=1.0)])]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação de nova variável, percorrendo a variável anterior para uma melhor visualização dos resultados\n",
        "resultados2 = [list(x) for x in resultados]\n",
        "resultados2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaCDlcrE-vn_",
        "outputId": "14abdbbe-daea-433a-d368-8def0c87134b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[frozenset({'Cerveja'}),\n",
              "  0.6666666666666666,\n",
              "  [OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Cerveja'}), confidence=0.6666666666666666, lift=1.0)]],\n",
              " [frozenset({'Pizza'}),\n",
              "  1.0,\n",
              "  [OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Pizza'}), confidence=1.0, lift=1.0)]],\n",
              " [frozenset({'Sorvete'}),\n",
              "  0.5,\n",
              "  [OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Sorvete'}), confidence=0.5, lift=1.0)]],\n",
              " [frozenset({'nan'}),\n",
              "  0.6666666666666666,\n",
              "  [OrderedStatistic(items_base=frozenset(), items_add=frozenset({'nan'}), confidence=0.6666666666666666, lift=1.0)]],\n",
              " [frozenset({'Cerveja', 'Pizza'}),\n",
              "  0.6666666666666666,\n",
              "  [OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Pizza', 'Cerveja'}), confidence=0.6666666666666666, lift=1.0),\n",
              "   OrderedStatistic(items_base=frozenset({'Cerveja'}), items_add=frozenset({'Pizza'}), confidence=1.0, lift=1.0),\n",
              "   OrderedStatistic(items_base=frozenset({'Pizza'}), items_add=frozenset({'Cerveja'}), confidence=0.6666666666666666, lift=1.0)]],\n",
              " [frozenset({'Pizza', 'Sorvete'}),\n",
              "  0.5,\n",
              "  [OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Pizza', 'Sorvete'}), confidence=0.5, lift=1.0),\n",
              "   OrderedStatistic(items_base=frozenset({'Pizza'}), items_add=frozenset({'Sorvete'}), confidence=0.5, lift=1.0),\n",
              "   OrderedStatistic(items_base=frozenset({'Sorvete'}), items_add=frozenset({'Pizza'}), confidence=1.0, lift=1.0)]],\n",
              " [frozenset({'Pizza', 'nan'}),\n",
              "  0.6666666666666666,\n",
              "  [OrderedStatistic(items_base=frozenset(), items_add=frozenset({'Pizza', 'nan'}), confidence=0.6666666666666666, lift=1.0),\n",
              "   OrderedStatistic(items_base=frozenset({'Pizza'}), items_add=frozenset({'nan'}), confidence=0.6666666666666666, lift=1.0),\n",
              "   OrderedStatistic(items_base=frozenset({'nan'}), items_add=frozenset({'Pizza'}), confidence=1.0, lift=1.0)]]]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação de outra variável para a visualização das regras ficar mais fácil para o usuário, adicionando as regras encontradas na variável resultados2\n",
        "resultados3 = []\n",
        "for j in range(0,7):\n",
        "    resultados3.append([list(x) for x in resultados2[j][2]])\n",
        "resultados3 #aq vemos confianca e lift "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN9lx-x-AAoG",
        "outputId": "e140e9f0-cf2c-4649-be88-3ab2b3026516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[frozenset(), frozenset({'Cerveja'}), 0.6666666666666666, 1.0]],\n",
              " [[frozenset(), frozenset({'Pizza'}), 1.0, 1.0]],\n",
              " [[frozenset(), frozenset({'Sorvete'}), 0.5, 1.0]],\n",
              " [[frozenset(), frozenset({'nan'}), 0.6666666666666666, 1.0]],\n",
              " [[frozenset(), frozenset({'Cerveja', 'Pizza'}), 0.6666666666666666, 1.0],\n",
              "  [frozenset({'Cerveja'}), frozenset({'Pizza'}), 1.0, 1.0],\n",
              "  [frozenset({'Pizza'}), frozenset({'Cerveja'}), 0.6666666666666666, 1.0]],\n",
              " [[frozenset(), frozenset({'Pizza', 'Sorvete'}), 0.5, 1.0],\n",
              "  [frozenset({'Pizza'}), frozenset({'Sorvete'}), 0.5, 1.0],\n",
              "  [frozenset({'Sorvete'}), frozenset({'Pizza'}), 1.0, 1.0]],\n",
              " [[frozenset(), frozenset({'Pizza', 'nan'}), 0.6666666666666666, 1.0],\n",
              "  [frozenset({'Pizza'}), frozenset({'nan'}), 0.6666666666666666, 1.0],\n",
              "  [frozenset({'nan'}), frozenset({'Pizza'}), 1.0, 1.0]]]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ECAT associador q mostra a frequencia dos itens"
      ],
      "metadata": {
        "id": "uZ3-l2GLByrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função pronta para o algoritmo ECLAT (atualmente o algoritmo não está disponível em uma biblioteca)\n",
        "import os;\n",
        "import sys;\n",
        "import numpy as np;\n",
        "import datetime as dt;\n",
        "from numpy import linalg as LA;\n",
        "import optparse;\n",
        "import argparse;"
      ],
      "metadata": {
        "id": "hxkfb0yaB0_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variable \n",
        "#containing all frequent patterns with its tid's\n",
        "F =[];\n",
        "# Time calculation\n",
        "#start_time =0;\n",
        "#end_time=0;\n",
        "\n",
        "# Pattern class:\n",
        "class Pattern:\n",
        "\tdef __init__(self, item, tids):\n",
        "\t\t# list of item Id's in the pattern\n",
        "\t\tself.item_id = item;\n",
        "\t\t# tid of the pattern\n",
        "\t\tself.tid_list = tids;\n",
        "\n",
        "\t# union operation of item Id's for two patterns to get ID of candidate pattern\n",
        "\tdef \tunion_id(self,next_node):\n",
        "\t\tt = set(self.item_id);\n",
        "\t\ttt = set(next_node.item_id);\n",
        "\t\tnew = t | tt;\n",
        "\t\tnew_id = list(new);\n",
        "\t\tnew_id.sort();\n",
        "\t\treturn new_id;\n",
        "\n",
        "    # intersection of tid's of two patterns to find tid of candidate pattern\n",
        "\tdef \tintersec_tid_list(self,next_node):\n",
        "\t\tt = set(self.tid_list);\n",
        "\t\ttt = set(next_node.tid_list);\n",
        "\t\tnew = t & tt;\n",
        "\t\tnew_list = list(new);\n",
        "\t\tnew_list.sort();\n",
        "\t\treturn new_list;\n",
        "\t\n",
        "\t# returns support value for the pattern\n",
        "\tdef\tgetSup(self):\n",
        "\t\treturn len(self.tid_list);\n",
        "\t\n",
        "\t\n",
        "#\tdef\tcompare(self,n):\n",
        "#\t\tif self.item_id == n.item_id:\n",
        "#\t\t\treturn 1;\n",
        "#\t\treturn 0;\n",
        "\n",
        "\t#Candidate generation & check for support\t\n",
        "\tdef\tgenerate_check(self, n , minsup):\n",
        "\t\t\n",
        "\t\t# generating tid_list first\n",
        "\t\ttemp_tid_list = self.intersec_tid_list(n);\n",
        "\t\t\n",
        "\t\t# if support for new candidate is >= minsup then only generate ID for that candidate\t\t\n",
        "\t\tif len(temp_tid_list) >= minsup:\n",
        "\t\t\ttemp_id = self.union_id(n);\n",
        "\t\t\treturn (temp_id,temp_tid_list);\n",
        "\t\telse:\n",
        "\t\t\treturn ([],[]);\n",
        "\tdef\tpattern_print(self):\n",
        "\t\tpattern_ID = str(\"\");\n",
        "\t\tfor i in self.item_id:\n",
        "\t\t\tpattern_ID = pattern_ID + str(i) + ' ';\n",
        "\t\tprint(pattern_ID + '\\t\\t : ' + str(self.tid_list)); \n",
        "\t\t\t\n",
        "#End of Pattern class"
      ],
      "metadata": {
        "id": "9PFg7447B3Yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pattern Store class:\n",
        "class PatternStore:\n",
        "\tdef \t__init__(self):\n",
        "\t\tself.Pattern_list = [];\n",
        "\t\n",
        "\t# Add a whole group of pattern to the list\n",
        "\tdef\taddGroup(self,list_nodes):\n",
        "\t\tfor n in list_nodes:\n",
        "\t\t\tself.Pattern_list.append(n);\n",
        "\n",
        "\t# Retursn i_th pattern from the list if available\n",
        "\tdef\tgetNode(self,index):\n",
        "\t\tif index < len(self.Pattern_list):\n",
        "\t\t\treturn self.Pattern_list[index];\n",
        "\t\telse:\n",
        "\t\t\treturn [];\n",
        "\t\n",
        "\t# To Fallow DFS method: Recursive function is used - to calculate all frequent patterns from the 1st level frequent list\n",
        "\tdef \tEclat(self,minsup):\n",
        "\t\tfor node in self.Pattern_list:\n",
        "\t\t\tF.append(node);\n",
        "\t\t\tnew_P = PatternStore();\n",
        "\t\t\t# As all patterns are sorted initially get only next pattern from the current\n",
        "\t\t\tindex = self.Pattern_list.index(node);\n",
        "\t\t\ti = index +1;\n",
        "\t\t\tn = self.getNode(i);\n",
        "\t\t\t\n",
        "\t\t\twhile n:\n",
        "\t\t\t\t# Here I am doing 2 steps togather: 1- candidate generation & 2- checking for minsup\n",
        "\t\t\t\t(temp_id,temp_tid_list) = node.generate_check(n,minsup);\n",
        "\t\t\t\t# if temp_id is not empty\t\t\t\t\n",
        "\t\t\t\tif temp_id:\t\t\t\t\n",
        "\t\t\t\t\tnew_P.Pattern_list.append(Pattern(temp_id,temp_tid_list));\n",
        "\t\t\t\ti = i +1;\n",
        "\t\t\t\t# get next node from the list\n",
        "\t\t\t\tn = self.getNode(i);\n",
        "\t\t\t# if any possible pattern child go to child first, DFS\n",
        "\t\t\tif new_P.Pattern_list:\n",
        "\t\t\t\tnew_P.Eclat(minsup);\n",
        "\n",
        "#End of PatternStore class"
      ],
      "metadata": {
        "id": "fffuVOkHB8b6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DBReader:\n",
        "\n",
        "\tdef\t__init__(self,filetoread):\n",
        "\t\tself.file_id = filetoread;\n",
        "\tdef\treadFile(self):\n",
        "\t\t# stores each transaction\n",
        "\t\tself.trans=[];\n",
        "\t\t# stores no of items in each tansaction\n",
        "\t\tself.no_items = [];\n",
        "\t\tfor\tline\tin\tself.file_id:\n",
        "\t\t\ttuplex=line.split(\" \");\n",
        "\t\t\tmylist=[];\n",
        "\t\t\tself.no_items.append(tuplex[0]);\n",
        "\t\t\tfor\tposition\tin\trange(1,len(tuplex)):\n",
        "\t\t\t\tmylist.append(tuplex[position]);\t\n",
        "\t\n",
        "\t\t\tself.trans.append(mylist);\n",
        "\n",
        "\t# From transactions: generate patterns and prepare a list\n",
        "\tdef\tgenPatternList(self):\n",
        "\t\t#all items\n",
        "\t\ttemp = [item for sublist in self.trans for item in sublist];\n",
        "\n",
        "\t\t#removing duplicates\n",
        "\t\tmy_set = set(temp)\n",
        "\t\tself.items = list(my_set)\n",
        "\n",
        "\t\t#put in sorted oirder\n",
        "\t\tself.items.sort();\n",
        "\t\t\n",
        "\t\t# generate level_1 pattern list\n",
        "\t\tself.level_1 = [];\n",
        "\n",
        "\t\t# Start the timmer as candidate generation for level 1 is a part of Eclat algorithm.\n",
        "\t\tstart_time = dt.datetime.now();\t\t\n",
        "\t\t\n",
        "\t\t#generate all candidates for level 1\n",
        "\t\tfor it in self.items:\n",
        "\t\t\titem = [];\n",
        "\t\t\titem.append(it)\n",
        "\t\t\tself.level_1.append(Pattern(item,[]));\t\n",
        "\t\t\n",
        "\t\t# generate tid_list for every items in level 1 \n",
        "\t\ti=0;\n",
        "\t\tfor t in self.trans:\n",
        "\t\t\ti = i + 1;\n",
        "\t\t\tt.sort();\n",
        "\t\t\tfor it_id in t:\n",
        "\t\t\t\tindex = self.items.index(it_id);\n",
        "\t\t\t\tself.level_1[index].tid_list.append(i);\n",
        "\t\n",
        "\t\treturn start_time;\n",
        "\n",
        "\t# returns frequent patterns\n",
        "\tdef\tgetFrequent(self,minsup):\n",
        "\t\tself.P = [];\n",
        "\t\tfor n in self.level_1:\n",
        "\t\t\tc = int(n.getSup());\n",
        "\t\t\tif  c >= minsup:\n",
        "\t\t\t\t#print c;\n",
        "\t\t\t\tself.P.append(n);\n",
        "\t\treturn self.P;\n",
        "\n",
        "#End of DBReader class"
      ],
      "metadata": {
        "id": "c_a6M-9MCXOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(file, support):\n",
        "\t#printing flag\n",
        "\tp_flag = 1;\n",
        "\n",
        "\t#parser = optparse.OptionParser(\"usage: %prog [options] arg1 arg2\")\n",
        "\t#parser.add_option(\"-f\",  dest=\"filename\", default=\"data.txt\", type=\"string\", help=\"specify filename to run on\");\n",
        "\t#parser.add_option(\"-s\",  dest=\"supnum\", default=0, type=\"int\", help=\"give minimun support to run on\");\n",
        "\t#parser.add_option(\"-p\",  dest=\"p\", default=1, type=\"int\");\n",
        "\t#(options, args) = parser.parse_args();\n",
        "\n",
        "\tparser = argparse.ArgumentParser();\n",
        "\tparser.add_argument(\"-f\",\"--filename\");\n",
        "\tparser.add_argument(\"-s\",\"--supnum\", type=int);\n",
        "\tparser.add_argument(\"-p\", \"--print_flag\", action=\"store_true\");\n",
        "\targs = parser.parse_args();\n",
        "\t\n",
        " \n",
        "\t#if\tlen(sys.argv) < 3:\n",
        "\t#\tprint('Please give me the filename &  minimum support value'+os.linesep);\n",
        "\t#\tsys.exit(1);\n",
        "\ttry:\t\n",
        "\t\t#file name\n",
        "\t\tf_name = file;\n",
        "\t\tfileToRead=open(f_name);\n",
        "\t\t#fileToRead = open(\"data.txt\");\n",
        "\t\t#Minimum Spport vlaue\t\n",
        "\t\tminsup = support;\n",
        "\t\t# printing flag \n",
        "\t\tif args.print_flag:\n",
        "\t\t\tp_flag = 1;\t\n",
        "\texcept(IOError,IndexError):\n",
        "\t\tprint('Bad file name'+os.linesep);\n",
        "\t\tsys.exit(1);\n",
        "\n",
        "\t\n",
        "\tprint('minsup = '+str(minsup));\n",
        "\n",
        "\t#minsup = 2;\n",
        "\n",
        "\t# DBReader object\n",
        "\treader = DBReader(fileToRead);\n",
        "\t#reading the file\n",
        "\treader.readFile();\n",
        "\t# Pattern generation for level 1 - It will return the starting time from when candidate generation is started.\t\n",
        "\tstart_time = reader.genPatternList();\n",
        "\t#print\n",
        "\t\n",
        "\t# Get frequent patterns from all candidates of level 1:\n",
        "\tlevel1_P = reader.getFrequent(minsup)\n",
        "\n",
        "\t#for n in level1_P:\n",
        "\t#\tprint n.item_id;\n",
        "\t#\tprint n.tid_list;\n",
        "\n",
        "\t#correct\n",
        "\n",
        "\t# Create Pattern Store object\n",
        "\tPttStr = PatternStore();\n",
        "\t\n",
        "\t# Add frequent patterns from level 1\n",
        "\tPttStr.addGroup(level1_P);\n",
        "\n",
        "\t# Eclat Algorithm\n",
        "\tPttStr.Eclat(minsup);\n",
        "\t\n",
        "\tend_time = dt.datetime.now();\n",
        "\t\n",
        "\t#print start_time;\n",
        "\t#print end_time;\n",
        "\t\t\n",
        "\ttime = end_time - start_time;\n",
        "\t\n",
        "\tprint('Computation time = '+ str(time.total_seconds()) + ' Seconds');\n",
        "\t\n",
        "\tif p_flag == 1:\n",
        "\t\tprint('Pattern\\t\\t : Tid_List');\t\n",
        "\t\tfor n in F:\n",
        "\t\t\tn.pattern_print();\n",
        "\n",
        "#End of main function"
      ],
      "metadata": {
        "id": "SB1zbi4wCZN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Geração dos itens frequentes, APRESENTANDO ERRO\n",
        "#if\t__name__== \"__main__\":\n",
        "\t#main('transacoes2.txt', 3);"
      ],
      "metadata": {
        "id": "8qFndFyeCgeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13/01 deep learning"
      ],
      "metadata": {
        "id": "mofc2wdcxws3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "#keras faz absorcaco de frameworks de deep learning"
      ],
      "metadata": {
        "id": "9EOXTFVYx0qM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base=datasets.load_iris() #carregando dados\n",
        "previsoresrn=base.data\n",
        "classern=base.target #separando especies ==3, das caracteristicas(previsores)\n",
        "classern"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P8G1W2Q0EwO",
        "outputId": "d210ccc1-6aff-459e-d39c-857beeda9640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classe_dummy= np_utils.to_categorical(classern) #valores se tornam colunas, devido estrutura cada rn tera 3 neuronios na classe de saida\n",
        "classe_dummy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQz4WmEJ0aJT",
        "outputId": "0fdbb83e-148c-4699-e3af-83407a9dc25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# divisao entre treino e teste, tem q passar a classe dummy aq\n",
        "X_treinorn, X_testern, y_treinorn, y_testern = train_test_split(previsoresrn,\n",
        "                                                                  classe_dummy,\n",
        "                                                                  test_size = 0.3,\n",
        "                                                                  random_state = 0)"
      ],
      "metadata": {
        "id": "QjGtkyMc0tzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação da estrutura da rede neural com a classe Sequential (sequência de camadas),camadas incluidas uma apos a outra\n",
        "modelo = Sequential()\n",
        "#primeira camada oculta, 5 neuronios, 4 neuronios de entrada, do tipo dense elas tem que ser conectadas uma as outras\n",
        "modelo.add(Dense(units = 5, input_dim = 4))#4 pois tinham 4 var's indep no conjunto iris, units pode alterar\n",
        "#segunda camada oculta\n",
        "modelo.add(Dense(units = 4)) #ñ usa input_im pq ñ é 1 camada\n",
        "# Função softmax porque temos um problema de classificação com mais de duas classes \n",
        "#(é gerada uma probabilidade em cada neurônio)\n",
        "modelo.add(Dense(units = 3, activation = 'softmax')) #softmax pra saida ser em prob"
      ],
      "metadata": {
        "id": "dNXqNJ8s1JAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização da estrutura da rede neural\n",
        "modelo.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6dbrfYs3cbo",
        "outputId": "6146d264-11ec-4cf8-8aa0-2c32af5da84c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 5)                 25        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 24        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 15        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64\n",
            "Trainable params: 64\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração dos parâmetros da rede neural (adam = algoritmo para atualizar os pesos e loss = cálculo do erro)\n",
        "modelo.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy']) #metrica mede erro \n",
        "# Treinamento, dividindo a base de treinamento em uma porção para validação (validation_data)\n",
        "modelo.fit(X_treinorn, y_treinorn, epochs = 1000,\n",
        "           validation_data = (X_testern, y_testern))#passa dados de treino e o teste na rn (treino 70% das vars indep)\n",
        "           #epoch mostra a validacao com o treino e com o test( 4 col esq pra dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2FK-MCI3gCD",
        "outputId": "5d1d20ee-58d8-4c75-e1e3-9c20cd4e93e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "4/4 [==============================] - 1s 72ms/step - loss: 6.5753 - accuracy: 0.3714 - val_loss: 7.7966 - val_accuracy: 0.2444\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 6.2769 - accuracy: 0.3714 - val_loss: 7.4413 - val_accuracy: 0.2444\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 5.9920 - accuracy: 0.3714 - val_loss: 7.0878 - val_accuracy: 0.2444\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.6985 - accuracy: 0.3714 - val_loss: 6.7429 - val_accuracy: 0.2444\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 5.4293 - accuracy: 0.3714 - val_loss: 6.3999 - val_accuracy: 0.2444\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 5.1472 - accuracy: 0.3714 - val_loss: 6.0684 - val_accuracy: 0.2444\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 4.8820 - accuracy: 0.3714 - val_loss: 5.7382 - val_accuracy: 0.2444\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4.6186 - accuracy: 0.3714 - val_loss: 5.4128 - val_accuracy: 0.2444\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 4.3508 - accuracy: 0.3714 - val_loss: 5.0932 - val_accuracy: 0.2444\n",
            "Epoch 10/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 4.0935 - accuracy: 0.3714 - val_loss: 4.7797 - val_accuracy: 0.2444\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.8406 - accuracy: 0.3714 - val_loss: 4.4759 - val_accuracy: 0.2444\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.5892 - accuracy: 0.3714 - val_loss: 4.1797 - val_accuracy: 0.2444\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 3.3556 - accuracy: 0.3714 - val_loss: 3.8819 - val_accuracy: 0.2444\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 3.1118 - accuracy: 0.3714 - val_loss: 3.5970 - val_accuracy: 0.2444\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 2.8842 - accuracy: 0.3714 - val_loss: 3.3280 - val_accuracy: 0.2444\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.6698 - accuracy: 0.3714 - val_loss: 3.0828 - val_accuracy: 0.2444\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.4876 - accuracy: 0.3714 - val_loss: 2.8693 - val_accuracy: 0.2444\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.3321 - accuracy: 0.3714 - val_loss: 2.6931 - val_accuracy: 0.2444\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.2099 - accuracy: 0.3714 - val_loss: 2.5527 - val_accuracy: 0.2222\n",
            "Epoch 20/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 2.1256 - accuracy: 0.3524 - val_loss: 2.4425 - val_accuracy: 0.1556\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 2.0552 - accuracy: 0.2476 - val_loss: 2.3501 - val_accuracy: 0.1111\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 1.9980 - accuracy: 0.2095 - val_loss: 2.2657 - val_accuracy: 0.1111\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.9393 - accuracy: 0.2000 - val_loss: 2.1861 - val_accuracy: 0.1111\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.8793 - accuracy: 0.2000 - val_loss: 2.1119 - val_accuracy: 0.1111\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.8220 - accuracy: 0.2190 - val_loss: 2.0431 - val_accuracy: 0.1111\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.7656 - accuracy: 0.2286 - val_loss: 1.9791 - val_accuracy: 0.1333\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.7152 - accuracy: 0.2762 - val_loss: 1.9180 - val_accuracy: 0.1556\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6674 - accuracy: 0.2952 - val_loss: 1.8590 - val_accuracy: 0.1556\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.6251 - accuracy: 0.3048 - val_loss: 1.8006 - val_accuracy: 0.1556\n",
            "Epoch 30/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.5794 - accuracy: 0.3143 - val_loss: 1.7507 - val_accuracy: 0.2000\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1.5421 - accuracy: 0.3429 - val_loss: 1.7053 - val_accuracy: 0.2000\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.5090 - accuracy: 0.3429 - val_loss: 1.6624 - val_accuracy: 0.2222\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4760 - accuracy: 0.3429 - val_loss: 1.6260 - val_accuracy: 0.2222\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.4497 - accuracy: 0.3619 - val_loss: 1.5934 - val_accuracy: 0.2222\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.4257 - accuracy: 0.3619 - val_loss: 1.5623 - val_accuracy: 0.2222\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.4014 - accuracy: 0.3619 - val_loss: 1.5321 - val_accuracy: 0.2222\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.3815 - accuracy: 0.3619 - val_loss: 1.4990 - val_accuracy: 0.2222\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.3599 - accuracy: 0.3619 - val_loss: 1.4709 - val_accuracy: 0.2222\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 1.3428 - accuracy: 0.3619 - val_loss: 1.4429 - val_accuracy: 0.2222\n",
            "Epoch 40/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.3244 - accuracy: 0.3619 - val_loss: 1.4175 - val_accuracy: 0.2222\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 1.3095 - accuracy: 0.3619 - val_loss: 1.3923 - val_accuracy: 0.2222\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2964 - accuracy: 0.3429 - val_loss: 1.3722 - val_accuracy: 0.2222\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2834 - accuracy: 0.3429 - val_loss: 1.3568 - val_accuracy: 0.2222\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2718 - accuracy: 0.3524 - val_loss: 1.3427 - val_accuracy: 0.2222\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2612 - accuracy: 0.3619 - val_loss: 1.3281 - val_accuracy: 0.2222\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2504 - accuracy: 0.3619 - val_loss: 1.3167 - val_accuracy: 0.2222\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2400 - accuracy: 0.3619 - val_loss: 1.3062 - val_accuracy: 0.2222\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2305 - accuracy: 0.3619 - val_loss: 1.2934 - val_accuracy: 0.2222\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 1.2200 - accuracy: 0.3619 - val_loss: 1.2828 - val_accuracy: 0.2222\n",
            "Epoch 50/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2122 - accuracy: 0.3619 - val_loss: 1.2696 - val_accuracy: 0.2222\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.2012 - accuracy: 0.3619 - val_loss: 1.2596 - val_accuracy: 0.2222\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1919 - accuracy: 0.3619 - val_loss: 1.2536 - val_accuracy: 0.2444\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1825 - accuracy: 0.3619 - val_loss: 1.2472 - val_accuracy: 0.2444\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1745 - accuracy: 0.3619 - val_loss: 1.2418 - val_accuracy: 0.2444\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1664 - accuracy: 0.3619 - val_loss: 1.2348 - val_accuracy: 0.2444\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1581 - accuracy: 0.3714 - val_loss: 1.2275 - val_accuracy: 0.2444\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1499 - accuracy: 0.3714 - val_loss: 1.2175 - val_accuracy: 0.2444\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1406 - accuracy: 0.3714 - val_loss: 1.2062 - val_accuracy: 0.2444\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.1314 - accuracy: 0.3714 - val_loss: 1.1940 - val_accuracy: 0.2444\n",
            "Epoch 60/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1230 - accuracy: 0.3619 - val_loss: 1.1819 - val_accuracy: 0.2444\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.1142 - accuracy: 0.3619 - val_loss: 1.1703 - val_accuracy: 0.2444\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.1068 - accuracy: 0.3619 - val_loss: 1.1573 - val_accuracy: 0.2444\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0994 - accuracy: 0.3619 - val_loss: 1.1465 - val_accuracy: 0.2444\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0920 - accuracy: 0.3619 - val_loss: 1.1366 - val_accuracy: 0.2444\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0845 - accuracy: 0.3619 - val_loss: 1.1299 - val_accuracy: 0.2444\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0770 - accuracy: 0.3619 - val_loss: 1.1241 - val_accuracy: 0.2667\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0687 - accuracy: 0.3619 - val_loss: 1.1163 - val_accuracy: 0.2444\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0606 - accuracy: 0.3619 - val_loss: 1.1097 - val_accuracy: 0.2444\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0533 - accuracy: 0.3619 - val_loss: 1.1052 - val_accuracy: 0.2444\n",
            "Epoch 70/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0462 - accuracy: 0.3714 - val_loss: 1.1005 - val_accuracy: 0.2444\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0383 - accuracy: 0.3714 - val_loss: 1.0923 - val_accuracy: 0.2444\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0314 - accuracy: 0.3714 - val_loss: 1.0853 - val_accuracy: 0.2444\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0248 - accuracy: 0.3714 - val_loss: 1.0778 - val_accuracy: 0.2444\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 1.0184 - accuracy: 0.3714 - val_loss: 1.0679 - val_accuracy: 0.2667\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 1.0125 - accuracy: 0.3714 - val_loss: 1.0590 - val_accuracy: 0.2667\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 1.0052 - accuracy: 0.3714 - val_loss: 1.0542 - val_accuracy: 0.2667\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9987 - accuracy: 0.3714 - val_loss: 1.0513 - val_accuracy: 0.2444\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.9920 - accuracy: 0.3714 - val_loss: 1.0508 - val_accuracy: 0.2444\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9861 - accuracy: 0.3714 - val_loss: 1.0478 - val_accuracy: 0.2444\n",
            "Epoch 80/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9805 - accuracy: 0.3810 - val_loss: 1.0434 - val_accuracy: 0.2667\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9732 - accuracy: 0.3905 - val_loss: 1.0345 - val_accuracy: 0.3111\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9651 - accuracy: 0.4095 - val_loss: 1.0252 - val_accuracy: 0.3333\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9592 - accuracy: 0.4571 - val_loss: 1.0155 - val_accuracy: 0.3778\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.9517 - accuracy: 0.4952 - val_loss: 1.0044 - val_accuracy: 0.4000\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9463 - accuracy: 0.5143 - val_loss: 0.9942 - val_accuracy: 0.4222\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9409 - accuracy: 0.5429 - val_loss: 0.9855 - val_accuracy: 0.4667\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9351 - accuracy: 0.5524 - val_loss: 0.9782 - val_accuracy: 0.4889\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9289 - accuracy: 0.5429 - val_loss: 0.9723 - val_accuracy: 0.4667\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.9228 - accuracy: 0.5429 - val_loss: 0.9657 - val_accuracy: 0.4444\n",
            "Epoch 90/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9170 - accuracy: 0.5429 - val_loss: 0.9605 - val_accuracy: 0.4444\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9108 - accuracy: 0.5429 - val_loss: 0.9582 - val_accuracy: 0.4667\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.9033 - accuracy: 0.5619 - val_loss: 0.9543 - val_accuracy: 0.5556\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8968 - accuracy: 0.5905 - val_loss: 0.9512 - val_accuracy: 0.5556\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.8905 - accuracy: 0.6095 - val_loss: 0.9500 - val_accuracy: 0.5778\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8857 - accuracy: 0.6095 - val_loss: 0.9497 - val_accuracy: 0.5778\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8796 - accuracy: 0.6286 - val_loss: 0.9460 - val_accuracy: 0.6000\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8739 - accuracy: 0.6667 - val_loss: 0.9403 - val_accuracy: 0.6000\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8681 - accuracy: 0.6667 - val_loss: 0.9336 - val_accuracy: 0.6000\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8624 - accuracy: 0.6762 - val_loss: 0.9264 - val_accuracy: 0.6000\n",
            "Epoch 100/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8565 - accuracy: 0.6762 - val_loss: 0.9169 - val_accuracy: 0.6000\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8501 - accuracy: 0.6857 - val_loss: 0.9075 - val_accuracy: 0.6000\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8457 - accuracy: 0.6857 - val_loss: 0.8973 - val_accuracy: 0.6000\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8401 - accuracy: 0.6857 - val_loss: 0.8905 - val_accuracy: 0.6000\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8350 - accuracy: 0.6857 - val_loss: 0.8846 - val_accuracy: 0.6000\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8294 - accuracy: 0.6857 - val_loss: 0.8817 - val_accuracy: 0.6000\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8234 - accuracy: 0.6857 - val_loss: 0.8782 - val_accuracy: 0.6000\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8176 - accuracy: 0.6857 - val_loss: 0.8741 - val_accuracy: 0.6000\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.8124 - accuracy: 0.6857 - val_loss: 0.8722 - val_accuracy: 0.6000\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.8070 - accuracy: 0.6857 - val_loss: 0.8697 - val_accuracy: 0.6000\n",
            "Epoch 110/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.8024 - accuracy: 0.6857 - val_loss: 0.8665 - val_accuracy: 0.6000\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7978 - accuracy: 0.6857 - val_loss: 0.8639 - val_accuracy: 0.6000\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7927 - accuracy: 0.6857 - val_loss: 0.8600 - val_accuracy: 0.6000\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7880 - accuracy: 0.6857 - val_loss: 0.8551 - val_accuracy: 0.6000\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7829 - accuracy: 0.6952 - val_loss: 0.8492 - val_accuracy: 0.6000\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7769 - accuracy: 0.6952 - val_loss: 0.8403 - val_accuracy: 0.6000\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7714 - accuracy: 0.6952 - val_loss: 0.8326 - val_accuracy: 0.6000\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7663 - accuracy: 0.6952 - val_loss: 0.8242 - val_accuracy: 0.6000\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7620 - accuracy: 0.6952 - val_loss: 0.8150 - val_accuracy: 0.6000\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7567 - accuracy: 0.6952 - val_loss: 0.8080 - val_accuracy: 0.6000\n",
            "Epoch 120/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7521 - accuracy: 0.6952 - val_loss: 0.8016 - val_accuracy: 0.6000\n",
            "Epoch 121/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7475 - accuracy: 0.6952 - val_loss: 0.7957 - val_accuracy: 0.6000\n",
            "Epoch 122/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7430 - accuracy: 0.6952 - val_loss: 0.7915 - val_accuracy: 0.6000\n",
            "Epoch 123/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7369 - accuracy: 0.6952 - val_loss: 0.7899 - val_accuracy: 0.6000\n",
            "Epoch 124/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.7326 - accuracy: 0.6952 - val_loss: 0.7903 - val_accuracy: 0.6000\n",
            "Epoch 125/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7281 - accuracy: 0.6952 - val_loss: 0.7899 - val_accuracy: 0.6000\n",
            "Epoch 126/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7230 - accuracy: 0.6952 - val_loss: 0.7860 - val_accuracy: 0.6000\n",
            "Epoch 127/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7188 - accuracy: 0.6952 - val_loss: 0.7821 - val_accuracy: 0.6000\n",
            "Epoch 128/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.7147 - accuracy: 0.6952 - val_loss: 0.7741 - val_accuracy: 0.6000\n",
            "Epoch 129/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7094 - accuracy: 0.6952 - val_loss: 0.7681 - val_accuracy: 0.6000\n",
            "Epoch 130/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.7046 - accuracy: 0.6952 - val_loss: 0.7642 - val_accuracy: 0.6000\n",
            "Epoch 131/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.7004 - accuracy: 0.6952 - val_loss: 0.7584 - val_accuracy: 0.6000\n",
            "Epoch 132/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6958 - accuracy: 0.6952 - val_loss: 0.7554 - val_accuracy: 0.6000\n",
            "Epoch 133/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6912 - accuracy: 0.6952 - val_loss: 0.7507 - val_accuracy: 0.6000\n",
            "Epoch 134/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6872 - accuracy: 0.6952 - val_loss: 0.7473 - val_accuracy: 0.6000\n",
            "Epoch 135/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6829 - accuracy: 0.6952 - val_loss: 0.7424 - val_accuracy: 0.6000\n",
            "Epoch 136/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6785 - accuracy: 0.6952 - val_loss: 0.7380 - val_accuracy: 0.6000\n",
            "Epoch 137/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6741 - accuracy: 0.6952 - val_loss: 0.7335 - val_accuracy: 0.6000\n",
            "Epoch 138/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6698 - accuracy: 0.6952 - val_loss: 0.7285 - val_accuracy: 0.6000\n",
            "Epoch 139/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6656 - accuracy: 0.6952 - val_loss: 0.7218 - val_accuracy: 0.6000\n",
            "Epoch 140/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6617 - accuracy: 0.6952 - val_loss: 0.7147 - val_accuracy: 0.6000\n",
            "Epoch 141/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6574 - accuracy: 0.7048 - val_loss: 0.7067 - val_accuracy: 0.6000\n",
            "Epoch 142/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6536 - accuracy: 0.7143 - val_loss: 0.6994 - val_accuracy: 0.6000\n",
            "Epoch 143/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6492 - accuracy: 0.7238 - val_loss: 0.6943 - val_accuracy: 0.6000\n",
            "Epoch 144/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6453 - accuracy: 0.7238 - val_loss: 0.6890 - val_accuracy: 0.6222\n",
            "Epoch 145/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6411 - accuracy: 0.7238 - val_loss: 0.6852 - val_accuracy: 0.6000\n",
            "Epoch 146/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6369 - accuracy: 0.7238 - val_loss: 0.6820 - val_accuracy: 0.6000\n",
            "Epoch 147/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6330 - accuracy: 0.7238 - val_loss: 0.6794 - val_accuracy: 0.6000\n",
            "Epoch 148/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6291 - accuracy: 0.7238 - val_loss: 0.6774 - val_accuracy: 0.6000\n",
            "Epoch 149/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6255 - accuracy: 0.7143 - val_loss: 0.6755 - val_accuracy: 0.6000\n",
            "Epoch 150/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6219 - accuracy: 0.7143 - val_loss: 0.6736 - val_accuracy: 0.6000\n",
            "Epoch 151/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6187 - accuracy: 0.7048 - val_loss: 0.6708 - val_accuracy: 0.6000\n",
            "Epoch 152/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.6146 - accuracy: 0.7048 - val_loss: 0.6653 - val_accuracy: 0.6000\n",
            "Epoch 153/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.6108 - accuracy: 0.7143 - val_loss: 0.6616 - val_accuracy: 0.6000\n",
            "Epoch 154/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.6073 - accuracy: 0.7143 - val_loss: 0.6577 - val_accuracy: 0.6000\n",
            "Epoch 155/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.6034 - accuracy: 0.7143 - val_loss: 0.6520 - val_accuracy: 0.6000\n",
            "Epoch 156/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5997 - accuracy: 0.7238 - val_loss: 0.6458 - val_accuracy: 0.6222\n",
            "Epoch 157/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5970 - accuracy: 0.7333 - val_loss: 0.6408 - val_accuracy: 0.6222\n",
            "Epoch 158/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5932 - accuracy: 0.7429 - val_loss: 0.6368 - val_accuracy: 0.6222\n",
            "Epoch 159/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5897 - accuracy: 0.7429 - val_loss: 0.6320 - val_accuracy: 0.6444\n",
            "Epoch 160/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5865 - accuracy: 0.7524 - val_loss: 0.6261 - val_accuracy: 0.6444\n",
            "Epoch 161/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5832 - accuracy: 0.7810 - val_loss: 0.6214 - val_accuracy: 0.6444\n",
            "Epoch 162/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5801 - accuracy: 0.7810 - val_loss: 0.6177 - val_accuracy: 0.6444\n",
            "Epoch 163/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5769 - accuracy: 0.7810 - val_loss: 0.6173 - val_accuracy: 0.6444\n",
            "Epoch 164/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5736 - accuracy: 0.7619 - val_loss: 0.6158 - val_accuracy: 0.6444\n",
            "Epoch 165/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5703 - accuracy: 0.7429 - val_loss: 0.6141 - val_accuracy: 0.6222\n",
            "Epoch 166/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5673 - accuracy: 0.7429 - val_loss: 0.6119 - val_accuracy: 0.6222\n",
            "Epoch 167/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5640 - accuracy: 0.7429 - val_loss: 0.6091 - val_accuracy: 0.6222\n",
            "Epoch 168/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5610 - accuracy: 0.7524 - val_loss: 0.6033 - val_accuracy: 0.6444\n",
            "Epoch 169/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5576 - accuracy: 0.7619 - val_loss: 0.6002 - val_accuracy: 0.6444\n",
            "Epoch 170/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5549 - accuracy: 0.7619 - val_loss: 0.5984 - val_accuracy: 0.6222\n",
            "Epoch 171/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.5520 - accuracy: 0.7619 - val_loss: 0.5943 - val_accuracy: 0.6444\n",
            "Epoch 172/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5485 - accuracy: 0.7619 - val_loss: 0.5926 - val_accuracy: 0.6222\n",
            "Epoch 173/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5459 - accuracy: 0.7619 - val_loss: 0.5901 - val_accuracy: 0.6222\n",
            "Epoch 174/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5429 - accuracy: 0.7619 - val_loss: 0.5890 - val_accuracy: 0.6222\n",
            "Epoch 175/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5404 - accuracy: 0.7429 - val_loss: 0.5874 - val_accuracy: 0.6222\n",
            "Epoch 176/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5375 - accuracy: 0.7429 - val_loss: 0.5837 - val_accuracy: 0.6222\n",
            "Epoch 177/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.5349 - accuracy: 0.7619 - val_loss: 0.5776 - val_accuracy: 0.6444\n",
            "Epoch 178/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5318 - accuracy: 0.7619 - val_loss: 0.5745 - val_accuracy: 0.6444\n",
            "Epoch 179/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5292 - accuracy: 0.7714 - val_loss: 0.5717 - val_accuracy: 0.6444\n",
            "Epoch 180/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5268 - accuracy: 0.7714 - val_loss: 0.5702 - val_accuracy: 0.6222\n",
            "Epoch 181/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5238 - accuracy: 0.7714 - val_loss: 0.5654 - val_accuracy: 0.6444\n",
            "Epoch 182/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5210 - accuracy: 0.7810 - val_loss: 0.5604 - val_accuracy: 0.6444\n",
            "Epoch 183/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5190 - accuracy: 0.8000 - val_loss: 0.5539 - val_accuracy: 0.7111\n",
            "Epoch 184/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.5160 - accuracy: 0.8190 - val_loss: 0.5501 - val_accuracy: 0.7111\n",
            "Epoch 185/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5140 - accuracy: 0.8286 - val_loss: 0.5472 - val_accuracy: 0.7111\n",
            "Epoch 186/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.5114 - accuracy: 0.8286 - val_loss: 0.5463 - val_accuracy: 0.7111\n",
            "Epoch 187/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5085 - accuracy: 0.8286 - val_loss: 0.5442 - val_accuracy: 0.7111\n",
            "Epoch 188/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.5063 - accuracy: 0.8286 - val_loss: 0.5415 - val_accuracy: 0.7111\n",
            "Epoch 189/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5035 - accuracy: 0.8286 - val_loss: 0.5410 - val_accuracy: 0.6889\n",
            "Epoch 190/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5017 - accuracy: 0.7905 - val_loss: 0.5424 - val_accuracy: 0.6444\n",
            "Epoch 191/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4988 - accuracy: 0.7905 - val_loss: 0.5409 - val_accuracy: 0.6444\n",
            "Epoch 192/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4965 - accuracy: 0.7905 - val_loss: 0.5400 - val_accuracy: 0.6444\n",
            "Epoch 193/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4948 - accuracy: 0.7810 - val_loss: 0.5390 - val_accuracy: 0.6222\n",
            "Epoch 194/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4924 - accuracy: 0.7810 - val_loss: 0.5357 - val_accuracy: 0.6444\n",
            "Epoch 195/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4899 - accuracy: 0.7905 - val_loss: 0.5331 - val_accuracy: 0.6444\n",
            "Epoch 196/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4882 - accuracy: 0.7905 - val_loss: 0.5288 - val_accuracy: 0.6444\n",
            "Epoch 197/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4853 - accuracy: 0.7905 - val_loss: 0.5280 - val_accuracy: 0.6444\n",
            "Epoch 198/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4836 - accuracy: 0.7905 - val_loss: 0.5256 - val_accuracy: 0.6444\n",
            "Epoch 199/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4813 - accuracy: 0.7905 - val_loss: 0.5239 - val_accuracy: 0.6444\n",
            "Epoch 200/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4790 - accuracy: 0.7905 - val_loss: 0.5203 - val_accuracy: 0.6667\n",
            "Epoch 201/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4770 - accuracy: 0.7905 - val_loss: 0.5151 - val_accuracy: 0.6889\n",
            "Epoch 202/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4745 - accuracy: 0.8286 - val_loss: 0.5109 - val_accuracy: 0.7111\n",
            "Epoch 203/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4728 - accuracy: 0.8476 - val_loss: 0.5066 - val_accuracy: 0.7111\n",
            "Epoch 204/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4705 - accuracy: 0.8571 - val_loss: 0.5051 - val_accuracy: 0.7111\n",
            "Epoch 205/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4684 - accuracy: 0.8381 - val_loss: 0.5065 - val_accuracy: 0.7111\n",
            "Epoch 206/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4666 - accuracy: 0.8190 - val_loss: 0.5052 - val_accuracy: 0.6889\n",
            "Epoch 207/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4644 - accuracy: 0.8190 - val_loss: 0.5024 - val_accuracy: 0.7111\n",
            "Epoch 208/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4623 - accuracy: 0.8381 - val_loss: 0.4988 - val_accuracy: 0.7111\n",
            "Epoch 209/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4603 - accuracy: 0.8476 - val_loss: 0.4965 - val_accuracy: 0.7111\n",
            "Epoch 210/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4585 - accuracy: 0.8571 - val_loss: 0.4940 - val_accuracy: 0.7111\n",
            "Epoch 211/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4567 - accuracy: 0.8571 - val_loss: 0.4932 - val_accuracy: 0.7111\n",
            "Epoch 212/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4547 - accuracy: 0.8571 - val_loss: 0.4912 - val_accuracy: 0.7111\n",
            "Epoch 213/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4528 - accuracy: 0.8476 - val_loss: 0.4907 - val_accuracy: 0.7111\n",
            "Epoch 214/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4510 - accuracy: 0.8381 - val_loss: 0.4883 - val_accuracy: 0.7111\n",
            "Epoch 215/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4494 - accuracy: 0.8571 - val_loss: 0.4850 - val_accuracy: 0.7111\n",
            "Epoch 216/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4476 - accuracy: 0.8571 - val_loss: 0.4857 - val_accuracy: 0.7111\n",
            "Epoch 217/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4457 - accuracy: 0.8476 - val_loss: 0.4828 - val_accuracy: 0.7111\n",
            "Epoch 218/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4439 - accuracy: 0.8571 - val_loss: 0.4791 - val_accuracy: 0.7556\n",
            "Epoch 219/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4420 - accuracy: 0.8571 - val_loss: 0.4778 - val_accuracy: 0.7556\n",
            "Epoch 220/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4405 - accuracy: 0.8571 - val_loss: 0.4750 - val_accuracy: 0.7778\n",
            "Epoch 221/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4385 - accuracy: 0.8571 - val_loss: 0.4729 - val_accuracy: 0.7778\n",
            "Epoch 222/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4373 - accuracy: 0.8571 - val_loss: 0.4693 - val_accuracy: 0.8222\n",
            "Epoch 223/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.4351 - accuracy: 0.8667 - val_loss: 0.4682 - val_accuracy: 0.8222\n",
            "Epoch 224/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4333 - accuracy: 0.8667 - val_loss: 0.4653 - val_accuracy: 0.8444\n",
            "Epoch 225/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4318 - accuracy: 0.8762 - val_loss: 0.4617 - val_accuracy: 0.8444\n",
            "Epoch 226/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4307 - accuracy: 0.8857 - val_loss: 0.4580 - val_accuracy: 0.8444\n",
            "Epoch 227/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4285 - accuracy: 0.8952 - val_loss: 0.4577 - val_accuracy: 0.8444\n",
            "Epoch 228/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.4269 - accuracy: 0.8857 - val_loss: 0.4567 - val_accuracy: 0.8444\n",
            "Epoch 229/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4252 - accuracy: 0.8857 - val_loss: 0.4538 - val_accuracy: 0.8444\n",
            "Epoch 230/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4238 - accuracy: 0.8952 - val_loss: 0.4497 - val_accuracy: 0.8667\n",
            "Epoch 231/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4222 - accuracy: 0.9048 - val_loss: 0.4489 - val_accuracy: 0.8667\n",
            "Epoch 232/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4205 - accuracy: 0.9048 - val_loss: 0.4503 - val_accuracy: 0.8444\n",
            "Epoch 233/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4190 - accuracy: 0.8857 - val_loss: 0.4524 - val_accuracy: 0.8444\n",
            "Epoch 234/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4174 - accuracy: 0.8762 - val_loss: 0.4532 - val_accuracy: 0.8222\n",
            "Epoch 235/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4159 - accuracy: 0.8667 - val_loss: 0.4514 - val_accuracy: 0.8222\n",
            "Epoch 236/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4144 - accuracy: 0.8667 - val_loss: 0.4497 - val_accuracy: 0.8444\n",
            "Epoch 237/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4130 - accuracy: 0.8667 - val_loss: 0.4474 - val_accuracy: 0.8444\n",
            "Epoch 238/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4116 - accuracy: 0.8667 - val_loss: 0.4467 - val_accuracy: 0.8444\n",
            "Epoch 239/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4096 - accuracy: 0.8667 - val_loss: 0.4422 - val_accuracy: 0.8444\n",
            "Epoch 240/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4086 - accuracy: 0.8952 - val_loss: 0.4365 - val_accuracy: 0.8667\n",
            "Epoch 241/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4069 - accuracy: 0.9143 - val_loss: 0.4334 - val_accuracy: 0.8667\n",
            "Epoch 242/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4055 - accuracy: 0.9333 - val_loss: 0.4306 - val_accuracy: 0.8667\n",
            "Epoch 243/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.4042 - accuracy: 0.9333 - val_loss: 0.4294 - val_accuracy: 0.8667\n",
            "Epoch 244/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.4027 - accuracy: 0.9333 - val_loss: 0.4281 - val_accuracy: 0.8667\n",
            "Epoch 245/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4011 - accuracy: 0.9333 - val_loss: 0.4279 - val_accuracy: 0.8667\n",
            "Epoch 246/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3999 - accuracy: 0.9333 - val_loss: 0.4279 - val_accuracy: 0.8667\n",
            "Epoch 247/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3983 - accuracy: 0.9238 - val_loss: 0.4293 - val_accuracy: 0.8444\n",
            "Epoch 248/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3967 - accuracy: 0.9048 - val_loss: 0.4300 - val_accuracy: 0.8444\n",
            "Epoch 249/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3954 - accuracy: 0.8952 - val_loss: 0.4316 - val_accuracy: 0.8444\n",
            "Epoch 250/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3943 - accuracy: 0.8857 - val_loss: 0.4319 - val_accuracy: 0.8444\n",
            "Epoch 251/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3932 - accuracy: 0.8762 - val_loss: 0.4309 - val_accuracy: 0.8444\n",
            "Epoch 252/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3916 - accuracy: 0.8762 - val_loss: 0.4264 - val_accuracy: 0.8444\n",
            "Epoch 253/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3899 - accuracy: 0.9048 - val_loss: 0.4188 - val_accuracy: 0.8667\n",
            "Epoch 254/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3887 - accuracy: 0.9333 - val_loss: 0.4142 - val_accuracy: 0.9111\n",
            "Epoch 255/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3874 - accuracy: 0.9333 - val_loss: 0.4123 - val_accuracy: 0.9111\n",
            "Epoch 256/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3862 - accuracy: 0.9333 - val_loss: 0.4112 - val_accuracy: 0.9111\n",
            "Epoch 257/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3846 - accuracy: 0.9333 - val_loss: 0.4110 - val_accuracy: 0.9111\n",
            "Epoch 258/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3832 - accuracy: 0.9333 - val_loss: 0.4114 - val_accuracy: 0.8889\n",
            "Epoch 259/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3820 - accuracy: 0.9333 - val_loss: 0.4123 - val_accuracy: 0.8667\n",
            "Epoch 260/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3805 - accuracy: 0.9333 - val_loss: 0.4086 - val_accuracy: 0.8889\n",
            "Epoch 261/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3792 - accuracy: 0.9333 - val_loss: 0.4060 - val_accuracy: 0.9111\n",
            "Epoch 262/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3777 - accuracy: 0.9333 - val_loss: 0.4057 - val_accuracy: 0.8889\n",
            "Epoch 263/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3765 - accuracy: 0.9333 - val_loss: 0.4072 - val_accuracy: 0.8889\n",
            "Epoch 264/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3750 - accuracy: 0.9333 - val_loss: 0.4077 - val_accuracy: 0.8667\n",
            "Epoch 265/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3740 - accuracy: 0.9333 - val_loss: 0.4068 - val_accuracy: 0.8667\n",
            "Epoch 266/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3728 - accuracy: 0.9333 - val_loss: 0.4037 - val_accuracy: 0.8889\n",
            "Epoch 267/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3708 - accuracy: 0.9333 - val_loss: 0.3981 - val_accuracy: 0.9111\n",
            "Epoch 268/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3698 - accuracy: 0.9333 - val_loss: 0.3948 - val_accuracy: 0.9333\n",
            "Epoch 269/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3689 - accuracy: 0.9333 - val_loss: 0.3900 - val_accuracy: 0.9333\n",
            "Epoch 270/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3682 - accuracy: 0.9333 - val_loss: 0.3883 - val_accuracy: 0.9333\n",
            "Epoch 271/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3671 - accuracy: 0.9333 - val_loss: 0.3884 - val_accuracy: 0.9333\n",
            "Epoch 272/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3654 - accuracy: 0.9333 - val_loss: 0.3861 - val_accuracy: 0.9333\n",
            "Epoch 273/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3645 - accuracy: 0.9333 - val_loss: 0.3840 - val_accuracy: 0.9333\n",
            "Epoch 274/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3631 - accuracy: 0.9619 - val_loss: 0.3841 - val_accuracy: 0.9333\n",
            "Epoch 275/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3614 - accuracy: 0.9333 - val_loss: 0.3876 - val_accuracy: 0.9333\n",
            "Epoch 276/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3606 - accuracy: 0.9333 - val_loss: 0.3908 - val_accuracy: 0.8889\n",
            "Epoch 277/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3587 - accuracy: 0.9333 - val_loss: 0.3880 - val_accuracy: 0.9111\n",
            "Epoch 278/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3573 - accuracy: 0.9333 - val_loss: 0.3833 - val_accuracy: 0.9333\n",
            "Epoch 279/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3568 - accuracy: 0.9333 - val_loss: 0.3779 - val_accuracy: 0.9333\n",
            "Epoch 280/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3558 - accuracy: 0.9524 - val_loss: 0.3762 - val_accuracy: 0.9333\n",
            "Epoch 281/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3546 - accuracy: 0.9619 - val_loss: 0.3754 - val_accuracy: 0.9333\n",
            "Epoch 282/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3528 - accuracy: 0.9429 - val_loss: 0.3775 - val_accuracy: 0.9333\n",
            "Epoch 283/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3517 - accuracy: 0.9333 - val_loss: 0.3788 - val_accuracy: 0.9333\n",
            "Epoch 284/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3503 - accuracy: 0.9333 - val_loss: 0.3778 - val_accuracy: 0.9333\n",
            "Epoch 285/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3490 - accuracy: 0.9333 - val_loss: 0.3755 - val_accuracy: 0.9333\n",
            "Epoch 286/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3479 - accuracy: 0.9333 - val_loss: 0.3741 - val_accuracy: 0.9333\n",
            "Epoch 287/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3467 - accuracy: 0.9333 - val_loss: 0.3753 - val_accuracy: 0.9333\n",
            "Epoch 288/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3456 - accuracy: 0.9333 - val_loss: 0.3752 - val_accuracy: 0.9333\n",
            "Epoch 289/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3443 - accuracy: 0.9333 - val_loss: 0.3728 - val_accuracy: 0.9333\n",
            "Epoch 290/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3431 - accuracy: 0.9333 - val_loss: 0.3683 - val_accuracy: 0.9333\n",
            "Epoch 291/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3419 - accuracy: 0.9333 - val_loss: 0.3657 - val_accuracy: 0.9333\n",
            "Epoch 292/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3410 - accuracy: 0.9524 - val_loss: 0.3633 - val_accuracy: 0.9333\n",
            "Epoch 293/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3399 - accuracy: 0.9619 - val_loss: 0.3614 - val_accuracy: 0.9333\n",
            "Epoch 294/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3388 - accuracy: 0.9619 - val_loss: 0.3607 - val_accuracy: 0.9333\n",
            "Epoch 295/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3376 - accuracy: 0.9524 - val_loss: 0.3607 - val_accuracy: 0.9333\n",
            "Epoch 296/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3365 - accuracy: 0.9524 - val_loss: 0.3607 - val_accuracy: 0.9333\n",
            "Epoch 297/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3356 - accuracy: 0.9524 - val_loss: 0.3577 - val_accuracy: 0.9333\n",
            "Epoch 298/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3344 - accuracy: 0.9619 - val_loss: 0.3553 - val_accuracy: 0.9333\n",
            "Epoch 299/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3332 - accuracy: 0.9619 - val_loss: 0.3506 - val_accuracy: 0.9333\n",
            "Epoch 300/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3327 - accuracy: 0.9619 - val_loss: 0.3495 - val_accuracy: 0.9333\n",
            "Epoch 301/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3312 - accuracy: 0.9619 - val_loss: 0.3512 - val_accuracy: 0.9333\n",
            "Epoch 302/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3293 - accuracy: 0.9619 - val_loss: 0.3536 - val_accuracy: 0.9333\n",
            "Epoch 303/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3279 - accuracy: 0.9429 - val_loss: 0.3587 - val_accuracy: 0.9333\n",
            "Epoch 304/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3274 - accuracy: 0.9333 - val_loss: 0.3616 - val_accuracy: 0.9333\n",
            "Epoch 305/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3264 - accuracy: 0.9333 - val_loss: 0.3610 - val_accuracy: 0.9333\n",
            "Epoch 306/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3253 - accuracy: 0.9333 - val_loss: 0.3581 - val_accuracy: 0.9333\n",
            "Epoch 307/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3243 - accuracy: 0.9333 - val_loss: 0.3550 - val_accuracy: 0.9333\n",
            "Epoch 308/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3228 - accuracy: 0.9333 - val_loss: 0.3541 - val_accuracy: 0.9333\n",
            "Epoch 309/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3222 - accuracy: 0.9333 - val_loss: 0.3566 - val_accuracy: 0.9333\n",
            "Epoch 310/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3210 - accuracy: 0.9333 - val_loss: 0.3555 - val_accuracy: 0.9333\n",
            "Epoch 311/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3200 - accuracy: 0.9333 - val_loss: 0.3537 - val_accuracy: 0.9333\n",
            "Epoch 312/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3187 - accuracy: 0.9333 - val_loss: 0.3528 - val_accuracy: 0.9333\n",
            "Epoch 313/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3180 - accuracy: 0.9333 - val_loss: 0.3541 - val_accuracy: 0.9333\n",
            "Epoch 314/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3166 - accuracy: 0.9333 - val_loss: 0.3498 - val_accuracy: 0.9333\n",
            "Epoch 315/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3152 - accuracy: 0.9333 - val_loss: 0.3432 - val_accuracy: 0.9333\n",
            "Epoch 316/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3146 - accuracy: 0.9429 - val_loss: 0.3368 - val_accuracy: 0.9333\n",
            "Epoch 317/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3130 - accuracy: 0.9524 - val_loss: 0.3365 - val_accuracy: 0.9333\n",
            "Epoch 318/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3121 - accuracy: 0.9619 - val_loss: 0.3331 - val_accuracy: 0.9333\n",
            "Epoch 319/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3105 - accuracy: 0.9619 - val_loss: 0.3325 - val_accuracy: 0.9333\n",
            "Epoch 320/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3093 - accuracy: 0.9619 - val_loss: 0.3315 - val_accuracy: 0.9333\n",
            "Epoch 321/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.3082 - accuracy: 0.9619 - val_loss: 0.3307 - val_accuracy: 0.9333\n",
            "Epoch 322/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3071 - accuracy: 0.9619 - val_loss: 0.3305 - val_accuracy: 0.9333\n",
            "Epoch 323/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3062 - accuracy: 0.9619 - val_loss: 0.3325 - val_accuracy: 0.9333\n",
            "Epoch 324/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.3051 - accuracy: 0.9524 - val_loss: 0.3325 - val_accuracy: 0.9333\n",
            "Epoch 325/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3042 - accuracy: 0.9524 - val_loss: 0.3254 - val_accuracy: 0.9333\n",
            "Epoch 326/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3032 - accuracy: 0.9619 - val_loss: 0.3201 - val_accuracy: 0.9778\n",
            "Epoch 327/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3024 - accuracy: 0.9619 - val_loss: 0.3194 - val_accuracy: 0.9778\n",
            "Epoch 328/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.3015 - accuracy: 0.9619 - val_loss: 0.3223 - val_accuracy: 0.9333\n",
            "Epoch 329/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2994 - accuracy: 0.9619 - val_loss: 0.3258 - val_accuracy: 0.9333\n",
            "Epoch 330/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2997 - accuracy: 0.9524 - val_loss: 0.3305 - val_accuracy: 0.9333\n",
            "Epoch 331/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2975 - accuracy: 0.9429 - val_loss: 0.3291 - val_accuracy: 0.9333\n",
            "Epoch 332/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2964 - accuracy: 0.9524 - val_loss: 0.3272 - val_accuracy: 0.9333\n",
            "Epoch 333/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2955 - accuracy: 0.9524 - val_loss: 0.3231 - val_accuracy: 0.9333\n",
            "Epoch 334/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2941 - accuracy: 0.9524 - val_loss: 0.3194 - val_accuracy: 0.9333\n",
            "Epoch 335/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2929 - accuracy: 0.9619 - val_loss: 0.3167 - val_accuracy: 0.9333\n",
            "Epoch 336/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2919 - accuracy: 0.9619 - val_loss: 0.3142 - val_accuracy: 0.9556\n",
            "Epoch 337/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2909 - accuracy: 0.9619 - val_loss: 0.3143 - val_accuracy: 0.9556\n",
            "Epoch 338/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2899 - accuracy: 0.9619 - val_loss: 0.3133 - val_accuracy: 0.9556\n",
            "Epoch 339/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2892 - accuracy: 0.9619 - val_loss: 0.3090 - val_accuracy: 0.9778\n",
            "Epoch 340/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2878 - accuracy: 0.9619 - val_loss: 0.3091 - val_accuracy: 0.9556\n",
            "Epoch 341/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2862 - accuracy: 0.9619 - val_loss: 0.3114 - val_accuracy: 0.9333\n",
            "Epoch 342/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2852 - accuracy: 0.9619 - val_loss: 0.3148 - val_accuracy: 0.9333\n",
            "Epoch 343/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2843 - accuracy: 0.9524 - val_loss: 0.3161 - val_accuracy: 0.9333\n",
            "Epoch 344/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2835 - accuracy: 0.9524 - val_loss: 0.3150 - val_accuracy: 0.9333\n",
            "Epoch 345/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2825 - accuracy: 0.9524 - val_loss: 0.3132 - val_accuracy: 0.9333\n",
            "Epoch 346/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2813 - accuracy: 0.9524 - val_loss: 0.3117 - val_accuracy: 0.9333\n",
            "Epoch 347/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2804 - accuracy: 0.9524 - val_loss: 0.3104 - val_accuracy: 0.9333\n",
            "Epoch 348/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2791 - accuracy: 0.9524 - val_loss: 0.3113 - val_accuracy: 0.9333\n",
            "Epoch 349/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2783 - accuracy: 0.9524 - val_loss: 0.3082 - val_accuracy: 0.9333\n",
            "Epoch 350/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2770 - accuracy: 0.9524 - val_loss: 0.3060 - val_accuracy: 0.9333\n",
            "Epoch 351/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2759 - accuracy: 0.9524 - val_loss: 0.3032 - val_accuracy: 0.9333\n",
            "Epoch 352/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2748 - accuracy: 0.9524 - val_loss: 0.3015 - val_accuracy: 0.9556\n",
            "Epoch 353/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2736 - accuracy: 0.9524 - val_loss: 0.3006 - val_accuracy: 0.9556\n",
            "Epoch 354/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2727 - accuracy: 0.9524 - val_loss: 0.2992 - val_accuracy: 0.9556\n",
            "Epoch 355/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2717 - accuracy: 0.9524 - val_loss: 0.2980 - val_accuracy: 0.9556\n",
            "Epoch 356/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2707 - accuracy: 0.9524 - val_loss: 0.2976 - val_accuracy: 0.9556\n",
            "Epoch 357/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2697 - accuracy: 0.9619 - val_loss: 0.2928 - val_accuracy: 0.9778\n",
            "Epoch 358/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2683 - accuracy: 0.9619 - val_loss: 0.2905 - val_accuracy: 0.9778\n",
            "Epoch 359/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2675 - accuracy: 0.9619 - val_loss: 0.2879 - val_accuracy: 0.9778\n",
            "Epoch 360/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2668 - accuracy: 0.9619 - val_loss: 0.2865 - val_accuracy: 0.9778\n",
            "Epoch 361/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2650 - accuracy: 0.9619 - val_loss: 0.2899 - val_accuracy: 0.9778\n",
            "Epoch 362/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2639 - accuracy: 0.9619 - val_loss: 0.2938 - val_accuracy: 0.9556\n",
            "Epoch 363/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2638 - accuracy: 0.9524 - val_loss: 0.2966 - val_accuracy: 0.9333\n",
            "Epoch 364/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2629 - accuracy: 0.9524 - val_loss: 0.2948 - val_accuracy: 0.9333\n",
            "Epoch 365/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2618 - accuracy: 0.9524 - val_loss: 0.2931 - val_accuracy: 0.9333\n",
            "Epoch 366/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2605 - accuracy: 0.9524 - val_loss: 0.2904 - val_accuracy: 0.9556\n",
            "Epoch 367/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2593 - accuracy: 0.9524 - val_loss: 0.2868 - val_accuracy: 0.9556\n",
            "Epoch 368/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2589 - accuracy: 0.9524 - val_loss: 0.2826 - val_accuracy: 0.9778\n",
            "Epoch 369/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2571 - accuracy: 0.9619 - val_loss: 0.2843 - val_accuracy: 0.9556\n",
            "Epoch 370/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2562 - accuracy: 0.9524 - val_loss: 0.2834 - val_accuracy: 0.9556\n",
            "Epoch 371/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2554 - accuracy: 0.9524 - val_loss: 0.2803 - val_accuracy: 0.9778\n",
            "Epoch 372/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2541 - accuracy: 0.9619 - val_loss: 0.2776 - val_accuracy: 0.9778\n",
            "Epoch 373/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2531 - accuracy: 0.9619 - val_loss: 0.2762 - val_accuracy: 0.9778\n",
            "Epoch 374/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2526 - accuracy: 0.9619 - val_loss: 0.2745 - val_accuracy: 0.9778\n",
            "Epoch 375/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2511 - accuracy: 0.9619 - val_loss: 0.2752 - val_accuracy: 0.9778\n",
            "Epoch 376/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2500 - accuracy: 0.9619 - val_loss: 0.2768 - val_accuracy: 0.9778\n",
            "Epoch 377/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2497 - accuracy: 0.9619 - val_loss: 0.2795 - val_accuracy: 0.9556\n",
            "Epoch 378/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2488 - accuracy: 0.9524 - val_loss: 0.2781 - val_accuracy: 0.9556\n",
            "Epoch 379/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2476 - accuracy: 0.9524 - val_loss: 0.2764 - val_accuracy: 0.9556\n",
            "Epoch 380/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2466 - accuracy: 0.9619 - val_loss: 0.2720 - val_accuracy: 0.9778\n",
            "Epoch 381/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2452 - accuracy: 0.9619 - val_loss: 0.2700 - val_accuracy: 0.9778\n",
            "Epoch 382/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2445 - accuracy: 0.9619 - val_loss: 0.2700 - val_accuracy: 0.9778\n",
            "Epoch 383/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2433 - accuracy: 0.9619 - val_loss: 0.2687 - val_accuracy: 0.9778\n",
            "Epoch 384/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2422 - accuracy: 0.9619 - val_loss: 0.2666 - val_accuracy: 0.9778\n",
            "Epoch 385/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2411 - accuracy: 0.9619 - val_loss: 0.2637 - val_accuracy: 0.9778\n",
            "Epoch 386/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2405 - accuracy: 0.9619 - val_loss: 0.2620 - val_accuracy: 0.9778\n",
            "Epoch 387/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2391 - accuracy: 0.9619 - val_loss: 0.2641 - val_accuracy: 0.9778\n",
            "Epoch 388/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2382 - accuracy: 0.9619 - val_loss: 0.2662 - val_accuracy: 0.9778\n",
            "Epoch 389/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2382 - accuracy: 0.9524 - val_loss: 0.2723 - val_accuracy: 0.9556\n",
            "Epoch 390/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2377 - accuracy: 0.9524 - val_loss: 0.2731 - val_accuracy: 0.9556\n",
            "Epoch 391/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2373 - accuracy: 0.9524 - val_loss: 0.2744 - val_accuracy: 0.9333\n",
            "Epoch 392/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2366 - accuracy: 0.9524 - val_loss: 0.2695 - val_accuracy: 0.9556\n",
            "Epoch 393/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2340 - accuracy: 0.9524 - val_loss: 0.2573 - val_accuracy: 0.9778\n",
            "Epoch 394/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2321 - accuracy: 0.9619 - val_loss: 0.2498 - val_accuracy: 0.9778\n",
            "Epoch 395/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2334 - accuracy: 0.9619 - val_loss: 0.2452 - val_accuracy: 0.9778\n",
            "Epoch 396/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2327 - accuracy: 0.9619 - val_loss: 0.2438 - val_accuracy: 0.9778\n",
            "Epoch 397/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2319 - accuracy: 0.9619 - val_loss: 0.2447 - val_accuracy: 0.9778\n",
            "Epoch 398/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2286 - accuracy: 0.9714 - val_loss: 0.2523 - val_accuracy: 0.9778\n",
            "Epoch 399/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2282 - accuracy: 0.9619 - val_loss: 0.2630 - val_accuracy: 0.9556\n",
            "Epoch 400/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2311 - accuracy: 0.9524 - val_loss: 0.2693 - val_accuracy: 0.9333\n",
            "Epoch 401/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2293 - accuracy: 0.9524 - val_loss: 0.2611 - val_accuracy: 0.9556\n",
            "Epoch 402/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2263 - accuracy: 0.9524 - val_loss: 0.2553 - val_accuracy: 0.9778\n",
            "Epoch 403/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2246 - accuracy: 0.9619 - val_loss: 0.2468 - val_accuracy: 0.9778\n",
            "Epoch 404/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2233 - accuracy: 0.9619 - val_loss: 0.2425 - val_accuracy: 0.9778\n",
            "Epoch 405/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2228 - accuracy: 0.9619 - val_loss: 0.2419 - val_accuracy: 0.9778\n",
            "Epoch 406/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2219 - accuracy: 0.9619 - val_loss: 0.2382 - val_accuracy: 0.9778\n",
            "Epoch 407/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2214 - accuracy: 0.9714 - val_loss: 0.2370 - val_accuracy: 0.9778\n",
            "Epoch 408/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2205 - accuracy: 0.9714 - val_loss: 0.2347 - val_accuracy: 0.9778\n",
            "Epoch 409/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2209 - accuracy: 0.9619 - val_loss: 0.2302 - val_accuracy: 0.9778\n",
            "Epoch 410/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2212 - accuracy: 0.9619 - val_loss: 0.2302 - val_accuracy: 0.9778\n",
            "Epoch 411/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2184 - accuracy: 0.9619 - val_loss: 0.2336 - val_accuracy: 0.9778\n",
            "Epoch 412/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2163 - accuracy: 0.9619 - val_loss: 0.2407 - val_accuracy: 0.9778\n",
            "Epoch 413/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2153 - accuracy: 0.9619 - val_loss: 0.2423 - val_accuracy: 0.9778\n",
            "Epoch 414/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2147 - accuracy: 0.9619 - val_loss: 0.2431 - val_accuracy: 0.9778\n",
            "Epoch 415/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2144 - accuracy: 0.9524 - val_loss: 0.2409 - val_accuracy: 0.9778\n",
            "Epoch 416/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2133 - accuracy: 0.9619 - val_loss: 0.2339 - val_accuracy: 0.9778\n",
            "Epoch 417/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2122 - accuracy: 0.9619 - val_loss: 0.2320 - val_accuracy: 0.9778\n",
            "Epoch 418/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.2117 - accuracy: 0.9714 - val_loss: 0.2299 - val_accuracy: 0.9778\n",
            "Epoch 419/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2111 - accuracy: 0.9619 - val_loss: 0.2318 - val_accuracy: 0.9778\n",
            "Epoch 420/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2098 - accuracy: 0.9619 - val_loss: 0.2297 - val_accuracy: 0.9778\n",
            "Epoch 421/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2087 - accuracy: 0.9714 - val_loss: 0.2253 - val_accuracy: 0.9778\n",
            "Epoch 422/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2086 - accuracy: 0.9619 - val_loss: 0.2218 - val_accuracy: 0.9778\n",
            "Epoch 423/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2089 - accuracy: 0.9619 - val_loss: 0.2203 - val_accuracy: 0.9778\n",
            "Epoch 424/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2071 - accuracy: 0.9619 - val_loss: 0.2248 - val_accuracy: 0.9778\n",
            "Epoch 425/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2058 - accuracy: 0.9619 - val_loss: 0.2306 - val_accuracy: 0.9778\n",
            "Epoch 426/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2053 - accuracy: 0.9524 - val_loss: 0.2336 - val_accuracy: 0.9778\n",
            "Epoch 427/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2046 - accuracy: 0.9524 - val_loss: 0.2328 - val_accuracy: 0.9778\n",
            "Epoch 428/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2035 - accuracy: 0.9524 - val_loss: 0.2264 - val_accuracy: 0.9778\n",
            "Epoch 429/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2021 - accuracy: 0.9619 - val_loss: 0.2214 - val_accuracy: 0.9778\n",
            "Epoch 430/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2021 - accuracy: 0.9714 - val_loss: 0.2177 - val_accuracy: 0.9778\n",
            "Epoch 431/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2011 - accuracy: 0.9619 - val_loss: 0.2178 - val_accuracy: 0.9778\n",
            "Epoch 432/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2011 - accuracy: 0.9714 - val_loss: 0.2226 - val_accuracy: 0.9778\n",
            "Epoch 433/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1996 - accuracy: 0.9619 - val_loss: 0.2236 - val_accuracy: 0.9778\n",
            "Epoch 434/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1982 - accuracy: 0.9619 - val_loss: 0.2182 - val_accuracy: 0.9778\n",
            "Epoch 435/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1984 - accuracy: 0.9714 - val_loss: 0.2154 - val_accuracy: 0.9778\n",
            "Epoch 436/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1964 - accuracy: 0.9714 - val_loss: 0.2188 - val_accuracy: 0.9778\n",
            "Epoch 437/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1970 - accuracy: 0.9619 - val_loss: 0.2238 - val_accuracy: 0.9778\n",
            "Epoch 438/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1957 - accuracy: 0.9524 - val_loss: 0.2224 - val_accuracy: 0.9778\n",
            "Epoch 439/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1945 - accuracy: 0.9619 - val_loss: 0.2183 - val_accuracy: 0.9778\n",
            "Epoch 440/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1934 - accuracy: 0.9714 - val_loss: 0.2136 - val_accuracy: 0.9778\n",
            "Epoch 441/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1926 - accuracy: 0.9714 - val_loss: 0.2091 - val_accuracy: 0.9778\n",
            "Epoch 442/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1926 - accuracy: 0.9619 - val_loss: 0.2074 - val_accuracy: 0.9778\n",
            "Epoch 443/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1920 - accuracy: 0.9714 - val_loss: 0.2107 - val_accuracy: 0.9778\n",
            "Epoch 444/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1908 - accuracy: 0.9714 - val_loss: 0.2152 - val_accuracy: 0.9778\n",
            "Epoch 445/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1899 - accuracy: 0.9619 - val_loss: 0.2169 - val_accuracy: 0.9778\n",
            "Epoch 446/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1895 - accuracy: 0.9619 - val_loss: 0.2192 - val_accuracy: 0.9778\n",
            "Epoch 447/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1895 - accuracy: 0.9524 - val_loss: 0.2173 - val_accuracy: 0.9778\n",
            "Epoch 448/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1887 - accuracy: 0.9619 - val_loss: 0.2142 - val_accuracy: 0.9778\n",
            "Epoch 449/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1877 - accuracy: 0.9524 - val_loss: 0.2141 - val_accuracy: 0.9778\n",
            "Epoch 450/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1870 - accuracy: 0.9524 - val_loss: 0.2125 - val_accuracy: 0.9778\n",
            "Epoch 451/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1862 - accuracy: 0.9619 - val_loss: 0.2123 - val_accuracy: 0.9778\n",
            "Epoch 452/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1853 - accuracy: 0.9619 - val_loss: 0.2088 - val_accuracy: 0.9778\n",
            "Epoch 453/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1842 - accuracy: 0.9714 - val_loss: 0.2049 - val_accuracy: 0.9778\n",
            "Epoch 454/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1835 - accuracy: 0.9714 - val_loss: 0.2027 - val_accuracy: 0.9778\n",
            "Epoch 455/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1827 - accuracy: 0.9714 - val_loss: 0.2000 - val_accuracy: 0.9778\n",
            "Epoch 456/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1822 - accuracy: 0.9714 - val_loss: 0.1987 - val_accuracy: 0.9778\n",
            "Epoch 457/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1814 - accuracy: 0.9714 - val_loss: 0.2002 - val_accuracy: 0.9778\n",
            "Epoch 458/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1806 - accuracy: 0.9714 - val_loss: 0.2026 - val_accuracy: 0.9778\n",
            "Epoch 459/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1798 - accuracy: 0.9714 - val_loss: 0.2071 - val_accuracy: 0.9778\n",
            "Epoch 460/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1800 - accuracy: 0.9524 - val_loss: 0.2085 - val_accuracy: 0.9778\n",
            "Epoch 461/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1796 - accuracy: 0.9524 - val_loss: 0.2043 - val_accuracy: 0.9778\n",
            "Epoch 462/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1778 - accuracy: 0.9714 - val_loss: 0.1982 - val_accuracy: 0.9778\n",
            "Epoch 463/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1770 - accuracy: 0.9714 - val_loss: 0.1927 - val_accuracy: 0.9778\n",
            "Epoch 464/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1770 - accuracy: 0.9619 - val_loss: 0.1903 - val_accuracy: 0.9778\n",
            "Epoch 465/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1761 - accuracy: 0.9619 - val_loss: 0.1922 - val_accuracy: 0.9778\n",
            "Epoch 466/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1749 - accuracy: 0.9714 - val_loss: 0.1943 - val_accuracy: 0.9778\n",
            "Epoch 467/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1752 - accuracy: 0.9714 - val_loss: 0.1985 - val_accuracy: 0.9778\n",
            "Epoch 468/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1739 - accuracy: 0.9714 - val_loss: 0.1955 - val_accuracy: 0.9778\n",
            "Epoch 469/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1735 - accuracy: 0.9714 - val_loss: 0.1919 - val_accuracy: 0.9778\n",
            "Epoch 470/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1724 - accuracy: 0.9714 - val_loss: 0.1910 - val_accuracy: 0.9778\n",
            "Epoch 471/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1717 - accuracy: 0.9714 - val_loss: 0.1907 - val_accuracy: 0.9778\n",
            "Epoch 472/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1709 - accuracy: 0.9714 - val_loss: 0.1882 - val_accuracy: 0.9778\n",
            "Epoch 473/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1709 - accuracy: 0.9714 - val_loss: 0.1855 - val_accuracy: 0.9778\n",
            "Epoch 474/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1700 - accuracy: 0.9619 - val_loss: 0.1849 - val_accuracy: 0.9778\n",
            "Epoch 475/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1694 - accuracy: 0.9619 - val_loss: 0.1848 - val_accuracy: 0.9778\n",
            "Epoch 476/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1687 - accuracy: 0.9619 - val_loss: 0.1848 - val_accuracy: 0.9778\n",
            "Epoch 477/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1679 - accuracy: 0.9714 - val_loss: 0.1869 - val_accuracy: 0.9778\n",
            "Epoch 478/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1677 - accuracy: 0.9714 - val_loss: 0.1857 - val_accuracy: 0.9778\n",
            "Epoch 479/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1663 - accuracy: 0.9714 - val_loss: 0.1881 - val_accuracy: 0.9778\n",
            "Epoch 480/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1659 - accuracy: 0.9714 - val_loss: 0.1898 - val_accuracy: 0.9778\n",
            "Epoch 481/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1657 - accuracy: 0.9714 - val_loss: 0.1892 - val_accuracy: 0.9778\n",
            "Epoch 482/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1648 - accuracy: 0.9714 - val_loss: 0.1847 - val_accuracy: 0.9778\n",
            "Epoch 483/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1645 - accuracy: 0.9714 - val_loss: 0.1790 - val_accuracy: 0.9778\n",
            "Epoch 484/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1637 - accuracy: 0.9619 - val_loss: 0.1782 - val_accuracy: 0.9778\n",
            "Epoch 485/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1631 - accuracy: 0.9619 - val_loss: 0.1767 - val_accuracy: 0.9778\n",
            "Epoch 486/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1627 - accuracy: 0.9619 - val_loss: 0.1765 - val_accuracy: 0.9778\n",
            "Epoch 487/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1619 - accuracy: 0.9619 - val_loss: 0.1778 - val_accuracy: 0.9778\n",
            "Epoch 488/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1610 - accuracy: 0.9619 - val_loss: 0.1780 - val_accuracy: 0.9778\n",
            "Epoch 489/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1605 - accuracy: 0.9619 - val_loss: 0.1778 - val_accuracy: 0.9778\n",
            "Epoch 490/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1604 - accuracy: 0.9714 - val_loss: 0.1795 - val_accuracy: 0.9778\n",
            "Epoch 491/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1591 - accuracy: 0.9714 - val_loss: 0.1766 - val_accuracy: 0.9778\n",
            "Epoch 492/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1587 - accuracy: 0.9619 - val_loss: 0.1742 - val_accuracy: 0.9778\n",
            "Epoch 493/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1582 - accuracy: 0.9619 - val_loss: 0.1732 - val_accuracy: 0.9778\n",
            "Epoch 494/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1579 - accuracy: 0.9619 - val_loss: 0.1711 - val_accuracy: 0.9778\n",
            "Epoch 495/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1573 - accuracy: 0.9619 - val_loss: 0.1709 - val_accuracy: 0.9778\n",
            "Epoch 496/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1567 - accuracy: 0.9619 - val_loss: 0.1712 - val_accuracy: 0.9778\n",
            "Epoch 497/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1567 - accuracy: 0.9619 - val_loss: 0.1731 - val_accuracy: 0.9778\n",
            "Epoch 498/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1553 - accuracy: 0.9714 - val_loss: 0.1714 - val_accuracy: 0.9778\n",
            "Epoch 499/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1546 - accuracy: 0.9714 - val_loss: 0.1722 - val_accuracy: 0.9778\n",
            "Epoch 500/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1542 - accuracy: 0.9714 - val_loss: 0.1719 - val_accuracy: 0.9778\n",
            "Epoch 501/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1534 - accuracy: 0.9714 - val_loss: 0.1739 - val_accuracy: 0.9778\n",
            "Epoch 502/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1536 - accuracy: 0.9714 - val_loss: 0.1743 - val_accuracy: 0.9778\n",
            "Epoch 503/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1531 - accuracy: 0.9714 - val_loss: 0.1756 - val_accuracy: 0.9778\n",
            "Epoch 504/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1532 - accuracy: 0.9714 - val_loss: 0.1761 - val_accuracy: 0.9778\n",
            "Epoch 505/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1521 - accuracy: 0.9714 - val_loss: 0.1703 - val_accuracy: 0.9778\n",
            "Epoch 506/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1511 - accuracy: 0.9714 - val_loss: 0.1697 - val_accuracy: 0.9778\n",
            "Epoch 507/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1507 - accuracy: 0.9714 - val_loss: 0.1721 - val_accuracy: 0.9778\n",
            "Epoch 508/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1505 - accuracy: 0.9714 - val_loss: 0.1740 - val_accuracy: 0.9778\n",
            "Epoch 509/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1503 - accuracy: 0.9619 - val_loss: 0.1739 - val_accuracy: 0.9778\n",
            "Epoch 510/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1501 - accuracy: 0.9619 - val_loss: 0.1730 - val_accuracy: 0.9778\n",
            "Epoch 511/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1489 - accuracy: 0.9619 - val_loss: 0.1658 - val_accuracy: 0.9778\n",
            "Epoch 512/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1484 - accuracy: 0.9619 - val_loss: 0.1605 - val_accuracy: 0.9778\n",
            "Epoch 513/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1478 - accuracy: 0.9619 - val_loss: 0.1578 - val_accuracy: 0.9778\n",
            "Epoch 514/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1484 - accuracy: 0.9714 - val_loss: 0.1569 - val_accuracy: 0.9778\n",
            "Epoch 515/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1478 - accuracy: 0.9619 - val_loss: 0.1588 - val_accuracy: 0.9778\n",
            "Epoch 516/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1462 - accuracy: 0.9619 - val_loss: 0.1618 - val_accuracy: 0.9778\n",
            "Epoch 517/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1460 - accuracy: 0.9619 - val_loss: 0.1646 - val_accuracy: 0.9778\n",
            "Epoch 518/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1451 - accuracy: 0.9714 - val_loss: 0.1609 - val_accuracy: 0.9778\n",
            "Epoch 519/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1445 - accuracy: 0.9619 - val_loss: 0.1606 - val_accuracy: 0.9778\n",
            "Epoch 520/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1439 - accuracy: 0.9714 - val_loss: 0.1615 - val_accuracy: 0.9778\n",
            "Epoch 521/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1435 - accuracy: 0.9714 - val_loss: 0.1623 - val_accuracy: 0.9778\n",
            "Epoch 522/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1432 - accuracy: 0.9714 - val_loss: 0.1622 - val_accuracy: 0.9778\n",
            "Epoch 523/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1429 - accuracy: 0.9714 - val_loss: 0.1623 - val_accuracy: 0.9778\n",
            "Epoch 524/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1428 - accuracy: 0.9714 - val_loss: 0.1605 - val_accuracy: 0.9778\n",
            "Epoch 525/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1420 - accuracy: 0.9714 - val_loss: 0.1618 - val_accuracy: 0.9778\n",
            "Epoch 526/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1417 - accuracy: 0.9714 - val_loss: 0.1615 - val_accuracy: 0.9778\n",
            "Epoch 527/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1408 - accuracy: 0.9714 - val_loss: 0.1578 - val_accuracy: 0.9778\n",
            "Epoch 528/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1409 - accuracy: 0.9619 - val_loss: 0.1517 - val_accuracy: 0.9778\n",
            "Epoch 529/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.1410 - accuracy: 0.9619 - val_loss: 0.1496 - val_accuracy: 0.9778\n",
            "Epoch 530/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1407 - accuracy: 0.9714 - val_loss: 0.1514 - val_accuracy: 0.9778\n",
            "Epoch 531/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1393 - accuracy: 0.9619 - val_loss: 0.1517 - val_accuracy: 0.9778\n",
            "Epoch 532/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1386 - accuracy: 0.9619 - val_loss: 0.1533 - val_accuracy: 0.9778\n",
            "Epoch 533/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1380 - accuracy: 0.9619 - val_loss: 0.1547 - val_accuracy: 0.9778\n",
            "Epoch 534/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1376 - accuracy: 0.9714 - val_loss: 0.1597 - val_accuracy: 0.9778\n",
            "Epoch 535/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1390 - accuracy: 0.9619 - val_loss: 0.1638 - val_accuracy: 0.9778\n",
            "Epoch 536/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1384 - accuracy: 0.9619 - val_loss: 0.1593 - val_accuracy: 0.9778\n",
            "Epoch 537/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1373 - accuracy: 0.9619 - val_loss: 0.1539 - val_accuracy: 0.9778\n",
            "Epoch 538/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1361 - accuracy: 0.9714 - val_loss: 0.1517 - val_accuracy: 0.9778\n",
            "Epoch 539/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1364 - accuracy: 0.9714 - val_loss: 0.1524 - val_accuracy: 0.9778\n",
            "Epoch 540/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1355 - accuracy: 0.9619 - val_loss: 0.1486 - val_accuracy: 0.9778\n",
            "Epoch 541/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1347 - accuracy: 0.9619 - val_loss: 0.1486 - val_accuracy: 0.9778\n",
            "Epoch 542/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1344 - accuracy: 0.9619 - val_loss: 0.1484 - val_accuracy: 0.9778\n",
            "Epoch 543/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1340 - accuracy: 0.9619 - val_loss: 0.1470 - val_accuracy: 0.9778\n",
            "Epoch 544/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1338 - accuracy: 0.9619 - val_loss: 0.1467 - val_accuracy: 0.9778\n",
            "Epoch 545/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1341 - accuracy: 0.9619 - val_loss: 0.1488 - val_accuracy: 0.9778\n",
            "Epoch 546/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1328 - accuracy: 0.9619 - val_loss: 0.1452 - val_accuracy: 0.9778\n",
            "Epoch 547/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1325 - accuracy: 0.9619 - val_loss: 0.1434 - val_accuracy: 0.9778\n",
            "Epoch 548/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1322 - accuracy: 0.9619 - val_loss: 0.1423 - val_accuracy: 0.9778\n",
            "Epoch 549/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1321 - accuracy: 0.9714 - val_loss: 0.1421 - val_accuracy: 0.9778\n",
            "Epoch 550/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1313 - accuracy: 0.9619 - val_loss: 0.1434 - val_accuracy: 0.9778\n",
            "Epoch 551/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1313 - accuracy: 0.9619 - val_loss: 0.1471 - val_accuracy: 0.9778\n",
            "Epoch 552/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1304 - accuracy: 0.9714 - val_loss: 0.1478 - val_accuracy: 0.9778\n",
            "Epoch 553/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1301 - accuracy: 0.9714 - val_loss: 0.1450 - val_accuracy: 0.9778\n",
            "Epoch 554/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1295 - accuracy: 0.9619 - val_loss: 0.1392 - val_accuracy: 0.9778\n",
            "Epoch 555/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1309 - accuracy: 0.9714 - val_loss: 0.1361 - val_accuracy: 0.9778\n",
            "Epoch 556/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1318 - accuracy: 0.9714 - val_loss: 0.1354 - val_accuracy: 0.9778\n",
            "Epoch 557/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1314 - accuracy: 0.9714 - val_loss: 0.1374 - val_accuracy: 0.9778\n",
            "Epoch 558/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1284 - accuracy: 0.9714 - val_loss: 0.1399 - val_accuracy: 0.9778\n",
            "Epoch 559/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1271 - accuracy: 0.9619 - val_loss: 0.1479 - val_accuracy: 0.9778\n",
            "Epoch 560/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1281 - accuracy: 0.9619 - val_loss: 0.1528 - val_accuracy: 0.9778\n",
            "Epoch 561/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1299 - accuracy: 0.9619 - val_loss: 0.1530 - val_accuracy: 0.9778\n",
            "Epoch 562/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1282 - accuracy: 0.9619 - val_loss: 0.1438 - val_accuracy: 0.9778\n",
            "Epoch 563/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1275 - accuracy: 0.9619 - val_loss: 0.1366 - val_accuracy: 0.9778\n",
            "Epoch 564/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1260 - accuracy: 0.9714 - val_loss: 0.1344 - val_accuracy: 0.9778\n",
            "Epoch 565/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1275 - accuracy: 0.9714 - val_loss: 0.1326 - val_accuracy: 0.9778\n",
            "Epoch 566/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1272 - accuracy: 0.9714 - val_loss: 0.1330 - val_accuracy: 0.9778\n",
            "Epoch 567/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1259 - accuracy: 0.9714 - val_loss: 0.1356 - val_accuracy: 0.9778\n",
            "Epoch 568/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1244 - accuracy: 0.9619 - val_loss: 0.1373 - val_accuracy: 0.9778\n",
            "Epoch 569/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1238 - accuracy: 0.9619 - val_loss: 0.1394 - val_accuracy: 0.9778\n",
            "Epoch 570/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1241 - accuracy: 0.9714 - val_loss: 0.1436 - val_accuracy: 0.9778\n",
            "Epoch 571/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1245 - accuracy: 0.9619 - val_loss: 0.1456 - val_accuracy: 0.9778\n",
            "Epoch 572/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1242 - accuracy: 0.9619 - val_loss: 0.1418 - val_accuracy: 0.9778\n",
            "Epoch 573/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1231 - accuracy: 0.9714 - val_loss: 0.1363 - val_accuracy: 0.9778\n",
            "Epoch 574/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1219 - accuracy: 0.9619 - val_loss: 0.1329 - val_accuracy: 0.9778\n",
            "Epoch 575/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1228 - accuracy: 0.9714 - val_loss: 0.1299 - val_accuracy: 0.9778\n",
            "Epoch 576/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1228 - accuracy: 0.9714 - val_loss: 0.1298 - val_accuracy: 0.9778\n",
            "Epoch 577/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1225 - accuracy: 0.9714 - val_loss: 0.1307 - val_accuracy: 0.9778\n",
            "Epoch 578/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1210 - accuracy: 0.9714 - val_loss: 0.1321 - val_accuracy: 0.9778\n",
            "Epoch 579/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1217 - accuracy: 0.9619 - val_loss: 0.1345 - val_accuracy: 0.9778\n",
            "Epoch 580/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1205 - accuracy: 0.9619 - val_loss: 0.1321 - val_accuracy: 0.9778\n",
            "Epoch 581/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1199 - accuracy: 0.9619 - val_loss: 0.1317 - val_accuracy: 0.9778\n",
            "Epoch 582/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1195 - accuracy: 0.9619 - val_loss: 0.1321 - val_accuracy: 0.9778\n",
            "Epoch 583/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1194 - accuracy: 0.9619 - val_loss: 0.1326 - val_accuracy: 0.9778\n",
            "Epoch 584/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1190 - accuracy: 0.9619 - val_loss: 0.1327 - val_accuracy: 0.9778\n",
            "Epoch 585/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1185 - accuracy: 0.9619 - val_loss: 0.1353 - val_accuracy: 0.9778\n",
            "Epoch 586/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1193 - accuracy: 0.9714 - val_loss: 0.1378 - val_accuracy: 0.9778\n",
            "Epoch 587/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1190 - accuracy: 0.9619 - val_loss: 0.1373 - val_accuracy: 0.9778\n",
            "Epoch 588/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1185 - accuracy: 0.9619 - val_loss: 0.1375 - val_accuracy: 0.9778\n",
            "Epoch 589/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1185 - accuracy: 0.9619 - val_loss: 0.1352 - val_accuracy: 0.9778\n",
            "Epoch 590/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1176 - accuracy: 0.9714 - val_loss: 0.1326 - val_accuracy: 0.9778\n",
            "Epoch 591/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1169 - accuracy: 0.9619 - val_loss: 0.1305 - val_accuracy: 0.9778\n",
            "Epoch 592/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1165 - accuracy: 0.9619 - val_loss: 0.1306 - val_accuracy: 0.9778\n",
            "Epoch 593/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1161 - accuracy: 0.9619 - val_loss: 0.1314 - val_accuracy: 0.9778\n",
            "Epoch 594/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1161 - accuracy: 0.9714 - val_loss: 0.1316 - val_accuracy: 0.9778\n",
            "Epoch 595/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1157 - accuracy: 0.9714 - val_loss: 0.1301 - val_accuracy: 0.9778\n",
            "Epoch 596/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1155 - accuracy: 0.9619 - val_loss: 0.1298 - val_accuracy: 0.9778\n",
            "Epoch 597/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1152 - accuracy: 0.9714 - val_loss: 0.1323 - val_accuracy: 0.9778\n",
            "Epoch 598/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1160 - accuracy: 0.9619 - val_loss: 0.1347 - val_accuracy: 0.9778\n",
            "Epoch 599/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1152 - accuracy: 0.9714 - val_loss: 0.1300 - val_accuracy: 0.9778\n",
            "Epoch 600/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1149 - accuracy: 0.9714 - val_loss: 0.1253 - val_accuracy: 0.9778\n",
            "Epoch 601/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1138 - accuracy: 0.9619 - val_loss: 0.1247 - val_accuracy: 0.9778\n",
            "Epoch 602/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1135 - accuracy: 0.9619 - val_loss: 0.1260 - val_accuracy: 0.9778\n",
            "Epoch 603/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1135 - accuracy: 0.9619 - val_loss: 0.1290 - val_accuracy: 0.9778\n",
            "Epoch 604/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1138 - accuracy: 0.9619 - val_loss: 0.1325 - val_accuracy: 0.9778\n",
            "Epoch 605/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1138 - accuracy: 0.9619 - val_loss: 0.1299 - val_accuracy: 0.9778\n",
            "Epoch 606/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1126 - accuracy: 0.9714 - val_loss: 0.1263 - val_accuracy: 0.9778\n",
            "Epoch 607/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1121 - accuracy: 0.9619 - val_loss: 0.1229 - val_accuracy: 0.9778\n",
            "Epoch 608/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1117 - accuracy: 0.9619 - val_loss: 0.1215 - val_accuracy: 0.9778\n",
            "Epoch 609/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1117 - accuracy: 0.9619 - val_loss: 0.1214 - val_accuracy: 0.9778\n",
            "Epoch 610/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1118 - accuracy: 0.9714 - val_loss: 0.1203 - val_accuracy: 0.9778\n",
            "Epoch 611/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1116 - accuracy: 0.9714 - val_loss: 0.1223 - val_accuracy: 0.9778\n",
            "Epoch 612/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1106 - accuracy: 0.9619 - val_loss: 0.1233 - val_accuracy: 0.9778\n",
            "Epoch 613/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1103 - accuracy: 0.9619 - val_loss: 0.1243 - val_accuracy: 0.9778\n",
            "Epoch 614/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1103 - accuracy: 0.9714 - val_loss: 0.1276 - val_accuracy: 0.9778\n",
            "Epoch 615/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1116 - accuracy: 0.9619 - val_loss: 0.1340 - val_accuracy: 0.9778\n",
            "Epoch 616/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1127 - accuracy: 0.9619 - val_loss: 0.1339 - val_accuracy: 0.9778\n",
            "Epoch 617/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1123 - accuracy: 0.9619 - val_loss: 0.1306 - val_accuracy: 0.9778\n",
            "Epoch 618/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1107 - accuracy: 0.9619 - val_loss: 0.1241 - val_accuracy: 0.9778\n",
            "Epoch 619/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1089 - accuracy: 0.9619 - val_loss: 0.1199 - val_accuracy: 0.9778\n",
            "Epoch 620/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1084 - accuracy: 0.9619 - val_loss: 0.1179 - val_accuracy: 0.9778\n",
            "Epoch 621/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1087 - accuracy: 0.9714 - val_loss: 0.1170 - val_accuracy: 0.9778\n",
            "Epoch 622/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1083 - accuracy: 0.9714 - val_loss: 0.1170 - val_accuracy: 0.9778\n",
            "Epoch 623/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1081 - accuracy: 0.9714 - val_loss: 0.1155 - val_accuracy: 0.9778\n",
            "Epoch 624/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1079 - accuracy: 0.9714 - val_loss: 0.1169 - val_accuracy: 0.9778\n",
            "Epoch 625/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1064 - accuracy: 0.9714 - val_loss: 0.1221 - val_accuracy: 0.9778\n",
            "Epoch 626/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1084 - accuracy: 0.9619 - val_loss: 0.1297 - val_accuracy: 0.9778\n",
            "Epoch 627/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1099 - accuracy: 0.9619 - val_loss: 0.1289 - val_accuracy: 0.9778\n",
            "Epoch 628/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1106 - accuracy: 0.9619 - val_loss: 0.1323 - val_accuracy: 0.9778\n",
            "Epoch 629/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1094 - accuracy: 0.9619 - val_loss: 0.1237 - val_accuracy: 0.9778\n",
            "Epoch 630/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1061 - accuracy: 0.9714 - val_loss: 0.1162 - val_accuracy: 0.9778\n",
            "Epoch 631/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1053 - accuracy: 0.9714 - val_loss: 0.1121 - val_accuracy: 0.9778\n",
            "Epoch 632/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1078 - accuracy: 0.9714 - val_loss: 0.1103 - val_accuracy: 0.9778\n",
            "Epoch 633/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1086 - accuracy: 0.9714 - val_loss: 0.1102 - val_accuracy: 0.9778\n",
            "Epoch 634/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1078 - accuracy: 0.9714 - val_loss: 0.1103 - val_accuracy: 0.9778\n",
            "Epoch 635/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1067 - accuracy: 0.9714 - val_loss: 0.1117 - val_accuracy: 0.9778\n",
            "Epoch 636/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1051 - accuracy: 0.9714 - val_loss: 0.1143 - val_accuracy: 0.9778\n",
            "Epoch 637/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1053 - accuracy: 0.9619 - val_loss: 0.1184 - val_accuracy: 0.9778\n",
            "Epoch 638/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1047 - accuracy: 0.9619 - val_loss: 0.1191 - val_accuracy: 0.9778\n",
            "Epoch 639/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1047 - accuracy: 0.9619 - val_loss: 0.1198 - val_accuracy: 0.9778\n",
            "Epoch 640/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1044 - accuracy: 0.9619 - val_loss: 0.1185 - val_accuracy: 0.9778\n",
            "Epoch 641/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1044 - accuracy: 0.9619 - val_loss: 0.1180 - val_accuracy: 0.9778\n",
            "Epoch 642/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1036 - accuracy: 0.9714 - val_loss: 0.1155 - val_accuracy: 0.9778\n",
            "Epoch 643/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1036 - accuracy: 0.9619 - val_loss: 0.1137 - val_accuracy: 0.9778\n",
            "Epoch 644/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1027 - accuracy: 0.9619 - val_loss: 0.1156 - val_accuracy: 0.9778\n",
            "Epoch 645/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1037 - accuracy: 0.9619 - val_loss: 0.1191 - val_accuracy: 0.9778\n",
            "Epoch 646/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1034 - accuracy: 0.9619 - val_loss: 0.1167 - val_accuracy: 0.9778\n",
            "Epoch 647/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1025 - accuracy: 0.9619 - val_loss: 0.1135 - val_accuracy: 0.9778\n",
            "Epoch 648/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1019 - accuracy: 0.9619 - val_loss: 0.1119 - val_accuracy: 0.9778\n",
            "Epoch 649/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1018 - accuracy: 0.9714 - val_loss: 0.1102 - val_accuracy: 0.9778\n",
            "Epoch 650/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1014 - accuracy: 0.9714 - val_loss: 0.1078 - val_accuracy: 0.9778\n",
            "Epoch 651/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1021 - accuracy: 0.9714 - val_loss: 0.1071 - val_accuracy: 0.9778\n",
            "Epoch 652/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1022 - accuracy: 0.9714 - val_loss: 0.1073 - val_accuracy: 0.9778\n",
            "Epoch 653/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1010 - accuracy: 0.9714 - val_loss: 0.1101 - val_accuracy: 0.9778\n",
            "Epoch 654/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1004 - accuracy: 0.9714 - val_loss: 0.1137 - val_accuracy: 0.9778\n",
            "Epoch 655/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1014 - accuracy: 0.9619 - val_loss: 0.1135 - val_accuracy: 0.9778\n",
            "Epoch 656/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1005 - accuracy: 0.9714 - val_loss: 0.1178 - val_accuracy: 0.9778\n",
            "Epoch 657/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1019 - accuracy: 0.9619 - val_loss: 0.1193 - val_accuracy: 0.9778\n",
            "Epoch 658/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1015 - accuracy: 0.9619 - val_loss: 0.1149 - val_accuracy: 0.9778\n",
            "Epoch 659/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1022 - accuracy: 0.9619 - val_loss: 0.1100 - val_accuracy: 0.9778\n",
            "Epoch 660/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0995 - accuracy: 0.9619 - val_loss: 0.1098 - val_accuracy: 0.9778\n",
            "Epoch 661/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0992 - accuracy: 0.9619 - val_loss: 0.1102 - val_accuracy: 0.9778\n",
            "Epoch 662/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0991 - accuracy: 0.9619 - val_loss: 0.1096 - val_accuracy: 0.9778\n",
            "Epoch 663/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0992 - accuracy: 0.9619 - val_loss: 0.1070 - val_accuracy: 0.9778\n",
            "Epoch 664/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0990 - accuracy: 0.9714 - val_loss: 0.1063 - val_accuracy: 0.9778\n",
            "Epoch 665/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0984 - accuracy: 0.9714 - val_loss: 0.1072 - val_accuracy: 0.9778\n",
            "Epoch 666/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0981 - accuracy: 0.9714 - val_loss: 0.1078 - val_accuracy: 0.9778\n",
            "Epoch 667/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0980 - accuracy: 0.9714 - val_loss: 0.1078 - val_accuracy: 0.9778\n",
            "Epoch 668/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0977 - accuracy: 0.9619 - val_loss: 0.1084 - val_accuracy: 0.9778\n",
            "Epoch 669/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0977 - accuracy: 0.9619 - val_loss: 0.1100 - val_accuracy: 0.9778\n",
            "Epoch 670/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0979 - accuracy: 0.9619 - val_loss: 0.1133 - val_accuracy: 0.9778\n",
            "Epoch 671/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0984 - accuracy: 0.9619 - val_loss: 0.1128 - val_accuracy: 0.9778\n",
            "Epoch 672/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0983 - accuracy: 0.9619 - val_loss: 0.1122 - val_accuracy: 0.9778\n",
            "Epoch 673/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0980 - accuracy: 0.9619 - val_loss: 0.1077 - val_accuracy: 0.9778\n",
            "Epoch 674/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0967 - accuracy: 0.9619 - val_loss: 0.1064 - val_accuracy: 0.9778\n",
            "Epoch 675/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0969 - accuracy: 0.9619 - val_loss: 0.1075 - val_accuracy: 0.9778\n",
            "Epoch 676/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0964 - accuracy: 0.9619 - val_loss: 0.1077 - val_accuracy: 0.9778\n",
            "Epoch 677/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0962 - accuracy: 0.9619 - val_loss: 0.1064 - val_accuracy: 0.9778\n",
            "Epoch 678/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0956 - accuracy: 0.9619 - val_loss: 0.1037 - val_accuracy: 0.9778\n",
            "Epoch 679/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0967 - accuracy: 0.9714 - val_loss: 0.1005 - val_accuracy: 0.9778\n",
            "Epoch 680/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0973 - accuracy: 0.9714 - val_loss: 0.1003 - val_accuracy: 0.9778\n",
            "Epoch 681/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0970 - accuracy: 0.9714 - val_loss: 0.1000 - val_accuracy: 0.9778\n",
            "Epoch 682/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0967 - accuracy: 0.9714 - val_loss: 0.1010 - val_accuracy: 0.9778\n",
            "Epoch 683/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0942 - accuracy: 0.9714 - val_loss: 0.1043 - val_accuracy: 0.9778\n",
            "Epoch 684/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0955 - accuracy: 0.9619 - val_loss: 0.1100 - val_accuracy: 0.9778\n",
            "Epoch 685/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0966 - accuracy: 0.9619 - val_loss: 0.1090 - val_accuracy: 0.9778\n",
            "Epoch 686/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0953 - accuracy: 0.9619 - val_loss: 0.1013 - val_accuracy: 0.9778\n",
            "Epoch 687/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0939 - accuracy: 0.9714 - val_loss: 0.0994 - val_accuracy: 0.9778\n",
            "Epoch 688/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0951 - accuracy: 0.9714 - val_loss: 0.0987 - val_accuracy: 0.9778\n",
            "Epoch 689/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0956 - accuracy: 0.9714 - val_loss: 0.0984 - val_accuracy: 0.9778\n",
            "Epoch 690/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0960 - accuracy: 0.9714 - val_loss: 0.0994 - val_accuracy: 0.9778\n",
            "Epoch 691/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0942 - accuracy: 0.9714 - val_loss: 0.1000 - val_accuracy: 0.9778\n",
            "Epoch 692/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0936 - accuracy: 0.9714 - val_loss: 0.1000 - val_accuracy: 0.9778\n",
            "Epoch 693/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0932 - accuracy: 0.9714 - val_loss: 0.0997 - val_accuracy: 0.9778\n",
            "Epoch 694/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0941 - accuracy: 0.9714 - val_loss: 0.1001 - val_accuracy: 0.9778\n",
            "Epoch 695/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0932 - accuracy: 0.9714 - val_loss: 0.0981 - val_accuracy: 0.9778\n",
            "Epoch 696/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0934 - accuracy: 0.9714 - val_loss: 0.0982 - val_accuracy: 0.9778\n",
            "Epoch 697/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0932 - accuracy: 0.9714 - val_loss: 0.0991 - val_accuracy: 0.9778\n",
            "Epoch 698/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0926 - accuracy: 0.9714 - val_loss: 0.0992 - val_accuracy: 0.9778\n",
            "Epoch 699/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0927 - accuracy: 0.9714 - val_loss: 0.0977 - val_accuracy: 0.9778\n",
            "Epoch 700/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0927 - accuracy: 0.9714 - val_loss: 0.0977 - val_accuracy: 0.9778\n",
            "Epoch 701/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0923 - accuracy: 0.9714 - val_loss: 0.0992 - val_accuracy: 0.9778\n",
            "Epoch 702/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0920 - accuracy: 0.9714 - val_loss: 0.1002 - val_accuracy: 0.9778\n",
            "Epoch 703/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0914 - accuracy: 0.9714 - val_loss: 0.1017 - val_accuracy: 0.9778\n",
            "Epoch 704/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0923 - accuracy: 0.9524 - val_loss: 0.1032 - val_accuracy: 0.9778\n",
            "Epoch 705/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0915 - accuracy: 0.9619 - val_loss: 0.0999 - val_accuracy: 0.9778\n",
            "Epoch 706/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0909 - accuracy: 0.9714 - val_loss: 0.0988 - val_accuracy: 0.9778\n",
            "Epoch 707/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0910 - accuracy: 0.9714 - val_loss: 0.0984 - val_accuracy: 0.9778\n",
            "Epoch 708/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0912 - accuracy: 0.9714 - val_loss: 0.1000 - val_accuracy: 0.9778\n",
            "Epoch 709/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0909 - accuracy: 0.9714 - val_loss: 0.0979 - val_accuracy: 0.9778\n",
            "Epoch 710/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0904 - accuracy: 0.9714 - val_loss: 0.0978 - val_accuracy: 0.9778\n",
            "Epoch 711/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0902 - accuracy: 0.9714 - val_loss: 0.0973 - val_accuracy: 0.9778\n",
            "Epoch 712/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0903 - accuracy: 0.9714 - val_loss: 0.0960 - val_accuracy: 0.9778\n",
            "Epoch 713/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0907 - accuracy: 0.9714 - val_loss: 0.0955 - val_accuracy: 0.9778\n",
            "Epoch 714/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0909 - accuracy: 0.9714 - val_loss: 0.0956 - val_accuracy: 0.9778\n",
            "Epoch 715/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0905 - accuracy: 0.9714 - val_loss: 0.0993 - val_accuracy: 0.9778\n",
            "Epoch 716/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0903 - accuracy: 0.9524 - val_loss: 0.1027 - val_accuracy: 0.9778\n",
            "Epoch 717/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0902 - accuracy: 0.9524 - val_loss: 0.1008 - val_accuracy: 0.9778\n",
            "Epoch 718/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0896 - accuracy: 0.9524 - val_loss: 0.0986 - val_accuracy: 0.9778\n",
            "Epoch 719/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0890 - accuracy: 0.9714 - val_loss: 0.0968 - val_accuracy: 0.9778\n",
            "Epoch 720/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0885 - accuracy: 0.9714 - val_loss: 0.0939 - val_accuracy: 0.9778\n",
            "Epoch 721/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0916 - accuracy: 0.9714 - val_loss: 0.0934 - val_accuracy: 0.9778\n",
            "Epoch 722/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0893 - accuracy: 0.9714 - val_loss: 0.0981 - val_accuracy: 0.9778\n",
            "Epoch 723/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0883 - accuracy: 0.9619 - val_loss: 0.1026 - val_accuracy: 0.9778\n",
            "Epoch 724/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0892 - accuracy: 0.9619 - val_loss: 0.1046 - val_accuracy: 0.9778\n",
            "Epoch 725/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0903 - accuracy: 0.9619 - val_loss: 0.1051 - val_accuracy: 0.9778\n",
            "Epoch 726/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0903 - accuracy: 0.9619 - val_loss: 0.1022 - val_accuracy: 0.9778\n",
            "Epoch 727/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0889 - accuracy: 0.9619 - val_loss: 0.0971 - val_accuracy: 0.9778\n",
            "Epoch 728/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0877 - accuracy: 0.9714 - val_loss: 0.0931 - val_accuracy: 0.9778\n",
            "Epoch 729/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0880 - accuracy: 0.9714 - val_loss: 0.0920 - val_accuracy: 0.9778\n",
            "Epoch 730/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0903 - accuracy: 0.9714 - val_loss: 0.0915 - val_accuracy: 0.9778\n",
            "Epoch 731/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0897 - accuracy: 0.9714 - val_loss: 0.0931 - val_accuracy: 0.9778\n",
            "Epoch 732/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0871 - accuracy: 0.9714 - val_loss: 0.0946 - val_accuracy: 0.9778\n",
            "Epoch 733/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0878 - accuracy: 0.9714 - val_loss: 0.0973 - val_accuracy: 0.9778\n",
            "Epoch 734/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0870 - accuracy: 0.9619 - val_loss: 0.0976 - val_accuracy: 0.9778\n",
            "Epoch 735/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0872 - accuracy: 0.9619 - val_loss: 0.0968 - val_accuracy: 0.9778\n",
            "Epoch 736/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0902 - accuracy: 0.9619 - val_loss: 0.0931 - val_accuracy: 0.9778\n",
            "Epoch 737/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0868 - accuracy: 0.9714 - val_loss: 0.0951 - val_accuracy: 0.9778\n",
            "Epoch 738/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0862 - accuracy: 0.9714 - val_loss: 0.0942 - val_accuracy: 0.9778\n",
            "Epoch 739/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0868 - accuracy: 0.9714 - val_loss: 0.0929 - val_accuracy: 0.9778\n",
            "Epoch 740/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0863 - accuracy: 0.9714 - val_loss: 0.0930 - val_accuracy: 0.9778\n",
            "Epoch 741/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0859 - accuracy: 0.9714 - val_loss: 0.0928 - val_accuracy: 0.9778\n",
            "Epoch 742/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0858 - accuracy: 0.9714 - val_loss: 0.0932 - val_accuracy: 0.9778\n",
            "Epoch 743/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0856 - accuracy: 0.9714 - val_loss: 0.0940 - val_accuracy: 0.9778\n",
            "Epoch 744/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0859 - accuracy: 0.9714 - val_loss: 0.0931 - val_accuracy: 0.9778\n",
            "Epoch 745/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0854 - accuracy: 0.9714 - val_loss: 0.0929 - val_accuracy: 0.9778\n",
            "Epoch 746/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0858 - accuracy: 0.9714 - val_loss: 0.0925 - val_accuracy: 0.9778\n",
            "Epoch 747/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0857 - accuracy: 0.9714 - val_loss: 0.0929 - val_accuracy: 0.9778\n",
            "Epoch 748/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0848 - accuracy: 0.9714 - val_loss: 0.0977 - val_accuracy: 0.9778\n",
            "Epoch 749/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0868 - accuracy: 0.9619 - val_loss: 0.1019 - val_accuracy: 0.9778\n",
            "Epoch 750/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0875 - accuracy: 0.9619 - val_loss: 0.1002 - val_accuracy: 0.9778\n",
            "Epoch 751/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0857 - accuracy: 0.9619 - val_loss: 0.0954 - val_accuracy: 0.9778\n",
            "Epoch 752/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0856 - accuracy: 0.9714 - val_loss: 0.0918 - val_accuracy: 0.9778\n",
            "Epoch 753/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0847 - accuracy: 0.9714 - val_loss: 0.0910 - val_accuracy: 0.9778\n",
            "Epoch 754/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0842 - accuracy: 0.9714 - val_loss: 0.0919 - val_accuracy: 0.9778\n",
            "Epoch 755/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0837 - accuracy: 0.9714 - val_loss: 0.0948 - val_accuracy: 0.9778\n",
            "Epoch 756/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0851 - accuracy: 0.9524 - val_loss: 0.0978 - val_accuracy: 0.9778\n",
            "Epoch 757/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0848 - accuracy: 0.9619 - val_loss: 0.0946 - val_accuracy: 0.9778\n",
            "Epoch 758/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0842 - accuracy: 0.9619 - val_loss: 0.0905 - val_accuracy: 0.9778\n",
            "Epoch 759/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0835 - accuracy: 0.9714 - val_loss: 0.0892 - val_accuracy: 0.9778\n",
            "Epoch 760/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0840 - accuracy: 0.9714 - val_loss: 0.0888 - val_accuracy: 0.9778\n",
            "Epoch 761/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0835 - accuracy: 0.9714 - val_loss: 0.0898 - val_accuracy: 0.9778\n",
            "Epoch 762/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0839 - accuracy: 0.9714 - val_loss: 0.0912 - val_accuracy: 0.9778\n",
            "Epoch 763/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0836 - accuracy: 0.9714 - val_loss: 0.0898 - val_accuracy: 0.9778\n",
            "Epoch 764/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0832 - accuracy: 0.9714 - val_loss: 0.0894 - val_accuracy: 0.9778\n",
            "Epoch 765/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0830 - accuracy: 0.9714 - val_loss: 0.0881 - val_accuracy: 0.9778\n",
            "Epoch 766/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0836 - accuracy: 0.9714 - val_loss: 0.0882 - val_accuracy: 0.9778\n",
            "Epoch 767/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0830 - accuracy: 0.9714 - val_loss: 0.0881 - val_accuracy: 0.9778\n",
            "Epoch 768/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0828 - accuracy: 0.9714 - val_loss: 0.0887 - val_accuracy: 0.9778\n",
            "Epoch 769/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0826 - accuracy: 0.9714 - val_loss: 0.0890 - val_accuracy: 0.9778\n",
            "Epoch 770/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0826 - accuracy: 0.9714 - val_loss: 0.0897 - val_accuracy: 0.9778\n",
            "Epoch 771/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0828 - accuracy: 0.9714 - val_loss: 0.0917 - val_accuracy: 0.9778\n",
            "Epoch 772/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0825 - accuracy: 0.9619 - val_loss: 0.0929 - val_accuracy: 0.9778\n",
            "Epoch 773/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0826 - accuracy: 0.9524 - val_loss: 0.0917 - val_accuracy: 0.9778\n",
            "Epoch 774/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0820 - accuracy: 0.9714 - val_loss: 0.0898 - val_accuracy: 0.9778\n",
            "Epoch 775/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0823 - accuracy: 0.9714 - val_loss: 0.0879 - val_accuracy: 0.9778\n",
            "Epoch 776/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0820 - accuracy: 0.9714 - val_loss: 0.0888 - val_accuracy: 0.9778\n",
            "Epoch 777/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0823 - accuracy: 0.9714 - val_loss: 0.0902 - val_accuracy: 0.9778\n",
            "Epoch 778/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0819 - accuracy: 0.9714 - val_loss: 0.0895 - val_accuracy: 0.9778\n",
            "Epoch 779/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0814 - accuracy: 0.9714 - val_loss: 0.0893 - val_accuracy: 0.9778\n",
            "Epoch 780/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0815 - accuracy: 0.9714 - val_loss: 0.0901 - val_accuracy: 0.9778\n",
            "Epoch 781/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0813 - accuracy: 0.9714 - val_loss: 0.0880 - val_accuracy: 0.9778\n",
            "Epoch 782/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0810 - accuracy: 0.9714 - val_loss: 0.0875 - val_accuracy: 0.9778\n",
            "Epoch 783/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0812 - accuracy: 0.9714 - val_loss: 0.0860 - val_accuracy: 0.9778\n",
            "Epoch 784/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0816 - accuracy: 0.9714 - val_loss: 0.0860 - val_accuracy: 0.9778\n",
            "Epoch 785/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0832 - accuracy: 0.9714 - val_loss: 0.0889 - val_accuracy: 0.9778\n",
            "Epoch 786/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0808 - accuracy: 0.9714 - val_loss: 0.0878 - val_accuracy: 0.9778\n",
            "Epoch 787/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0813 - accuracy: 0.9714 - val_loss: 0.0860 - val_accuracy: 0.9778\n",
            "Epoch 788/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0805 - accuracy: 0.9714 - val_loss: 0.0864 - val_accuracy: 0.9778\n",
            "Epoch 789/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0815 - accuracy: 0.9714 - val_loss: 0.0873 - val_accuracy: 0.9778\n",
            "Epoch 790/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0799 - accuracy: 0.9714 - val_loss: 0.0861 - val_accuracy: 0.9778\n",
            "Epoch 791/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0811 - accuracy: 0.9714 - val_loss: 0.0850 - val_accuracy: 0.9778\n",
            "Epoch 792/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0796 - accuracy: 0.9714 - val_loss: 0.0872 - val_accuracy: 0.9778\n",
            "Epoch 793/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0800 - accuracy: 0.9714 - val_loss: 0.0906 - val_accuracy: 0.9778\n",
            "Epoch 794/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0804 - accuracy: 0.9524 - val_loss: 0.0929 - val_accuracy: 0.9778\n",
            "Epoch 795/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0818 - accuracy: 0.9619 - val_loss: 0.0946 - val_accuracy: 0.9778\n",
            "Epoch 796/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0818 - accuracy: 0.9619 - val_loss: 0.0930 - val_accuracy: 0.9778\n",
            "Epoch 797/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0812 - accuracy: 0.9524 - val_loss: 0.0899 - val_accuracy: 0.9778\n",
            "Epoch 798/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0800 - accuracy: 0.9524 - val_loss: 0.0906 - val_accuracy: 0.9778\n",
            "Epoch 799/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0805 - accuracy: 0.9524 - val_loss: 0.0928 - val_accuracy: 0.9778\n",
            "Epoch 800/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0809 - accuracy: 0.9619 - val_loss: 0.0912 - val_accuracy: 0.9778\n",
            "Epoch 801/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0790 - accuracy: 0.9619 - val_loss: 0.0859 - val_accuracy: 0.9778\n",
            "Epoch 802/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0787 - accuracy: 0.9714 - val_loss: 0.0836 - val_accuracy: 0.9778\n",
            "Epoch 803/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0797 - accuracy: 0.9714 - val_loss: 0.0829 - val_accuracy: 0.9778\n",
            "Epoch 804/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0800 - accuracy: 0.9714 - val_loss: 0.0829 - val_accuracy: 0.9778\n",
            "Epoch 805/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0798 - accuracy: 0.9714 - val_loss: 0.0830 - val_accuracy: 0.9778\n",
            "Epoch 806/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0791 - accuracy: 0.9714 - val_loss: 0.0847 - val_accuracy: 0.9778\n",
            "Epoch 807/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0788 - accuracy: 0.9714 - val_loss: 0.0867 - val_accuracy: 0.9778\n",
            "Epoch 808/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0788 - accuracy: 0.9714 - val_loss: 0.0871 - val_accuracy: 0.9778\n",
            "Epoch 809/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0784 - accuracy: 0.9714 - val_loss: 0.0897 - val_accuracy: 0.9778\n",
            "Epoch 810/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0797 - accuracy: 0.9524 - val_loss: 0.0908 - val_accuracy: 0.9778\n",
            "Epoch 811/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0791 - accuracy: 0.9524 - val_loss: 0.0883 - val_accuracy: 0.9778\n",
            "Epoch 812/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0796 - accuracy: 0.9524 - val_loss: 0.0853 - val_accuracy: 0.9778\n",
            "Epoch 813/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0786 - accuracy: 0.9714 - val_loss: 0.0855 - val_accuracy: 0.9778\n",
            "Epoch 814/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0778 - accuracy: 0.9714 - val_loss: 0.0835 - val_accuracy: 0.9778\n",
            "Epoch 815/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0778 - accuracy: 0.9714 - val_loss: 0.0834 - val_accuracy: 0.9778\n",
            "Epoch 816/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0775 - accuracy: 0.9714 - val_loss: 0.0844 - val_accuracy: 0.9778\n",
            "Epoch 817/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0772 - accuracy: 0.9714 - val_loss: 0.0874 - val_accuracy: 0.9778\n",
            "Epoch 818/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0781 - accuracy: 0.9619 - val_loss: 0.0895 - val_accuracy: 0.9778\n",
            "Epoch 819/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0798 - accuracy: 0.9524 - val_loss: 0.0900 - val_accuracy: 0.9778\n",
            "Epoch 820/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0783 - accuracy: 0.9524 - val_loss: 0.0876 - val_accuracy: 0.9778\n",
            "Epoch 821/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0779 - accuracy: 0.9619 - val_loss: 0.0836 - val_accuracy: 0.9778\n",
            "Epoch 822/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0770 - accuracy: 0.9714 - val_loss: 0.0838 - val_accuracy: 0.9778\n",
            "Epoch 823/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0767 - accuracy: 0.9714 - val_loss: 0.0849 - val_accuracy: 0.9778\n",
            "Epoch 824/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0775 - accuracy: 0.9714 - val_loss: 0.0848 - val_accuracy: 0.9778\n",
            "Epoch 825/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0766 - accuracy: 0.9714 - val_loss: 0.0815 - val_accuracy: 0.9778\n",
            "Epoch 826/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0769 - accuracy: 0.9714 - val_loss: 0.0808 - val_accuracy: 0.9778\n",
            "Epoch 827/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0785 - accuracy: 0.9714 - val_loss: 0.0808 - val_accuracy: 0.9778\n",
            "Epoch 828/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0762 - accuracy: 0.9714 - val_loss: 0.0828 - val_accuracy: 0.9778\n",
            "Epoch 829/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0773 - accuracy: 0.9619 - val_loss: 0.0880 - val_accuracy: 0.9778\n",
            "Epoch 830/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0780 - accuracy: 0.9524 - val_loss: 0.0915 - val_accuracy: 0.9778\n",
            "Epoch 831/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0785 - accuracy: 0.9619 - val_loss: 0.0901 - val_accuracy: 0.9778\n",
            "Epoch 832/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0774 - accuracy: 0.9524 - val_loss: 0.0860 - val_accuracy: 0.9778\n",
            "Epoch 833/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0756 - accuracy: 0.9714 - val_loss: 0.0822 - val_accuracy: 0.9778\n",
            "Epoch 834/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0756 - accuracy: 0.9714 - val_loss: 0.0810 - val_accuracy: 0.9778\n",
            "Epoch 835/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0774 - accuracy: 0.9714 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
            "Epoch 836/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0757 - accuracy: 0.9714 - val_loss: 0.0840 - val_accuracy: 0.9778\n",
            "Epoch 837/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0761 - accuracy: 0.9524 - val_loss: 0.0871 - val_accuracy: 0.9778\n",
            "Epoch 838/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0766 - accuracy: 0.9524 - val_loss: 0.0850 - val_accuracy: 0.9778\n",
            "Epoch 839/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0759 - accuracy: 0.9619 - val_loss: 0.0801 - val_accuracy: 0.9778\n",
            "Epoch 840/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0772 - accuracy: 0.9714 - val_loss: 0.0791 - val_accuracy: 0.9778\n",
            "Epoch 841/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0773 - accuracy: 0.9714 - val_loss: 0.0793 - val_accuracy: 0.9778\n",
            "Epoch 842/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0754 - accuracy: 0.9714 - val_loss: 0.0810 - val_accuracy: 0.9778\n",
            "Epoch 843/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0745 - accuracy: 0.9714 - val_loss: 0.0850 - val_accuracy: 0.9778\n",
            "Epoch 844/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0753 - accuracy: 0.9524 - val_loss: 0.0868 - val_accuracy: 0.9778\n",
            "Epoch 845/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0762 - accuracy: 0.9524 - val_loss: 0.0868 - val_accuracy: 0.9778\n",
            "Epoch 846/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0762 - accuracy: 0.9524 - val_loss: 0.0837 - val_accuracy: 0.9778\n",
            "Epoch 847/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0750 - accuracy: 0.9714 - val_loss: 0.0825 - val_accuracy: 0.9778\n",
            "Epoch 848/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0746 - accuracy: 0.9714 - val_loss: 0.0830 - val_accuracy: 0.9778\n",
            "Epoch 849/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0748 - accuracy: 0.9714 - val_loss: 0.0835 - val_accuracy: 0.9778\n",
            "Epoch 850/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0750 - accuracy: 0.9619 - val_loss: 0.0845 - val_accuracy: 0.9778\n",
            "Epoch 851/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0751 - accuracy: 0.9619 - val_loss: 0.0835 - val_accuracy: 0.9778\n",
            "Epoch 852/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0746 - accuracy: 0.9619 - val_loss: 0.0811 - val_accuracy: 0.9778\n",
            "Epoch 853/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0741 - accuracy: 0.9714 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
            "Epoch 854/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0742 - accuracy: 0.9714 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
            "Epoch 855/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0750 - accuracy: 0.9714 - val_loss: 0.0811 - val_accuracy: 0.9778\n",
            "Epoch 856/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0743 - accuracy: 0.9714 - val_loss: 0.0789 - val_accuracy: 0.9778\n",
            "Epoch 857/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0742 - accuracy: 0.9714 - val_loss: 0.0782 - val_accuracy: 0.9778\n",
            "Epoch 858/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0752 - accuracy: 0.9714 - val_loss: 0.0779 - val_accuracy: 0.9778\n",
            "Epoch 859/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0751 - accuracy: 0.9714 - val_loss: 0.0780 - val_accuracy: 0.9778\n",
            "Epoch 860/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0745 - accuracy: 0.9714 - val_loss: 0.0781 - val_accuracy: 0.9778\n",
            "Epoch 861/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0742 - accuracy: 0.9714 - val_loss: 0.0791 - val_accuracy: 0.9778\n",
            "Epoch 862/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0737 - accuracy: 0.9714 - val_loss: 0.0801 - val_accuracy: 0.9778\n",
            "Epoch 863/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0742 - accuracy: 0.9714 - val_loss: 0.0812 - val_accuracy: 0.9778\n",
            "Epoch 864/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0733 - accuracy: 0.9714 - val_loss: 0.0799 - val_accuracy: 0.9778\n",
            "Epoch 865/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0732 - accuracy: 0.9714 - val_loss: 0.0795 - val_accuracy: 0.9778\n",
            "Epoch 866/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0743 - accuracy: 0.9714 - val_loss: 0.0784 - val_accuracy: 0.9778\n",
            "Epoch 867/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0732 - accuracy: 0.9714 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
            "Epoch 868/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0734 - accuracy: 0.9619 - val_loss: 0.0836 - val_accuracy: 0.9778\n",
            "Epoch 869/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0737 - accuracy: 0.9524 - val_loss: 0.0841 - val_accuracy: 0.9778\n",
            "Epoch 870/1000\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0735 - accuracy: 0.9524 - val_loss: 0.0819 - val_accuracy: 0.9778\n",
            "Epoch 871/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0725 - accuracy: 0.9619 - val_loss: 0.0795 - val_accuracy: 0.9778\n",
            "Epoch 872/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0723 - accuracy: 0.9714 - val_loss: 0.0776 - val_accuracy: 0.9778\n",
            "Epoch 873/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0732 - accuracy: 0.9714 - val_loss: 0.0767 - val_accuracy: 0.9778\n",
            "Epoch 874/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0739 - accuracy: 0.9714 - val_loss: 0.0765 - val_accuracy: 0.9778\n",
            "Epoch 875/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0756 - accuracy: 0.9714 - val_loss: 0.0763 - val_accuracy: 0.9778\n",
            "Epoch 876/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0749 - accuracy: 0.9714 - val_loss: 0.0765 - val_accuracy: 0.9778\n",
            "Epoch 877/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0734 - accuracy: 0.9714 - val_loss: 0.0785 - val_accuracy: 0.9778\n",
            "Epoch 878/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0735 - accuracy: 0.9619 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
            "Epoch 879/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0730 - accuracy: 0.9619 - val_loss: 0.0810 - val_accuracy: 0.9778\n",
            "Epoch 880/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0728 - accuracy: 0.9619 - val_loss: 0.0804 - val_accuracy: 0.9778\n",
            "Epoch 881/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0721 - accuracy: 0.9714 - val_loss: 0.0803 - val_accuracy: 0.9778\n",
            "Epoch 882/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0720 - accuracy: 0.9714 - val_loss: 0.0801 - val_accuracy: 0.9778\n",
            "Epoch 883/1000\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0725 - accuracy: 0.9619 - val_loss: 0.0812 - val_accuracy: 0.9778\n",
            "Epoch 884/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0723 - accuracy: 0.9619 - val_loss: 0.0800 - val_accuracy: 0.9778\n",
            "Epoch 885/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0710 - accuracy: 0.9714 - val_loss: 0.0771 - val_accuracy: 0.9778\n",
            "Epoch 886/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0717 - accuracy: 0.9714 - val_loss: 0.0759 - val_accuracy: 0.9778\n",
            "Epoch 887/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0727 - accuracy: 0.9714 - val_loss: 0.0759 - val_accuracy: 0.9778\n",
            "Epoch 888/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0725 - accuracy: 0.9714 - val_loss: 0.0754 - val_accuracy: 0.9778\n",
            "Epoch 889/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0731 - accuracy: 0.9714 - val_loss: 0.0754 - val_accuracy: 0.9778\n",
            "Epoch 890/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0729 - accuracy: 0.9714 - val_loss: 0.0755 - val_accuracy: 0.9778\n",
            "Epoch 891/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0727 - accuracy: 0.9714 - val_loss: 0.0769 - val_accuracy: 0.9778\n",
            "Epoch 892/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0710 - accuracy: 0.9714 - val_loss: 0.0783 - val_accuracy: 0.9778\n",
            "Epoch 893/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0710 - accuracy: 0.9714 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
            "Epoch 894/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0718 - accuracy: 0.9619 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
            "Epoch 895/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0719 - accuracy: 0.9524 - val_loss: 0.0822 - val_accuracy: 0.9778\n",
            "Epoch 896/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0717 - accuracy: 0.9524 - val_loss: 0.0804 - val_accuracy: 0.9778\n",
            "Epoch 897/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0712 - accuracy: 0.9619 - val_loss: 0.0788 - val_accuracy: 0.9778\n",
            "Epoch 898/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0711 - accuracy: 0.9714 - val_loss: 0.0771 - val_accuracy: 0.9778\n",
            "Epoch 899/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0706 - accuracy: 0.9714 - val_loss: 0.0779 - val_accuracy: 0.9778\n",
            "Epoch 900/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0706 - accuracy: 0.9714 - val_loss: 0.0783 - val_accuracy: 0.9778\n",
            "Epoch 901/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0704 - accuracy: 0.9714 - val_loss: 0.0771 - val_accuracy: 0.9778\n",
            "Epoch 902/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0706 - accuracy: 0.9714 - val_loss: 0.0755 - val_accuracy: 0.9778\n",
            "Epoch 903/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0706 - accuracy: 0.9714 - val_loss: 0.0753 - val_accuracy: 0.9778\n",
            "Epoch 904/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0710 - accuracy: 0.9714 - val_loss: 0.0752 - val_accuracy: 0.9778\n",
            "Epoch 905/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0704 - accuracy: 0.9714 - val_loss: 0.0766 - val_accuracy: 0.9778\n",
            "Epoch 906/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0695 - accuracy: 0.9714 - val_loss: 0.0801 - val_accuracy: 0.9778\n",
            "Epoch 907/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0723 - accuracy: 0.9619 - val_loss: 0.0861 - val_accuracy: 0.9778\n",
            "Epoch 908/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0745 - accuracy: 0.9619 - val_loss: 0.0897 - val_accuracy: 0.9778\n",
            "Epoch 909/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0745 - accuracy: 0.9619 - val_loss: 0.0854 - val_accuracy: 0.9778\n",
            "Epoch 910/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0723 - accuracy: 0.9619 - val_loss: 0.0791 - val_accuracy: 0.9778\n",
            "Epoch 911/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0698 - accuracy: 0.9714 - val_loss: 0.0767 - val_accuracy: 0.9778\n",
            "Epoch 912/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0696 - accuracy: 0.9714 - val_loss: 0.0755 - val_accuracy: 0.9778\n",
            "Epoch 913/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0699 - accuracy: 0.9714 - val_loss: 0.0752 - val_accuracy: 0.9778\n",
            "Epoch 914/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0699 - accuracy: 0.9714 - val_loss: 0.0756 - val_accuracy: 0.9778\n",
            "Epoch 915/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0696 - accuracy: 0.9714 - val_loss: 0.0793 - val_accuracy: 0.9778\n",
            "Epoch 916/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0709 - accuracy: 0.9524 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
            "Epoch 917/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0711 - accuracy: 0.9524 - val_loss: 0.0813 - val_accuracy: 0.9778\n",
            "Epoch 918/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0700 - accuracy: 0.9619 - val_loss: 0.0770 - val_accuracy: 0.9778\n",
            "Epoch 919/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0682 - accuracy: 0.9714 - val_loss: 0.0741 - val_accuracy: 0.9778\n",
            "Epoch 920/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0709 - accuracy: 0.9714 - val_loss: 0.0733 - val_accuracy: 0.9778\n",
            "Epoch 921/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0724 - accuracy: 0.9810 - val_loss: 0.0732 - val_accuracy: 0.9778\n",
            "Epoch 922/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0724 - accuracy: 0.9714 - val_loss: 0.0734 - val_accuracy: 0.9778\n",
            "Epoch 923/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0703 - accuracy: 0.9714 - val_loss: 0.0738 - val_accuracy: 0.9778\n",
            "Epoch 924/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0697 - accuracy: 0.9714 - val_loss: 0.0743 - val_accuracy: 0.9778\n",
            "Epoch 925/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0696 - accuracy: 0.9714 - val_loss: 0.0744 - val_accuracy: 0.9778\n",
            "Epoch 926/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0690 - accuracy: 0.9714 - val_loss: 0.0760 - val_accuracy: 0.9778\n",
            "Epoch 927/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0691 - accuracy: 0.9714 - val_loss: 0.0772 - val_accuracy: 0.9778\n",
            "Epoch 928/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0686 - accuracy: 0.9619 - val_loss: 0.0755 - val_accuracy: 0.9778\n",
            "Epoch 929/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0684 - accuracy: 0.9714 - val_loss: 0.0748 - val_accuracy: 0.9778\n",
            "Epoch 930/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0687 - accuracy: 0.9714 - val_loss: 0.0744 - val_accuracy: 0.9778\n",
            "Epoch 931/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0685 - accuracy: 0.9714 - val_loss: 0.0746 - val_accuracy: 0.9778\n",
            "Epoch 932/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0682 - accuracy: 0.9714 - val_loss: 0.0752 - val_accuracy: 0.9778\n",
            "Epoch 933/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0694 - accuracy: 0.9714 - val_loss: 0.0765 - val_accuracy: 0.9778\n",
            "Epoch 934/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0684 - accuracy: 0.9619 - val_loss: 0.0758 - val_accuracy: 0.9778\n",
            "Epoch 935/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0685 - accuracy: 0.9714 - val_loss: 0.0752 - val_accuracy: 0.9778\n",
            "Epoch 936/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0680 - accuracy: 0.9714 - val_loss: 0.0753 - val_accuracy: 0.9778\n",
            "Epoch 937/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0680 - accuracy: 0.9714 - val_loss: 0.0752 - val_accuracy: 0.9778\n",
            "Epoch 938/1000\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0679 - accuracy: 0.9714 - val_loss: 0.0747 - val_accuracy: 0.9778\n",
            "Epoch 939/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0678 - accuracy: 0.9714 - val_loss: 0.0732 - val_accuracy: 0.9778\n",
            "Epoch 940/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0679 - accuracy: 0.9714 - val_loss: 0.0724 - val_accuracy: 0.9778\n",
            "Epoch 941/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0688 - accuracy: 0.9714 - val_loss: 0.0723 - val_accuracy: 0.9778\n",
            "Epoch 942/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0686 - accuracy: 0.9714 - val_loss: 0.0728 - val_accuracy: 0.9778\n",
            "Epoch 943/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0688 - accuracy: 0.9714 - val_loss: 0.0743 - val_accuracy: 0.9778\n",
            "Epoch 944/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0677 - accuracy: 0.9714 - val_loss: 0.0739 - val_accuracy: 0.9778\n",
            "Epoch 945/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0684 - accuracy: 0.9714 - val_loss: 0.0725 - val_accuracy: 0.9778\n",
            "Epoch 946/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0693 - accuracy: 0.9714 - val_loss: 0.0721 - val_accuracy: 0.9778\n",
            "Epoch 947/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0683 - accuracy: 0.9714 - val_loss: 0.0730 - val_accuracy: 0.9778\n",
            "Epoch 948/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0674 - accuracy: 0.9714 - val_loss: 0.0734 - val_accuracy: 0.9778\n",
            "Epoch 949/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0679 - accuracy: 0.9714 - val_loss: 0.0753 - val_accuracy: 0.9778\n",
            "Epoch 950/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0673 - accuracy: 0.9619 - val_loss: 0.0763 - val_accuracy: 0.9778\n",
            "Epoch 951/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0675 - accuracy: 0.9619 - val_loss: 0.0785 - val_accuracy: 0.9778\n",
            "Epoch 952/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0680 - accuracy: 0.9619 - val_loss: 0.0768 - val_accuracy: 0.9778\n",
            "Epoch 953/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0672 - accuracy: 0.9619 - val_loss: 0.0750 - val_accuracy: 0.9778\n",
            "Epoch 954/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0664 - accuracy: 0.9714 - val_loss: 0.0724 - val_accuracy: 0.9778\n",
            "Epoch 955/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0678 - accuracy: 0.9714 - val_loss: 0.0713 - val_accuracy: 0.9778\n",
            "Epoch 956/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0690 - accuracy: 0.9714 - val_loss: 0.0712 - val_accuracy: 0.9778\n",
            "Epoch 957/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0683 - accuracy: 0.9714 - val_loss: 0.0716 - val_accuracy: 0.9778\n",
            "Epoch 958/1000\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0662 - accuracy: 0.9714 - val_loss: 0.0736 - val_accuracy: 0.9778\n",
            "Epoch 959/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0668 - accuracy: 0.9619 - val_loss: 0.0774 - val_accuracy: 0.9778\n",
            "Epoch 960/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0682 - accuracy: 0.9619 - val_loss: 0.0777 - val_accuracy: 0.9778\n",
            "Epoch 961/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0679 - accuracy: 0.9619 - val_loss: 0.0725 - val_accuracy: 0.9778\n",
            "Epoch 962/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0676 - accuracy: 0.9714 - val_loss: 0.0715 - val_accuracy: 0.9778\n",
            "Epoch 963/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0671 - accuracy: 0.9714 - val_loss: 0.0726 - val_accuracy: 0.9778\n",
            "Epoch 964/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0672 - accuracy: 0.9619 - val_loss: 0.0757 - val_accuracy: 0.9778\n",
            "Epoch 965/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0669 - accuracy: 0.9619 - val_loss: 0.0794 - val_accuracy: 0.9778\n",
            "Epoch 966/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0687 - accuracy: 0.9524 - val_loss: 0.0810 - val_accuracy: 0.9778\n",
            "Epoch 967/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0686 - accuracy: 0.9524 - val_loss: 0.0783 - val_accuracy: 0.9778\n",
            "Epoch 968/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0670 - accuracy: 0.9619 - val_loss: 0.0755 - val_accuracy: 0.9778\n",
            "Epoch 969/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0659 - accuracy: 0.9619 - val_loss: 0.0721 - val_accuracy: 0.9778\n",
            "Epoch 970/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0676 - accuracy: 0.9714 - val_loss: 0.0707 - val_accuracy: 0.9778\n",
            "Epoch 971/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0672 - accuracy: 0.9714 - val_loss: 0.0706 - val_accuracy: 0.9778\n",
            "Epoch 972/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0672 - accuracy: 0.9714 - val_loss: 0.0705 - val_accuracy: 0.9778\n",
            "Epoch 973/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0680 - accuracy: 0.9714 - val_loss: 0.0711 - val_accuracy: 0.9778\n",
            "Epoch 974/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0665 - accuracy: 0.9714 - val_loss: 0.0719 - val_accuracy: 0.9778\n",
            "Epoch 975/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0657 - accuracy: 0.9714 - val_loss: 0.0723 - val_accuracy: 0.9778\n",
            "Epoch 976/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0663 - accuracy: 0.9714 - val_loss: 0.0728 - val_accuracy: 0.9778\n",
            "Epoch 977/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0654 - accuracy: 0.9714 - val_loss: 0.0715 - val_accuracy: 0.9778\n",
            "Epoch 978/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0654 - accuracy: 0.9714 - val_loss: 0.0706 - val_accuracy: 0.9778\n",
            "Epoch 979/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0661 - accuracy: 0.9714 - val_loss: 0.0705 - val_accuracy: 0.9778\n",
            "Epoch 980/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0667 - accuracy: 0.9714 - val_loss: 0.0702 - val_accuracy: 0.9778\n",
            "Epoch 981/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0667 - accuracy: 0.9714 - val_loss: 0.0703 - val_accuracy: 0.9778\n",
            "Epoch 982/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0659 - accuracy: 0.9714 - val_loss: 0.0714 - val_accuracy: 0.9778\n",
            "Epoch 983/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0652 - accuracy: 0.9714 - val_loss: 0.0729 - val_accuracy: 0.9778\n",
            "Epoch 984/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0653 - accuracy: 0.9714 - val_loss: 0.0742 - val_accuracy: 0.9778\n",
            "Epoch 985/1000\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0654 - accuracy: 0.9619 - val_loss: 0.0743 - val_accuracy: 0.9778\n",
            "Epoch 986/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0657 - accuracy: 0.9619 - val_loss: 0.0743 - val_accuracy: 0.9778\n",
            "Epoch 987/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0659 - accuracy: 0.9619 - val_loss: 0.0765 - val_accuracy: 0.9778\n",
            "Epoch 988/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0662 - accuracy: 0.9619 - val_loss: 0.0738 - val_accuracy: 0.9778\n",
            "Epoch 989/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0648 - accuracy: 0.9619 - val_loss: 0.0719 - val_accuracy: 0.9778\n",
            "Epoch 990/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0644 - accuracy: 0.9714 - val_loss: 0.0699 - val_accuracy: 0.9778\n",
            "Epoch 991/1000\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0656 - accuracy: 0.9714 - val_loss: 0.0696 - val_accuracy: 0.9778\n",
            "Epoch 992/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0668 - accuracy: 0.9714 - val_loss: 0.0699 - val_accuracy: 0.9778\n",
            "Epoch 993/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0655 - accuracy: 0.9714 - val_loss: 0.0699 - val_accuracy: 0.9778\n",
            "Epoch 994/1000\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0656 - accuracy: 0.9714 - val_loss: 0.0699 - val_accuracy: 0.9778\n",
            "Epoch 995/1000\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0656 - accuracy: 0.9714 - val_loss: 0.0697 - val_accuracy: 0.9778\n",
            "Epoch 996/1000\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0658 - accuracy: 0.9714 - val_loss: 0.0695 - val_accuracy: 0.9778\n",
            "Epoch 997/1000\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0655 - accuracy: 0.9714 - val_loss: 0.0708 - val_accuracy: 0.9778\n",
            "Epoch 998/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0648 - accuracy: 0.9714 - val_loss: 0.0719 - val_accuracy: 0.9778\n",
            "Epoch 999/1000\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0641 - accuracy: 0.9714 - val_loss: 0.0703 - val_accuracy: 0.9778\n",
            "Epoch 1000/1000\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0640 - accuracy: 0.9714 - val_loss: 0.0691 - val_accuracy: 0.9778\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29f4d00670>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsões e mudar a variável para True ou False de acordo com o threshold 0.5\n",
        "previsoesrn = modelo.predict(X_testern)\n",
        "previsoesrn = (previsoesrn > 0.5)\n",
        "previsoesrn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YoEEBo_3mIS",
        "outputId": "25a67b79-5ada-40eb-db23-34ec7d8c92c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False,  True],\n",
              "       [False,  True, False],\n",
              "       [ True, False, False],\n",
              "       [False, False,  True],\n",
              "       [ True, False, False],\n",
              "       [False, False,  True],\n",
              "       [ True, False, False],\n",
              "       [False,  True, False],\n",
              "       [False,  True, False],\n",
              "       [False,  True, False],\n",
              "       [False, False,  True],\n",
              "       [False,  True, False],\n",
              "       [False,  True, False],\n",
              "       [False,  True, False],\n",
              "       [False,  True, False],\n",
              "       [ True, False, False],\n",
              "       [False,  True, False],\n",
              "       [False,  True, False],\n",
              "       [ True, False, False],\n",
              "       [ True, False, False],\n",
              "       [False, False,  True],\n",
              "       [False,  True, False],\n",
              "       [ True, False, False],\n",
              "       [ True, False, False],\n",
              "       [False, False,  True],\n",
              "       [ True, False, False],\n",
              "       [ True, False, False],\n",
              "       [False,  True, False],\n",
              "       [False,  True, False],\n",
              "       [ True, False, False],\n",
              "       [False, False,  True],\n",
              "       [False,  True, False],\n",
              "       [ True, False, False],\n",
              "       [False, False,  True],\n",
              "       [False, False,  True],\n",
              "       [False,  True, False],\n",
              "       [ True, False, False],\n",
              "       [False, False,  True],\n",
              "       [False,  True, False],\n",
              "       [False,  True, False],\n",
              "       [False, False,  True],\n",
              "       [ True, False, False],\n",
              "       [False, False,  True],\n",
              "       [ True, False, False],\n",
              "       [ True, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Como é um problema com três saídas, precisamos buscar a posição que possui o maior valor (são retornados 3 valores)\n",
        "y_teste_matrix = [np.argmax(t) for t in y_testern]\n",
        "y_previsao_matrix = [np.argmax(t) for t in previsoesrn]"
      ],
      "metadata": {
        "id": "jpTbPMwj3qOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Geração da matriz de confusão, diag principal sao os acertos\n",
        "confusaorn = confusion_matrix(y_teste_matrix, y_previsao_matrix)\n",
        "confusaorn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMnFmVvp3wZs",
        "outputId": "4edcc79d-de36-4d7a-c485-71d9a567a7e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16,  0,  0],\n",
              "       [ 0, 17,  1],\n",
              "       [ 0,  0, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#deep learning"
      ],
      "metadata": {
        "id": "clQJyMBB_o0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bOzqaMVBGaD",
        "outputId": "e0fc824c-d630-46a3-d95a-238da99b5dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.29.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.datasets import mnist"
      ],
      "metadata": {
        "id": "hiWnxjiU_rAu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenção dos dados e divisão automática entre treinamento e teste\n",
        "(X_treinoimg, y_treinoimg), (X_testeimg, y_testeimg) = mnist.load_data()\n",
        "# Visualização de imagens específicas\n",
        "plt.imshow(X_treinoimg[21], cmap = 'gray')\n",
        "plt.title(y_treinoimg[21]) #gerou um zero na posicao 21"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "JI5jVvOyBMaN",
        "outputId": "d9ca8839-0850-48f4-c905-6dec01580ba2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '0')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mudança de dimensão, originalmente está em 28x28 e precisamos 784, muda de vetor pra matriz\n",
        "X_treinoimg = X_treinoimg.reshape((len(X_treinoimg), np.prod(X_treinoimg.shape[1:])))\n",
        "X_testeimg = X_testeimg.reshape((len(X_testeimg), np.prod(X_testeimg.shape[1:])))\n",
        "X_testeimg[0]"
      ],
      "metadata": {
        "id": "fXQ6DRPYBQKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc336c80-7380-4b5c-e0df-f6e43f623afe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0, 222, 254, 254, 254,\n",
              "       254, 241, 198, 198, 198, 198, 198, 198, 198, 198, 170,  52,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  67, 114,\n",
              "        72, 114, 163, 227, 254, 225, 254, 254, 254, 250, 229, 254, 254,\n",
              "       140,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  17,  66,  14,  67,  67,  67,  59,  21,\n",
              "       236, 254, 106,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,  83, 253, 209,  18,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 133, 254, 187,   5,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   9, 205, 248,  58,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 126, 254, 182,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  75, 251,\n",
              "       240,  57,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  19,\n",
              "       221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         3, 203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  38, 254, 254,  77,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  31, 224, 254, 115,   1,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0, 133, 254, 254,  52,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,  61, 242, 254, 254,  52,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254, 219,  40,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
              "        18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformação dos dados para float para podermos normalizar os dados\n",
        "X_treinoimg = X_treinoimg.astype('float32')\n",
        "X_testeimg = X_testeimg.astype('float32')"
      ],
      "metadata": {
        "id": "P1x3W_0cBTXS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalização (255 é o valor máximo de um pixel)\n",
        "X_treinoimg /= 255\n",
        "X_testeimg /= 255"
      ],
      "metadata": {
        "id": "hBFOx9qWBX5S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformação para o formato dummy (temos 10 classes)\n",
        "y_treinoimg = np_utils.to_categorical(y_treinoimg, 10)\n",
        "y_testeimg = np_utils.to_categorical(y_testeimg, 10)\n",
        "y_testeimg[0] #vetor com posicao do caracter==1"
      ],
      "metadata": {
        "id": "OZj7CqlABdwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f803582-50e7-413f-eef7-ab46a8167d0c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Estrutura da rede neural: 784 - 64 - 64 - 64 - 10\n",
        "# Dropout é utilizado para zerar uma porcentagem dos neurônios, para evitar o overfitting(dropouting transf valores iguaal a zero pra ñ ter super ajuste no modelo)\n",
        "modeloimg = Sequential()\n",
        "modeloimg.add(Dense(units = 64, activation = 'relu', input_dim = 784)) #densa= conectadas, 64 neuronios dessa camada conectada com 64 da seguinte\n",
        "modeloimg.add(Dropout(0.2))\n",
        "modeloimg.add(Dense(units = 64, activation = 'relu'))\n",
        "modeloimg.add(Dropout(0.2))\n",
        "modeloimg.add(Dense(units = 64, activation = 'relu'))\n",
        "modeloimg.add(Dropout(0.2))#20%\n",
        "#camada de saida, softmax probabilidade\n",
        "modeloimg.add(Dense(units = 10, activation = 'softmax')) #de 0 a 9 ==10 caracteres de saida"
      ],
      "metadata": {
        "id": "iCm1yR-aBi2t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização da estrutura da rede neural\n",
        "modeloimg.summary()"
      ],
      "metadata": {
        "id": "wNW34x2yBnzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8f22e72-2836-4e93-d856-2a6319599273"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59,210\n",
            "Trainable params: 59,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração dos parâmetros da rede neural e treinamento (utilizando base de dados de validação)\n",
        "# Na variável historico temos os histórico das execuções (erro e accuracy). acurancy 1=teste\n",
        "modeloimg.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
        "               metrics = ['accuracy'])\n",
        "historico = modeloimg.fit(X_treinoimg, y_treinoimg, epochs = 20,\n",
        "                       validation_data = (X_testeimg, y_testeimg))"
      ],
      "metadata": {
        "id": "3vz-piLBBtKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50064c5c-c257-4a8d-f5c7-46a07a821a97"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4487 - accuracy: 0.8640 - val_loss: 0.1654 - val_accuracy: 0.9503\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2314 - accuracy: 0.9331 - val_loss: 0.1293 - val_accuracy: 0.9616\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1908 - accuracy: 0.9446 - val_loss: 0.1210 - val_accuracy: 0.9654\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1691 - accuracy: 0.9505 - val_loss: 0.1006 - val_accuracy: 0.9718\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1523 - accuracy: 0.9563 - val_loss: 0.0954 - val_accuracy: 0.9713\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1432 - accuracy: 0.9571 - val_loss: 0.0980 - val_accuracy: 0.9706\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1331 - accuracy: 0.9620 - val_loss: 0.1003 - val_accuracy: 0.9709\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1255 - accuracy: 0.9630 - val_loss: 0.1002 - val_accuracy: 0.9719\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1206 - accuracy: 0.9645 - val_loss: 0.0890 - val_accuracy: 0.9741\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1151 - accuracy: 0.9658 - val_loss: 0.0954 - val_accuracy: 0.9747\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1127 - accuracy: 0.9665 - val_loss: 0.0951 - val_accuracy: 0.9739\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1085 - accuracy: 0.9675 - val_loss: 0.0912 - val_accuracy: 0.9743\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1043 - accuracy: 0.9693 - val_loss: 0.0888 - val_accuracy: 0.9747\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1007 - accuracy: 0.9696 - val_loss: 0.0962 - val_accuracy: 0.9742\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1010 - accuracy: 0.9700 - val_loss: 0.0934 - val_accuracy: 0.9739\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0978 - accuracy: 0.9700 - val_loss: 0.0947 - val_accuracy: 0.9736\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0944 - accuracy: 0.9715 - val_loss: 0.0891 - val_accuracy: 0.9752\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0907 - accuracy: 0.9732 - val_loss: 0.0946 - val_accuracy: 0.9730\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0910 - accuracy: 0.9726 - val_loss: 0.0963 - val_accuracy: 0.9745\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0896 - accuracy: 0.9730 - val_loss: 0.0912 - val_accuracy: 0.9755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico para visualizar os erros e accuracy == metrica de avaliacao,\n",
        "historico.history.keys()\n",
        "#evolução do erro, azul\n",
        "plt.plot(historico.history['val_loss'])\n",
        "#performance da rede\n",
        "plt.plot(historico.history['val_accuracy']) #azul é decorrocada do erro ,performance da rede é laranja"
      ],
      "metadata": {
        "id": "kRyyxPR-B0bN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "8cc6dbf7-d2f2-4f0d-9596-87d6d7d66c08"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa8eb1b26a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenção das previsões \n",
        "previsoesimg = modeloimg.predict(X_testeimg)\n",
        "previsoesimg #termos de prob"
      ],
      "metadata": {
        "id": "SU2FGgikB54Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "818025f5-463d-45b0-bc53-d88d9b897c28"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.6644542e-11, 6.4317931e-08, 1.8447750e-05, ..., 9.9995786e-01,\n",
              "        1.1730671e-08, 9.6105086e-06],\n",
              "       [2.1606818e-14, 1.0763186e-08, 9.9999946e-01, ..., 2.3897477e-09,\n",
              "        4.7867874e-09, 7.2115512e-16],\n",
              "       [8.8695338e-13, 9.9995440e-01, 1.2208115e-07, ..., 9.8720886e-07,\n",
              "        4.1922503e-05, 3.4491791e-08],\n",
              "       ...,\n",
              "       [8.4462884e-13, 3.5186210e-09, 4.3216694e-08, ..., 8.1272350e-07,\n",
              "        3.2789604e-08, 8.4902968e-05],\n",
              "       [3.0842762e-10, 3.7276981e-14, 5.1157216e-12, ..., 2.8218822e-10,\n",
              "        4.0832347e-07, 2.7689413e-08],\n",
              "       [6.2012673e-13, 1.6594048e-21, 8.3877258e-16, ..., 1.0075286e-21,\n",
              "        1.7398893e-15, 3.8225067e-18]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# valor máximo (com a probabilidade maior por serem 10 saídas) e geração da matriz de confusão\n",
        "y_teste_matriz = [np.argmax(t) for t in y_testeimg] #poe agr max em y_testeimg\n",
        "y_previsoes_matriz = [np.argmax(t) for t in previsoesimg]\n",
        "confusao = confusion_matrix(y_teste_matriz, y_previsoes_matriz)\n",
        "confusao #diag principal acertou"
      ],
      "metadata": {
        "id": "S_WSusxOB6Xr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8001edf-fa43-43e2-cb48-a3d34d62f797"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 969,    0,    1,    1,    0,    0,    6,    1,    2,    0],\n",
              "       [   0, 1122,    3,    3,    0,    0,    2,    1,    4,    0],\n",
              "       [   0,    0, 1010,    5,    1,    1,    3,    3,    9,    0],\n",
              "       [   1,    0,    2,  994,    0,    2,    0,    5,    3,    3],\n",
              "       [   1,    0,    4,    0,  954,    0,    6,    1,    0,   16],\n",
              "       [   4,    0,    0,   15,    1,  857,    8,    0,    6,    1],\n",
              "       [   4,    3,    0,    1,    2,    3,  941,    0,    3,    1],\n",
              "       [   2,    5,   10,   10,    2,    0,    0,  988,    2,    9],\n",
              "       [   5,    0,    3,    3,    5,    2,    6,    3,  943,    4],\n",
              "       [   3,    4,    0,    7,   10,    1,    0,    5,    2,  977]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsão com um novo registro, convertendo o array para o formato de matriz\n",
        "#número 4 \n",
        "y_treinoimg[20]"
      ],
      "metadata": {
        "id": "_Ff9LwKgCBxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "595421a1-f372-4f1f-e018-15bdcc7e1d30"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#passo a mesma posição para o modelo prever\n",
        "novo = X_treinoimg[20]\n",
        "#de matriz para vetor\n",
        "novo = np.expand_dims(novo, axis = 0)\n",
        "#previsao\n",
        "pred = modeloimg.predict(novo)\n",
        "#maior valor\n",
        "pred = [np.argmax(pred) for t in pred]\n",
        "pred"
      ],
      "metadata": {
        "id": "QOqOnukPB6tR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd47839d-1d74-4392-f116-98512a6ab156"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 41ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#deep learning II"
      ],
      "metadata": {
        "id": "hVczbVRmuVSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import make_column_transformer"
      ],
      "metadata": {
        "id": "AvtrO900uZkP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"Credit2.csv\", sep=\";\")\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "Gm4x2Eepua6K",
        "outputId": "8525b843-a2f2-4eab-e841-307c978194a5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ID checking_status                  credit_history  duration  \\\n",
              "0       1              <0  critical/other existing credit         6   \n",
              "1       2        0<=X<200                   existing paid        48   \n",
              "2       3     no checking  critical/other existing credit        12   \n",
              "3       4              <0                   existing paid        42   \n",
              "4       5              <0              delayed previously        24   \n",
              "..    ...             ...                             ...       ...   \n",
              "995   996     no checking                   existing paid        12   \n",
              "996   997              <0                   existing paid        30   \n",
              "997   998     no checking                   existing paid        12   \n",
              "998   999              <0                   existing paid        45   \n",
              "999  1000        0<=X<200  critical/other existing credit        45   \n",
              "\n",
              "     credit_amount  installment_commitment  residence_since  age  \\\n",
              "0             1169                       4                4   67   \n",
              "1             5951                       2                2   22   \n",
              "2             2096                       2                3   49   \n",
              "3             7882                       2                4   45   \n",
              "4             4870                       3                4   53   \n",
              "..             ...                     ...              ...  ...   \n",
              "995           1736                       3                4   31   \n",
              "996           3857                       4                4   40   \n",
              "997            804                       4                4   38   \n",
              "998           1845                       4                4   23   \n",
              "999           4576                       3                4   27   \n",
              "\n",
              "     existing_credits  num_dependents class  \n",
              "0                   2               1  good  \n",
              "1                   1               1   bad  \n",
              "2                   1               2  good  \n",
              "3                   1               2  good  \n",
              "4                   2               2   bad  \n",
              "..                ...             ...   ...  \n",
              "995                 1               1  good  \n",
              "996                 1               1  good  \n",
              "997                 1               1  good  \n",
              "998                 1               1   bad  \n",
              "999                 1               1  good  \n",
              "\n",
              "[1000 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-167e89a8-ad40-4aa5-ae78-0118cdf9587e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>checking_status</th>\n",
              "      <th>credit_history</th>\n",
              "      <th>duration</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>installment_commitment</th>\n",
              "      <th>residence_since</th>\n",
              "      <th>age</th>\n",
              "      <th>existing_credits</th>\n",
              "      <th>num_dependents</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;0</td>\n",
              "      <td>critical/other existing credit</td>\n",
              "      <td>6</td>\n",
              "      <td>1169</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0&lt;=X&lt;200</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>48</td>\n",
              "      <td>5951</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>no checking</td>\n",
              "      <td>critical/other existing credit</td>\n",
              "      <td>12</td>\n",
              "      <td>2096</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>&lt;0</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>42</td>\n",
              "      <td>7882</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>&lt;0</td>\n",
              "      <td>delayed previously</td>\n",
              "      <td>24</td>\n",
              "      <td>4870</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>996</td>\n",
              "      <td>no checking</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>12</td>\n",
              "      <td>1736</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>997</td>\n",
              "      <td>&lt;0</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>30</td>\n",
              "      <td>3857</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>998</td>\n",
              "      <td>no checking</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>12</td>\n",
              "      <td>804</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>999</td>\n",
              "      <td>&lt;0</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>45</td>\n",
              "      <td>1845</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1000</td>\n",
              "      <td>0&lt;=X&lt;200</td>\n",
              "      <td>critical/other existing credit</td>\n",
              "      <td>45</td>\n",
              "      <td>4576</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-167e89a8-ad40-4aa5-ae78-0118cdf9587e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-167e89a8-ad40-4aa5-ae78-0118cdf9587e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-167e89a8-ad40-4aa5-ae78-0118cdf9587e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#separação dos variáveis, ignoro primeira pois não tem valor semântico\n",
        "Xi = dataset.iloc[:,1:10].values #coluna zero fora de checking stts ate num_dep\n",
        "yd = dataset.iloc[:, 10].values #classe em y\n",
        "#temos um arry e não mais um data frame\n",
        "Xi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6-z3QAqucVD",
        "outputId": "13b740d1-9f61-4bf9-ce5c-32e8a56b9321"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['<0', 'critical/other existing credit', 6, ..., 67, 2, 1],\n",
              "       ['0<=X<200', 'existing paid', 48, ..., 22, 1, 1],\n",
              "       ['no checking', 'critical/other existing credit', 12, ..., 49, 1,\n",
              "        2],\n",
              "       ...,\n",
              "       ['no checking', 'existing paid', 12, ..., 38, 1, 1],\n",
              "       ['<0', 'existing paid', 45, ..., 23, 1, 1],\n",
              "       ['0<=X<200', 'critical/other existing credit', 45, ..., 27, 1, 1]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#label encoder coluna checking_status, substitui colunas por valores\n",
        "#atribui valores de zero a 3\n",
        "labelencoder = LabelEncoder()\n",
        "Xi[:,0] = labelencoder.fit_transform(Xi[:,0]) #checking stts e o 0 pq ignorou o id\n",
        "Xi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py-GiykOulD4",
        "outputId": "ff582d03-ee08-4843-f67f-db42cb00e379"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 'critical/other existing credit', 6, ..., 67, 2, 1],\n",
              "       [0, 'existing paid', 48, ..., 22, 1, 1],\n",
              "       [3, 'critical/other existing credit', 12, ..., 49, 1, 2],\n",
              "       ...,\n",
              "       [3, 'existing paid', 12, ..., 38, 1, 1],\n",
              "       [1, 'existing paid', 45, ..., 23, 1, 1],\n",
              "       [0, 'critical/other existing credit', 45, ..., 27, 1, 1]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoder coluna credit_history, criar uma col pra cada um dos 5 valores possiveis , restante tera zero\n",
        "#deve adicionar 5 colunas\n",
        "onehotencoder = make_column_transformer((OneHotEncoder(categories='auto', sparse=False), [1]), remainder=\"passthrough\")\n",
        "Xi = onehotencoder.fit_transform(Xi)\n",
        "Xi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FSsKzX3uuQW",
        "outputId": "4e9cd2bc-b679-4728-86e2-3aebe1ec2220"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 0.0, ..., 67, 2, 1],\n",
              "       [0.0, 0.0, 0.0, ..., 22, 1, 1],\n",
              "       [0.0, 1.0, 0.0, ..., 49, 1, 2],\n",
              "       ...,\n",
              "       [0.0, 0.0, 0.0, ..., 38, 1, 1],\n",
              "       [0.0, 0.0, 0.0, ..., 23, 1, 1],\n",
              "       [0.0, 1.0, 0.0, ..., 27, 1, 1]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Excluimos a variável para evitar a dummy variable trap\n",
        "Xi = Xi[:,1:]\n",
        "Xi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RKSGgMIuyGt",
        "outputId": "e06b9246-35af-4661-e62e-436522bf7f34"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0, 0.0, 0.0, ..., 67, 2, 1],\n",
              "       [0.0, 0.0, 1.0, ..., 22, 1, 1],\n",
              "       [1.0, 0.0, 0.0, ..., 49, 1, 2],\n",
              "       ...,\n",
              "       [0.0, 0.0, 1.0, ..., 38, 1, 1],\n",
              "       [0.0, 0.0, 1.0, ..., 23, 1, 1],\n",
              "       [1.0, 0.0, 0.0, ..., 27, 1, 1]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Laber encoder com a classe pra transf em valores 0  e 1\n",
        "labelencoder_Y = LabelEncoder()\n",
        "yd = labelencoder_Y.fit_transform(yd)\n",
        "yd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9tgXDOJu2Iu",
        "outputId": "e89f0f9b-1e70-4960-db98-369b4b0745a4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#separação em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xi, yd, test_size = 0.2, random_state = 0)\n",
        "print(len(X_train),len(X_test),len(y_train),len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_9Sbs3ou7Xi",
        "outputId": "edfb0e32-afe7-4358-c5cf-91aa5a546071"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800 200 800 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Scalling, Padronização z-score(processo preferencial em relacao a minimax)\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "X_test #dados em msm escala"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-77yQCTsu8lP",
        "outputId": "b6c00319-a8bc-47b7-ee71-27ee23b92899"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.65270587, -0.30966177,  0.95357636, ..., -0.50870719,\n",
              "        -0.71596668, -0.42214126],\n",
              "       [-0.65270587, -0.30966177,  0.95357636, ..., -0.85315557,\n",
              "        -0.71596668,  2.36887531],\n",
              "       [-0.65270587, -0.30966177,  0.95357636, ...,  0.61075002,\n",
              "        -0.71596668, -0.42214126],\n",
              "       ...,\n",
              "       [ 1.53208366, -0.30966177, -1.04868371, ...,  0.26630165,\n",
              "         1.04100677, -0.42214126],\n",
              "       [-0.65270587,  3.22932987, -1.04868371, ...,  0.52463793,\n",
              "         4.55495365, -0.42214126],\n",
              "       [-0.65270587, -0.30966177,  0.95357636, ...,  0.52463793,\n",
              "        -0.71596668,  2.36887531]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential() #rn do sequencial\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 12))\n",
        "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu')) #segunda camada densa\n",
        "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) #camada de saida com 1 neuronio ,pois e 0 ou 1\n",
        "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100) #atualiza a cada batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiU6VycZvFyh",
        "outputId": "9c9e5697-ae40-4f93-b99e-e2b841d6d9e1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "80/80 [==============================] - 1s 2ms/step - loss: 0.6826 - accuracy: 0.6988\n",
            "Epoch 2/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.6975\n",
            "Epoch 3/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.6975\n",
            "Epoch 4/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.6975\n",
            "Epoch 5/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.6975\n",
            "Epoch 6/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.6975\n",
            "Epoch 7/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.6975\n",
            "Epoch 8/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.6975\n",
            "Epoch 9/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.6975\n",
            "Epoch 10/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.6975\n",
            "Epoch 11/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.6975\n",
            "Epoch 12/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.6975\n",
            "Epoch 13/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7237\n",
            "Epoch 14/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7462\n",
            "Epoch 15/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.7437\n",
            "Epoch 16/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.7538\n",
            "Epoch 17/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7475\n",
            "Epoch 18/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.7613\n",
            "Epoch 19/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.7563\n",
            "Epoch 20/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7563\n",
            "Epoch 21/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.7538\n",
            "Epoch 22/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7563\n",
            "Epoch 23/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7600\n",
            "Epoch 24/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7613\n",
            "Epoch 25/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7638\n",
            "Epoch 26/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.7625\n",
            "Epoch 27/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7625\n",
            "Epoch 28/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7625\n",
            "Epoch 29/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5065 - accuracy: 0.7675\n",
            "Epoch 30/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.7638\n",
            "Epoch 31/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7588\n",
            "Epoch 32/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7613\n",
            "Epoch 33/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.7625\n",
            "Epoch 34/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7650\n",
            "Epoch 35/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7613\n",
            "Epoch 36/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7675\n",
            "Epoch 37/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.7688\n",
            "Epoch 38/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.5003 - accuracy: 0.7638\n",
            "Epoch 39/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4999 - accuracy: 0.7663\n",
            "Epoch 40/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.7638\n",
            "Epoch 41/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7700\n",
            "Epoch 42/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7663\n",
            "Epoch 43/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7638\n",
            "Epoch 44/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7650\n",
            "Epoch 45/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7675\n",
            "Epoch 46/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7688\n",
            "Epoch 47/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7700\n",
            "Epoch 48/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7738\n",
            "Epoch 49/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7700\n",
            "Epoch 50/100\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.4913 - accuracy: 0.7713\n",
            "Epoch 51/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7713\n",
            "Epoch 52/100\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.4896 - accuracy: 0.7738\n",
            "Epoch 53/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7763\n",
            "Epoch 54/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7788\n",
            "Epoch 55/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7750\n",
            "Epoch 56/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7775\n",
            "Epoch 57/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7775\n",
            "Epoch 58/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7800\n",
            "Epoch 59/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7775\n",
            "Epoch 60/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7763\n",
            "Epoch 61/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.7775\n",
            "Epoch 62/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7812\n",
            "Epoch 63/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7800\n",
            "Epoch 64/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7763\n",
            "Epoch 65/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7800\n",
            "Epoch 66/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7763\n",
            "Epoch 67/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7775\n",
            "Epoch 68/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7763\n",
            "Epoch 69/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7788\n",
            "Epoch 70/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7750\n",
            "Epoch 71/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.7775\n",
            "Epoch 72/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.7725\n",
            "Epoch 73/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7775\n",
            "Epoch 74/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7812\n",
            "Epoch 75/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.7775\n",
            "Epoch 76/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7788\n",
            "Epoch 77/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7788\n",
            "Epoch 78/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7763\n",
            "Epoch 79/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7775\n",
            "Epoch 80/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7788\n",
            "Epoch 81/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.7775\n",
            "Epoch 82/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7750\n",
            "Epoch 83/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7800\n",
            "Epoch 84/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.7738\n",
            "Epoch 85/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7788\n",
            "Epoch 86/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7775\n",
            "Epoch 87/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.7750\n",
            "Epoch 88/100\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7763\n",
            "Epoch 89/100\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7750\n",
            "Epoch 90/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7800\n",
            "Epoch 91/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7788\n",
            "Epoch 92/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.7788\n",
            "Epoch 93/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.7750\n",
            "Epoch 94/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7775\n",
            "Epoch 95/100\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7738\n",
            "Epoch 96/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7775\n",
            "Epoch 97/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7775\n",
            "Epoch 98/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7763\n",
            "Epoch 99/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7763\n",
            "Epoch 100/100\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7788\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa8ef70e4c0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test) #previsao em termos de prob\n",
        "y_pred = (y_pred > 0.5) #transf em TorF pra gerar matriz de confusao\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o5fcoM4vLLh",
        "outputId": "c42fd696-e9c6-4e46-d5ae-b39ba1b7b6a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#matriz de confusão\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_YqIRq0vMWT",
        "outputId": "734b0fcd-1abc-48db-a74b-3f8ce85941be"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 22,  36],\n",
              "       [ 20, 122]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRAFOS"
      ],
      "metadata": {
        "id": "ddoyTg7YJgAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libcairo2-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNXNCzUJKacw",
        "outputId": "bf342efc-91ac-49f7-abde-0fd584d4df76"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libcairo-script-interpreter2 libpixman-1-dev libxcb-shm0-dev\n",
            "Suggested packages:\n",
            "  libcairo2-doc\n",
            "The following NEW packages will be installed:\n",
            "  libcairo-script-interpreter2 libcairo2-dev libpixman-1-dev libxcb-shm0-dev\n",
            "0 upgraded, 4 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 930 kB of archives.\n",
            "After this operation, 3,986 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo-script-interpreter2 amd64 1.15.10-2ubuntu0.1 [53.5 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libpixman-1-dev amd64 0.34.0-2ubuntu0.1 [244 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-shm0-dev amd64 1.13-2~ubuntu18.04 [6,684 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcairo2-dev amd64 1.15.10-2ubuntu0.1 [626 kB]\n",
            "Fetched 930 kB in 2s (488 kB/s)\n",
            "Selecting previously unselected package libcairo-script-interpreter2:amd64.\n",
            "(Reading database ... 124016 files and directories currently installed.)\n",
            "Preparing to unpack .../libcairo-script-interpreter2_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libpixman-1-dev:amd64.\n",
            "Preparing to unpack .../libpixman-1-dev_0.34.0-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libpixman-1-dev:amd64 (0.34.0-2ubuntu0.1) ...\n",
            "Selecting previously unselected package libxcb-shm0-dev:amd64.\n",
            "Preparing to unpack .../libxcb-shm0-dev_1.13-2~ubuntu18.04_amd64.deb ...\n",
            "Unpacking libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Selecting previously unselected package libcairo2-dev:amd64.\n",
            "Preparing to unpack .../libcairo2-dev_1.15.10-2ubuntu0.1_amd64.deb ...\n",
            "Unpacking libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up libcairo-script-interpreter2:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Setting up libxcb-shm0-dev:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Setting up libpixman-1-dev:amd64 (0.34.0-2ubuntu0.1) ...\n",
            "Setting up libcairo2-dev:amd64 (1.15.10-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycairo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l1XM8sfRDMe",
        "outputId": "e8b157b9-3925-4d81-efcd-4cd7ca5d389a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycairo\n",
            "  Using cached pycairo-1.23.0.tar.gz (344 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycairo\n",
            "  Building wheel for pycairo (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycairo: filename=pycairo-1.23.0-cp38-cp38-linux_x86_64.whl size=297239 sha256=161ae6e517536d88ddb025ed6e5986b8ceee952b2d3b3265b57adf740f2637c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/25/86/ba7950c33840b1fda7ab932c7c7172d77b994807c5fd35c3ea\n",
            "Successfully built pycairo\n",
            "Installing collected packages: pycairo\n",
            "Successfully installed pycairo-1.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install igraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qShalpxVROwt",
        "outputId": "8de8ac42-c107-40ff-87ba-4e09fc2c3932"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: igraph in /usr/local/lib/python3.8/dist-packages (0.10.3)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from igraph) (1.6.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação das bibliotecas\n",
        "from igraph import Graph\n",
        "from igraph import plot\n"
      ],
      "metadata": {
        "id": "H4KNdnQGJh1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DiN1qiUtS2Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do grafo com as arestas\n",
        "grafo1 = Graph(edges = [(0,1),(1,2),(2,3),(3,0)], directed = True)\n",
        "# Definição do rótulo de cada vértice\n",
        "grafo1.vs['label'] = range(grafo1.vcount()) #contagem é o rotulo dos vertices\n",
        "print(grafo1) #grafico é direcionado, de 4 vert e 4 arestas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC83Iy0hJ22U",
        "outputId": "3b7b74b6-6675-4253-c98a-e5faa197d542"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IGRAPH D--- 4 4 --\n",
            "+ attr: label (v)\n",
            "+ edges:\n",
            "0->1 1->2 2->3 3->0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gráfico\n",
        "#gráfico\n",
        "#plot(grafo1, bbox = (0,0,300,300) \n",
        "plot(grafo1, target=plt.axes())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "TT7AB39_J9R8",
        "outputId": "f48bb0f7-f0d1-48fc-85c3-e6b2530720b4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa8e6f27a90>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAY70lEQVR4nO3deXhU5b3A8e9kkiEziYDsi8hiBUERSYJUChqSqIUry8WKokCkqPQWl6og4PW22KIJobYaoeDGEsDK1iqiIjIhcWFNIhJAi5Wl+rCjsmWyzZz7RwgGmH3OmTln5vd5njyPmXnnnTfA17PMmYlJURSEEPoTF+kFCCHckziF0CmJUwidkjiF0CmJUwidivdxv5zKFUJ7Jnc3ypZTCJ2SOIXQKYlTCJ2SOIXQKYlTCJ2SOIXQKYlTCJ2SOIXQKV8XIQgDqK2tZc+ePRw7dgyTyUTbtm256qqriIuT//camcRpUJWVlaxYsYL5L77Itp07aWux0NZsRgH+U1vLSaeTX/Tpw4NPPMEdd9xBfLz8VRuNycebreXyPR1auXIljzzwAL2cTn5z5gwDgSYXjTkOrAX+dtllHE1O5vU33yQ9PT3saxV+cXv5nsRpIFVVVYwfNYqSDz9kQUUFN/n5uDXAb6xWRo0fz8yXXpLdXf2ROI2surqaYVlZJJeUUOBwYA3w8d8Dw202uo0YwasFBZhMbv89iMiQC9+NbPIjj2ApKeHvQYQJ0Ax4v6KCL/7xD1584QW1lyc0IFtOAyguLubeQYModzhoFuJc/wZ+brWycft2unbtqsbyROhkt9ao+vbowaQvv+QulebLi4ujdNAglq1Zo9KMIkSyW2tEJSUlHDlwgBFexswG0oBGwP1+zDnB5WLd+vUcPnxYjSUKjUicOrdsyRLur6zE7GVMO+AZ4Nd+ztkEGBYXx6pVq0Jen9COxKlz24qL6edyeR0zAhgONA9g3pscDkqKi0NZmtCYxKlz5Xv20EuDeW8AdpSVaTCzUIvEqXOnq6ouufpHDU2AMxUVGsws1CJx6pzFbKZKg3mrgQS53lbXJE6d+1n79vxLg3m/Aq6++moNZhZqkTh1LrVvX0p8jKkFKgHnua/Kc7d5UxIfT+ott6iwQqEViVPnfjliBMuTk72OmQFYgVxgybn/nuFlvBNYYbFw+6BBai1TaECuENK56upqOrZqxUcnT3KdSnOuAZ7t1o1tX32l0owiRHKFkBFZLBae+t//5eGkJLy/2ukfB/CkzcbTOTkqzCa0JFtOA3A6nQxISeHO8nKeDPE3kT9qsXD09tt5a/VqlVYnVCBbTqMym808PGUKfzSbWRjkHAowIz6eda1aMWfBAhVXJ7QiW04DKCoqIicnh9OnT/NNeTmjqqt5vroam5+PPwE8arWyo00bMoYMITExkaysLPr374/VGsy7Q4XKZMtpRPVhulwuHnroIXbt28exwYO5PimJV4AzXh57AvhzXBw9rVZaZmezZedOhgwZQllZGXl5eYwcOZLnn3+eLVu24HQ6w/QTCX/JllPHGoY5evRoxo4de/7jRQoLC5mdm8uGjz8mtVEjUisqaFtbW/fpewkJlNps7KiqYtgdd/Do1KmkpqYC4HA4GDlyJJWVlRc8V9OmTUlPTycrK4tu3bqF+0eNdfJmayPxFmZDx44dY9u2bZSVlHD80CFMcXG06dCB1LQ00tLSaNq06SWPyc3NxW63e3zuDh06kJGRwYgRI7DZ/N15FiFwG6dcXKlD/oYJ0LJlSwYPHszgwYP9nj8zM9NrnN9++y0//PCDhBlhcsypM4GEGayUlBSaNfP8aURDhw7lkUceUfU5ReAkTh0JR5hQ99KMpw+Yvv322yVMnZA4dSJcYdbLzMy85LaePXvy8ccfs3PnTs2eV/hP4tSBDRs2hDVMgK5du3LllVee/37o0KG0bt0ah8PBtGnTJFAdkDgjbMOGDeTm5oY1zHoZGRnAT8eYkyZNIjMzk8rKSglUB+SllAiKZJgAhw8fZtWqVUycOPH8bU6nk1mzZmG320lMTCQnJ4frrlPr/TDCA3mdU08iHaY3EmjYSZx60TDMMWPGMHbs2Egv6RISaFjJtbV6YIQwoe7llsmTJ8sxaARJnGFklDDrSaCRJXGGidHCrCeBRo7EGQZGDbPexYE+/fTTEmgYSJwaKywsNHSY9RoG6nA4JNAwkDg1VFhYyMyZMw0fZj0JNLwkTo1EW5j16gPNyMiQQDUmcWogWsOsZzabeeqppyRQjUmcKov2MOtJoNqTOFUUK2HWk0C1JXGqJNbCrCeBakfiVEGshllPAtWGxBmiWA+zngSqPokzBBLmhSRQdUmcQZIw3ZNA1SNxBkHC9E4CVYfEGSAJ0z8SaOgkzgBImIGRQEMjcfpJwgyOBBo8idMPEmZoJNDgSJw+NAxz7NixEmaQJNDASZxeXBzmmDFjIr0kQ3MX6K5duyK9LN2SOD2w2+0SpgYuDnTatGkSqAcSpxt2u528vDwJUyMSqH8kzotImOEhgfomcTYgYYZXfaADBw6UQN2QOM+RMCPDbDYzZcoUCdQNiRMJM9IkUPdiPk4JUx8k0EvFdJwSpr5IoBeK2TglTH26ONBYvlAhJuNcv369hKljDQOtqKiI2UBjLs7169cza9YsCVPnJNAYi1PCNJZYDzRm4pQwjSmWA42JOCVMY4vVQKM+TgkzOtQHmp6eHjOBRnWcEmZ0MZvNTJ06NWYCjdo4Jczo5C7Q3bt3R3pZmojKOCXM6HZxoNOmTYvKQKMuzoZhZmdnS5hRKhYCjao4G175k52dzejRoyO9JKGhaA80auKsD1NRFAkzhkRzoFERp4QZ26I1UMPHKWEKiM5ADR2nhCkairZAdR/n2bNn3d4uYQp3oilQ3ceZn5/P22+/fcFtEqbwJloC1XWcDoeDjRs3MmfOnPOBSpjCH9EQqElRFG/3e71Ta+vWrWPWrFnnv//Vr37FqlWrJEzhN6fTSW5uLkVFRdhsNnJycujRo0ekl3Uxk9sb9RznlClTKCsru+C2nj17kpKSImEKvxkgULdx6na39sSJE2zfvv2S28vLy0lOTo7AioRRGXUXV7dxFhYW4nK53N7X8BhUCH8YMVDdxmm3273eP2fOHFavXh2m1YhoYLRANT/m3LNnD6vfeYeSoiK+3L0bR2Ul1sREuvfoQeottzBs+HC6du16wWP279/Pgw8+6HHO7t27k5mZSXp6Ok2aNAl1iSLG+HsMunPnTtZ+8AGlxcX8e88eqmtquCw5mZ5pafQZMIBhw4bRvHlzNZYU3hNCGzdu5A9PPMGOHTu4y+mkb3U11wJJwFlgF7DFYmF5XBy9evXi2b/8hX79+gHw+uuvs2zZsgvma9euHVlZWWRkZNC+fftglyUE4D3QtWvX8tzUqez7+mtG1NaSVl1NN6ARcBLYDmxMSmKd08mwIUOYnpdHp06dQlmO2zhRFMXbV8AcDofyxMSJSlurVVkISiUoipevSlAWgNLGalWemDhRqaioUEaNGqVkZWUpd955p5Kfn6/s2rUrmKUI4VVtba0yY8YMJSsrSxk6dKiyefNmJXvkSKWzzaasAKXax7/dY6A8azYrzW02Ze6cOYrL5Qp2KW77U3XLWVFRwdDMTJK/+ILXHQ5aBPDY48ADVivHunYla9gwBg0aRJ8+fTCbzYEsQYiAOJ1OcnJy+Oijj/iypIQhNTW8VFNDIK8H7AbutdkYcN995L/yCiaT+w2hF9ru1iqKwtDMTC7ftIkFlZUEk5QTGJeYyA833cRquz2YH1KIgJ05c4ZrO3Xi7u+/Z6aieNjH9O4kcJvNxm0TJ/KnvLxAH67t65yvzJ3L0a1bmR9kmABmYH5lJUe2buXVefPUWpoQXj379NPcWFERdJgATYA1FRW8MXs2n332mSrrUmXLefToUXp07szHFRWocd3FbuBmm43d+/bRqlUrFWYUwr3t27fzy379KHc4aKnCfP8Anr7iCnbt3x/IIZl2W843Xn2V4S6X1zCrgPFAR+Ay4AbgAw9jewDDFIX5r72mxvKE8Cg/N5fHq6q8hvk98N/UvdLQEXjTy9gRQOOTJ1m7dm3oi/N0pkjx82yty+VSOrdqpZT4OLN1BpQ/gLIPFCco74KSfO57d+O3gdK5VatQzoAJ4dXJkyeVJomJylEf/3bvAWUkKKdB+QSUxqDs9DJ+AShDBg4MZClu+wt5y3nw4EFOnzpFio9xScB0oBN1m+s7gM5AqYfxqcDpU6c4ePBgqEsUwq1t27bRs1Ejr1vNs8Aq4E9AMtAfGAos9vKYQcAnmzejeD9k9CnkOMvKyki1WAI+kD4C7AGu9XC/CUi1WCgt9ZSvEKEpLSkh1eHwOmYPEA80vIatF3UX0XjSGkgymdi7d29I61Nly3llTU1Aj6kB7gOygWu8jLuytpbDhw+HsDohPDu4fz8dq6u9jjkDNL7otibAaR9zd0pICHmvL+Q4lQBPP7uAMYAFmO1jrOnc/EJowZ9/u8nAqYtuO0XdSU1vTODxXVX+CjnOli1bcighwa+xCnVnbI9Qtx/v61GH4uNp0SKQ64yE8F/zNm044uPljq5ALfB1g9u+wPPhWL0jTmfIF8WHHGdKSgpltbV+jf0f4EvgXcDqx/jS2lpSUnydahIiOL1TUylLSvI6Jom6l0d+T93Joc+Ad6jb+/PkFHCwupprrvF20OZbyHF26tQJZ0IC//Ix7gDwCnVX9LehbnchGVjqYfxXgDM+PtSr/YXw6MYbb2RrVRUVPsb9DXAArYBRwFy8bzmLgdQePYiPjw9pfSHHaTKZGPfgg8yzWLyO60jdbm0ldQfZ9V/3eRg/z2Jh/IQJcn2t0Ezr1q3pf9NNvOVjXDPgbeq2nP8B7vUxfl5yMuMeeyzk9aly+d6BAwdI7d6d7Q4HV4S8JPgW6G21Uvrll3Ts2FGFGYVwb926dTw6YgTbz54lUYX5SoD/atyY/YcPY7X6c/AGaHn5XseOHXls0iQetNlC/ugEBXjIZuN3kydLmEJzt956K9fdfDPTfez5+aMKuD8piRfnzg0kTI9Ue8tYTU0N/Xv3JnPPHp6rqQnq6n4FeMpk4oOOHfl8zx4S/DwLLEQojh49Su9rruEvP/zA3UHO4QSyExOpyshg+Zo1gR6OafuWsYSEBN4rKmJNhw48arFQGeDjK4GH4+NZmJhIi44dKS4uVmtpQnj1448/Mu63v+Wxxo2ZazIFvPd3ChiVmMihXr0oWLlStfMkqn76XosWLSjato2DGRmkJiVRhO9NrwIUASk2G4ezspjx17+SkJBAXl4e69evV3N5Qpx35MgRli5dyvjx45k4cSInT56keOtWXu/alUE22wWva3riou5lwZ42G03vuov3iopU2Z2tF9q5XjeaNWvGyvffZ/myZUx48kkST51izJkz9AGu46cP+NoJbAUWJydT1bgxf3zhBUbefTcmk4mkpCQWLVp0/lcxZGVlqb1MEYNOnz5NcXExdrudXbt2XXD1WWZmJt26dWNzeTmznn+efn/+M6nA3WfOkEbdZabx1F22tx3YZDIx32ajUatWvDZvHrfddpvq69X0ozEVRcFut/P2W29RunEju/fto7KmhsSEBHp07kxqv34Mv+ceMjMzL9kVWLJkCYsWLSIuLo7JkydLoCIoNTU1bN68GbvdztatW6lxcx242Wxm2bJlF3zMqsPhYMWKFXy4ahWlJSV8fegQLkXBmpDA9VddRdovfsGocePo16+fGruxxvtdKRKoCFVOTg6FhYVex/Tt25cZM2Z4HXP+PZZxmnwOu7F+VwrA6NGjyc7OxuVyMWvWLDkGFQF78skn6dOnj9cxmZmZPucxmUxahemRruMECVSExmKxMH36dI+B2my28x9mrje6jxMkUBEai8VC9+7dufrqqy+5r3///jRq1CgCq/LNEHGCBCqCt3jxYgoKCjhw4AA33HDDBff5s0sbKYaJEyRQEbj6MOPi4nj88cd57rnnzu/itmjR4pJY9cQ8ffp0b/d7vTMSrr/+euLi4ti+fTubNm2ibdu2dOnSJdLLEjrUMMz6s/1ms5kBAwbw9ddf07t3b9LS0iK9TIBn3d2o65dSvGn4B//UU0/pevdEhJ+7MBuqrq7m1KlTevmkDeO9zumLBCrc8RWmDrmNU/XL98JpzJi6D4soKCgg79wvj5FAY5sBw/TI0HGCBCp+Ek1hQhTECRKoiL4wIUriBAk0lkVjmBBFcYIEGoui+aRgVMUJEmgsieYwIQrjBAk0FkR7mBClcYIEGs1iIUyI4jhBAo1GsRImRHmccGmgJpOJjIyMCK9KBCOWwoQYiBMuDHTmzJkAEqjBxFqYECNxggRqZLEYJsRQnCCBGlGshgkxFidIoEbSMMwpU6bE3N9TzMUJEqgRFBQUsHjx4pgNE2I0TpBA9UzCrBOzcUJdoIqisHjxYglUJyTMn8R0nABjx44FkEB1QMK8UMzHCRKoHkiYl5I4z5FAI0fCdE/ibEACDT8J0zOJ8yISaPhImN5JnG5IoNqTMH2TOD2QQLUjYfpH4vRCAlWfhOk/idMHCVQ9EmZgJE4/SKChkzADJ3H6SQINnoQZHIkzABJo4CTM4EmcAZJA/SdhhkbiDMLFgZpMJgYOHBjhVemLhBk6iTNIDQPNzc0FkEDPkTDVIXGGQAK9VMMwp06dGvN/HqGQOEM0duxYFEVhyZIlMR+ohKkuiVMF9VvQWA5UwlSfxKkCk8kUs4EqikJBQQFLliyRMFUmcaokFgOVMLUlcaoolgKVMLUncaosFgKVMMND4tRANAcqYYaPxKkRd4GaTCbS09Mju7AQSJjhJXFq6OJAc3JyAAwZ6MVhTps2zZA/h5FInBqrD1RRFJYuXWrIQCXMyJA4w8BkMpGdnQ1guEAlzMiROMPEiIFKmJElcYaRkQJVFIVFixaxdOlSCTNCJM4wM0KgEqY+xEV6AbGoPtD77rsPl8tFTk4ORUVFl4xbunQpLpcrrGuTMPVD4owQX4Hm5+ezcOFCvvjii7CtScLUF9mtjSBPu7g7duzg3XffBcBut9O7d2/N1yJh6o9JURRv93u9U6ijYRg9e/akvLz8/H02m43ly5fTqFGjsDy/hBkRJnc3ym6tDtRvQfv3739BmAAVFRVs2rRJs+eWMPVL4tSJl19+mU8//dTtfXa7XZPnlDD1TeLUgfz8/PPHmO6UlJRw8uRJVZ9TwtQ/OSEUYYcOHeLo0aOYzWacTqfbMbW1tRQVFTFs2LBL7lMUhW+++YbPP/+cEydOYDKZaNeuHampqbRr187tfBKmMcgJIZ348ccfKSoqwm6389VXX11yf/fu3cnPzz///d69e5mXn8/C+fNJdLlIMZtpXVODAhxISKC0upqmTZsy4Xe/49cPPEDz5s0BCVOn3J4Qkjh16LvvvsNut1NYWMjBgwfP375o0SKaN2/OjN//nnkvv8z9tbVMqKnhZ27mUICtwFyrlffNZma++CLZ48ZRUFAgYeqPxGlEu3fvZv369RQXF5Oens6C2bPp8N13zKuooK2fc+wA7k9KwtKlC7YWLUhISJAw9UXiNLKDBw9yc2oq2ceP80xtrfu/TS+qgbvi4iht0oSFy5eTlZWlxTJFcOR1TqNSFIXx99zDnSdO8H9BhAlgAVa6XPSoqKBo3Tq1lyg0IHEawML58zlSVsaMmpqQ5kkAFlVV8drs2ZSWlqqzOKEZ2a3VOafTSefWrVl54gQ3qjTnXGBtRgbvaHRxgwiY7NYa0XvvvUe76mqfYY4G2gKNga7A617GjgU+3biRAwcOqLRKoQWJU+fefvNNxpw+7XPcNGA/cApYDTwDeNpxTQKGmUysWbNGpVUKLUicOle6ZQt9/Rh3LVD/vhXTua9vvIzv63BQ+sknoS5PaEji1Lkvv/2Wa/0c+1vABlxD3S7uYC9jrwN2h/GN3CJwEqeOOZ1Oap1OrH6O/xtwGvgEGMFPW1J3bEBlZWWIKxRakjh1zGw2E2824wjkMUB/4Dvqzsp6UgEkJiaGsjyhMYlT57p36MCuIB5Xi/djzp1Aj169gluUCAuJU+fSfv5ztvgYcxR4CzgDOIEPgb8DmV4es8VqJXXAAHUWKTQhcerc8HvvZfFll3kdY6JuF/YK4HJgEvAiMNTD+LPAO4rCkCFDVFypUJtcIaRzTqeTLm3asPz4cb9eUvHHXODDzEzeXr9epRlFiOQKISMym808O3Mmv0lKIrQra+scAv5gtfL7vDwVZhNakjgNIHvcONqlpfFMQkJI89QA42w2JjzyCCkpKeosTmhGdmsN4tixY9ycmsq9hw4F/X7O0VYrZ/v25Z8ffojFYtFimSI4sltrZC1btmTD1q38s0sXhttsHArgsV8AfZOScKWns+qDDyRMg5A4DaRNmzZsLi/n+ocf5nqrlUkWC197GKsAW4Bsq5Vbk5N59KWXWPHee3LhgYHIbq1B7d27l1defpkFb7xBI6eTlPj4uk/fM5nYHx9PWVUVzS6/nAmPP8648ePPf/qe0CX5DKFopCgK+/bto6ysjOPHjxMXF0f79u1JTU2lTZs2kV6e8I/EKYROyQkhIYxE4hRCpyROIXRK4hRCpyROIXRK4hRCpyROIXRK4hRCp3z9ZutgfmeOEEIFsuUUQqckTiF0SuIUQqckTiF0SuIUQqckTiF06v8BqIiSCigHePgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação do segundo grafo\n",
        "grafo2 = Graph(edges = [(0,1),(1,2),(2,3),(3,0),(0,3),(3,2),(2,1),(1,0)], directed = True) #direcionado \n",
        "grafo2.vs['label'] = range(grafo2.vcount())\n",
        "plot(grafo2, # Grafo com Laço\n",
        "grafo3 = Graph(edges = [(0,1),(1,2),(2,3),(3,0),(1,1)], directed = True)\n",
        "grafo3.vs['label'] = range(grafo3.vcount())\n",
        "plot(grafo3, target=plt.axes()) #devido erro do igraph na lib só roda com o target=plt.axes()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ZxaWCuA2TJre",
        "outputId": "6726be77-b4c4-434d-df9b-0ca67e0fc1f9"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa8e73655e0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deVhUZf+H7xn2zR1EBBVFERQXcEOTEsTcsnJfMvfUMs3lLZfMV60kFZdMU980K5fUsjJDTXBNQUVUXEBFBEVQQFRkHZiZ3x8083MBZJs5Z+Dc18V11cxZPsJ85nnO83wXmVqtRkJCQnzIhRYgISFROJI5JSREimROCQmRIplTQkKkSOaUkBApxi95X1rKlZDQPbLCXpRGTgkJkSKZU0JCpEjmlJAQKZI5JSREimROCQmRIplTQkKkSOaUkBApkjklJETKy4IQJAyA/Px8rl+/TkpKCjKZjHr16tGkSRPkcum715CRzGmg5OTksHv3bjavWsXZy5epZ2pKPSMj1MDt/HweK5V0ad+eCTNm0LdvX4yNpT+1oSF7SbK1FL4nQn755Rc+HD+e1kolkzIy6AZUf+6YVOAAsM7GhmRra77bvp3XXntN71olSkSh4XuSOQ2I3Nxcxg0bRvjBg3yflYV3Cc/bB0yysGDYuHF8tXq1NN0VH5I5DRmFQsGb3btjHR7Oj9nZWJTy/DTgLUtLXPv3Z+OPPyKTFfp5kBAGKfDdkPnPhx9iGh7OjjIYE6AWEJSVxcU9e1gVGFjR8iR0gDRyGgDHjh1jeK9eXMrOplY5rxUDdLKw4NSFCzRr1qwi5EmUH2laa6h0dHdnVlQUgyroekvlcs716sXOffsq6IoS5USa1hoi4eHh3I+Pp38xx3wDtAPMgNEluOZElYq/g4O5d+9eRUiU0BGSOUXOzq1bGZ2Tg1ExxzgAnwJjS3jN6sCbcjm//vprufVJ6A7JnCLn7LFjdFapij2mP/AWULsU1/XOzib82LHySJPQMZI5BeDKlSukpaWV6NhL16/TWgca2gCRERE6uLJERSHFdAlAcHAw+/bto1GjRnh6euLp6UmrVq2wsHhxk+RJbu4L0T8VQXXgfkoK27Ztw9HREUdHRxwcHArVICEMkjkFoHHjxgDExcURFxfHnj17MDY2xs3NTWtWV1dXjIyMMDUyIlepxLyCNSgARW4uW7ZseeZ1W1tb6tevj5OTE46OjjRp0oRmzZpJphUAyZwCoDHn0+Tn53Pp0iUuXbrEDz/8gJWVFa1bt8apdm2uJSXRoYI1RAPNmjVj8ODB3Llzh4SEBJKSkkhJSSElJYULFy5oj5XL5TRp0oTmzZvj7u6Ou7s79erVk6KMdIxkTj2iVqt58OABqampyGQyittjzszMpFq1anTo0oXwX34p1pz5//4o//3JoeAPW9wfN9zYmJ4DBzJhwgTta0qlkvv375OQkEBCQgK3b9/m2rVrxMbGcuPGDW7cuMGff/4JQI0aNfDw8KBTp0506NCBGjVqlPj3IFEypCAEHZKfn090dDTnz58nKiqKGzdu8OjRI6Bg+piSklLoeTY2NkyfPp2uXbuye/du1o4dy9GMjCLv819g4XOvLfj39cJQAi6Wluw6epT27du/9N+RnZ3N9evXuXr1KlevXiUqKorHjx9r35fL5bi5ueHt7U2nTp1o0KCBNKqWDilCSNeo1Wri4uI4f/48ERERREZGkp2d/cwx1tbWuLi4oFaruXjx4gvXaNu2LR9//DF16tQBCgLeG9rZcejxY1pWkM59wEJXV85GR5fpfLVaTWJiIuHh4YSGhnLx4kXy8/O17zs4ONC1a1d69uyJo6NjBamu1Ejm1AUKhYIzZ85w4sQJzp8/z8OHD59538nJSbsa27RpU+zt7ZHJZPzwww9s3bpVe5yJiQljxoxh4MCBL4w6K5ct44+FCzmcmVnuva9soI2lJQFbt/L222+X82oFZGZmcu7cOcLCwjh9+jTp6ena91q1akXv3r3p2rUrpqamFXK/SohkzopCpVJx+fJlDh8+zLFjx8h4aspZq1Yt7Ypr27ZttSPg85w4cYJFixYBBQaeO3cuLi4uhR6rVCrp6unJwMuXmfGSgISXMdXUlOTXX+fnvXvLdZ2iUCqVXLlyhUOHDnH06FFycnKAgqm6n58fvXv3xtnZWSf3NmAkc5aX+Ph4goODOXz4MMnJydrXGzdujK+vb6metxISEhgzZgx9+/Zl0qRJmJmZFXt8bGwsXdu1Y8mjR7xb/N+sUNTAF8bGbHdw4EREBLVrlyaeqGxkZmZy5MgRgoKCuHHjhvZ1T09PRo4cScuWFTVRN3gkc5YFtVrNmTNn2LVrF5GRkdrXbW1t8fPzw9fXt0wjgUql4uzZs3Ts2LHE50RFRdHTx4f+6el8oVBgWcLzHgBTLSyItLfn75MnqVevXqn1lpeYmBiCgoIIDg7WPodLJtUimbM05Ofnc+TIEXbt2kVcXBwAlpaWvPbaa/j5+dGyZUtByn08ePCAqePHc/rQIf6TmckIwLqoY4Hv5XJWmJkxeNQovgwMxNKypJbWDenp6ezZs4fffvuNrKwsANq0acPIkSNp1aqVoNoERDJnScjOzmb//v38+uuv2qlr7dq1GTBgAL1798bKykpghQUcPnyYbwICOHL8OF5mZrR58gRHtRo1EG9iQoSlJZG5ubzZty9TZ8/Gy8tLaMnP8OTJE/bs2cOePXu0Jm3fvj1TpkzBwcFBYHV6RzJncSiVSoKCgvjhhx+0e3hOTk4MHjwYX19f0a40pqSkcPbsWT6dO5fHqal069YN61q1sLaxYdasWaIPDnjy5Am//fYbv/76K1lZWZiamjJ8+HAGDRok2t+5DpDMWRSXLl1i7dq13Lx5EwA3NzeGDh1Kp06dDKJSnVKppG/fvuTn57N371527NjB7t27Wb16tcGUInn48CEbN24kODgYKPhinDZtGq1b6yInR3RI5nye5ORk/ve//3H06FEA7OzsmDhxIl27djWoCJekpCTeffddbG1t2b59Ox9++CHR0dE4OTmxbt06zM0rOmxed5w/f541a9Zw584dALp3786kSZOoXl0XuTmiQSpToiE/P59t27Yxbtw4jh49iqmpKe+++y6bNm3Cx8fHoIwJaD/I9evXJyMjg+vXr2tfX79+vZDSSk3btm1Zv349o0ePxsTEhODgYCZNmsTly5eFlqZ3qpw5ExMT+eijj9iyZQs5OTn4+PiwefNmRo4caVAjzNMkJCQABVPB8+fPo3oqUOGvv/7i1KlTQkkrE6ampowYMYLvvvsOd3d3UlNTmTlzJrt37y42WaCyUaXMGRwczOTJk7l27Rp2dnYsXbqU+fPnU7duXaGllQuNOR0dHYkopLrBihUrePDggb5llRsHBwcCAwMZPHgwKpWKjRs38tlnnz0THliZqRLmzMzMJCAggK+++oqsrCx8fHxYv349bdu2FVpahaAxZ/369Qs15+PHj1m2bJlBjjrGxsZMmDCBRYsWYWNjQ1hYGO+//z7RZQzaNyQqvTmvXbvG+++/T0hICObm5syYMYNPP/0UGxsboaVVGBpzmpubk5iYWOgx586dY8+ePfqUVaF4e3uzbt06XF1duX//PjNnziQ0NFRoWTqlUpvz1KlTzJgxg8TERJo0acLatWvp1auXwS34FEdmZiYpKSmYmJhoF4aKYtOmTcTGxupJWcVjb2/PypUr6dWrFwqFgv/+978cOnRIaFk6o9Ka888//2ThwoUoFAp69uzJ119/TYMGDYSWVeFERUUB4OLiUmh+qAZzc3MaN27MuXPn9CVNJ5iYmDB9+nSGDRuGSqVi6dKlBj0jKI5KV6ZErVazefNmfv75ZwDeffdd3nnnnUo1Wj6NxpzNmzfn8OHDyGQy6tatS8OGDcnJyUGtVjN9+nQcHBwMIqCiJMhkMsaOHUu1atXYsGED3377Lenp6YwaNapS/Z0rlTnz8vJYsWIFwcHByOVypk+fTs+ePYWWpVOuXr0KgKurKz4+Pjg7O2NlZYVKpeLtt98mKysLCwuLSmPMpxk4cCDVqlUjMDCQbdu2kZGRwQcffFBpDFpp/mIKhYIFCxYQHByMubk5ixcvrvTGVKlU2pHTw8ODli1bagPz5XK5Nnk7JiZGMI26pkePHixYsAATExP++OMPtm3bJrSkCqNSmFOpVPLVV19x9uxZatSowfLly+nQoaKLSYqPO3fukJmZSZ06dbCzs3vh/aZNmwKV25wAnTt3Zt68ecjlcn744QcOHDggtKQKweDNqVarWbNmDcePH8fS0pIlS5bg6uoqtCy9oBk13dzcCn1fM3JWhT3BLl268MEHHwCwcuVKzp49K7Ci8mPw5vz+++/566+/MDU1ZfHixUXW4amMaOJNizKnJnk5MjISpVKpN11C0a9fP4YOHYpKpWLRokXaGGNDxaDN+csvv7Bjxw7kcjmffvpplcqkV6lUnDlzBqDISCc7OzscHR3Jysri2rVr+pQnGGPHjqV79+7k5OQwb948g+5BarDmPHr0KBs2bABg1qxZeHt7C6xIv1y/fp2HDx9ia2tLkyZNijxOY9zCwvoqIzKZjBkzZuDp6cmjR4/48ssvn6mpa0gYpDlv375NYGAgABMnTsTf319gRfpHE7rm7e1d7NaBp6cnUHXMCQWBCvPmzcPW1paoqCh++uknoSWVCYMzZ05ODosXLyYnJ4du3boxYMAAoSUJQlhYGACdOnUq9rjWrVsjl8uJiop6ofp8ZaZatWrMnj0buVzOjh07io2eEisGZ85vvvmGuLg4nJyc+OijjyrNhnNpuH//PrGxsVhYWLy0jIeNjQ1NmzYlPz+/yiUst2rVimHDhqFWqwkICDC4VDODMufBgwc5ePAgZmZmzJ8/X/Ayj0KhmdK2a9euREWwNM+dhh5XWxZGjhypTdgODAw0qLQ5gzFnXFwca9asAWDKlClVuqT/yZMnAUq8CNauXTvteapytnMwNIyMjJgzZw5WVlacOnWKgwcPCi2pxBiEOZVKJcuXLyc3Nxd/f/9KH5ZXHImJiVy4cAEzM7MSm9PDwwNbW1vu3bunjcWtStjb2zNlyhSgIG0uo5h2imLCIMwZFBTEtWvXqFOnjvaXXFXZv38/AD4+PlhbF1Xr/VnkcjndunUD0JaerGr4+fnh4eHBo0ePnunuJmZEb860tDQ2bdoEwPvvv19lnzOhoGrg33//DUDv3r1LdW737t0BOH78OHl5eRWuTezIZDLef/995HI5v//+O/Hx8UJLeimiN+eGDRvIzMykQ4cOvPLKK0LLEZTTp0+TlpaGk5MTLVq0KNW5zs7OODs78+TJk0oRd1oWXFxc6NWrF0qlkm+//Vb0i0OiNmdERASHDx/G1NSUKVOmVMltk6cJCgoCKHOpFT8/PwBCQkIqVJchMWbMGKytrTl37pzoaxCJ1px5eXna1dl33nlHkLZ1YiI5OZnw8HCMjY3LHBHVrVs3ZDIZoaGhBrMoUtFUr16dUaNGAbB+/XpRh/aJ1pwHDx4kISEBJycnBg4cKLQcwdmzZw8qlYouXbqUuTmRnZ0dbdq0IS8vT7uwVBV54403cHJyIikpiWPHjgktp0hEac68vDx27NgBwKhRozAxMRFYkbA8fPiQffv2ATB06NByXUsT7vjrr7+iUCjKrc0QMTIyYtCgQQDs2rVLtM+eojTnoUOHSE5OpmHDhnTt2lVoOYKza9cucnNz8fb2Lne+aocOHWjUqBEPHjzg8OHDFaTQ8PDz86NWrVrExsYSHh4utJxCEZ058/Ly2L59OwAjRoyolIWpSsPDhw/5888/gYJQtPIik8kYPHgwUGD6qhYxpMHU1JT+/fsDsHPnToHVFI7oPvmHDh3i/v37ODk54ePjI7Qcwdm9eze5ubl06tRJWxOovHTr1g07Ozvu3LmjzW6pivTt2xdLS0suXrwoylIuojJnfn6+9lnznXfewcjISGBFwlLRo6YGY2Nj7bPnzp07RfvMpWusrKx44403gIJZhNgQlTlPnjzJvXv3cHJy4tVXXxVajuD8+OOP5OTk0LFjxwrvUN2rVy9sbGy4evUq58+fr9BrGxJvv/02JiYm/PPPPyQnJwst5xlEZU7NJnu/fv2q/Kh59epV/vrrL4yMjBg/fnyFX9/CwkK7Yvntt99WiQJghVG7dm28vb1Rq9UcOXJEaDnPIBpzJiUlERERgampqTaSpaqiVCpZvXo1arWaQYMG0ahRI53cZ8CAAdSrV4+4uDjt9LkqItbIKdGYU1MIuGvXrpWqPV9Z+P3334mNjcXe3p4RI0bo7D6mpqZMnDgRgB9++IHHjx/r7F5ipn379tjY2HDr1i1RdWEThTmVSqU2Cba02RaVjeTkZLZs2QIUJJWbm5vr9H6dO3fG09OTjIwMvv/+e53eS6yYmJho1zjENHqKwpynT5/mwYMHODk54eHhIbQcwVCr1axbt46cnBy6du1Kx44ddX7Pp1OpgoKCKn3rhqLQTG0PHz4smr1fUZhTM6WtbI1tS0tQUBAnT57EwsKCyZMn6+2+DRs25K233kKtVrN69eoquTjUokUL7O3tSU1NJTIyUmg5gAjMmZ2dTXh4ODKZTJsQXBWJiYlh7dq1AEybNg1bW1u93n/kyJHUqVOH6Ohog63zWh5kMhm+vr5AQcFyMSC4OcPDw8nLy8PNzY2aNWsKLUcQMjMzWbx4MXl5efTp00eQ1Wpra2s++eQTZDIZ27dvN8g6r+Wlc+fOgHgKcAtuTk34WFVrp6BBrVYTGBhIYmIijRs31ut09nnatGmjrfP61VdfGVyd1/Li4uKCtbU1SUlJJCUlCS1HWHMqlUpOnz4NvLxyeWXljz/+4MSJE1haWjJ//nzMzMwE1TNy5Ejc3NxISUlhxYoVVSq0z8jISFukWwxRU4KaMyoqisePH1OvXj0aNmwopBRBOHv2rLYZ04wZM3B0dBRYUUHc7Zw5c7C0tOTkyZPaPNKqgqa3TJU359P9PqraKu2VK1dYtGgR+fn5DBo0SFSxxPXq1WPatGkArFu3TjTPYPpAUx3/woULgm+piMKcVe1589atW3z66afk5OTQo0cPJkyYILSkF/D19WXAgAHk5+ezcOFCbt68KbQkveDo6IitrS2PHj3i1q1bgmoRzJyPHz8mPj4eMzMzWrZsKZQMvZOUlMTs2bPJyMigc+fOzJgxQ7Szhvfee4/XXnuNrKws5s6dy/3794WWpHNkMpl29BR6aiuYOaOiogBo1qxZlakRlJaWxuzZs0lLS6N169bMmzdP1Nk3crmc//znP7Rq1Yq0tDTmzp1bJVZw27RpAyB4VzbBzKnp2eHm5iaUBL2SmJjI9OnTSUxMpGnTpixcuLBEHcKExtTUlIULF9KoUSNu377NggULyM3NFVqWTtHkzgodyij4yOnu7i6UBL1x7do1pk2bRmJiIi4uLnz55ZdYWVkJLavEWFtb88UXX1CnTh0uX77MnDlzyMzMFFqWznB0dMTMzIz79+8LOlMQxJxKpVJbs6Wym/P06dPMmjWLR48e4eXlRWBgYJnrzgqJnZ0dAQEB1K5dm0uXLjFz5kwePnwotCydYGRkRJMmTYCC0fPJkydcvHiR3377Ta+jqewlm8w62YG+efMmkyZNwt7evlLHce7fv59Vq1ahUqnw9/dnxowZGBsbCy2rXNy7d4/Zs2dz9+5dHBwc+Oqrr7C3txdaVoWgVCpJSEggNjaWf/75h3v37vHgwQMePHigPebHH3/URfeBQlcEBfmkaJ43K+uomZ+fz5YtW7QlF4cPH87o0aNFuypbGuzt7Vm5ciVz5szh5s2bfPTRRwQEBOisWoO+CAsLY/HixcUW2q5Xr55e24IIMq3V7Jm5uroKcXudkpSUxPTp09m5cydyuZypU6cyZsyYSmFMDTVr1iQwMBAPDw8ePHjAjBkzRFuYuaR06tRJu4VSFJroIX0hiDnv3LkDgJOTkxC31xkhISFMmjSJ6OhobG1tWb58ubb0YmXDysqKJUuW4O3tzZMnT5g7dy4//PCDQeeCzpw5s9jMqCphzoSEBKDymDMrK4ulS5cSEBBAVlYWXbt2ZcOGDZW+qoOZmRkLFizQdu3aunWrdh/XEKlZsyazZs0q9D25XK7d/9QXejdnVlYWaWlpmJiY6D2hWBeEh4czefJkDh06hJmZGdOnT2f+/PlVpkiZkZER77zzDgEBAdSoUYMLFy4wefJkg80H7dChA2+++eYLrzdp0oRq1arpVYvezXn37l0A6tevL+romJeRmJjIZ599xpw5c7S5mGvXrqV3796V6vmypHh6erJ+/XptNNHHH3/M5s2bDTJg4b333nthgcvLy0vvOvRuTs2Utn79+vq+dYWQnZ3Npk2bGD9+PKGhoVhYWDB+/HjWrFlTJdPenqZ27dosXbqU4cOHo1Kp2LFjBxMmTDC4NvempqbMmTPnmbDSly0W6QLBzCmG3MXSoFKpCAkJYcyYMfz888/k5eXh7+/P999/z5AhQwwiFE8fGBkZMWbMGFatWoWzszNJSUnMnTuXRYsWkZqaKrS8EtO4cWPGjRsHIFhyht73OTXTWkMxp0KhICQkhN27d2tXmZs1a8YHH3xQafdpK4IWLVqwbt06fvvtN3788UdOnDhBeHg4o0ePpl+/fgYRjNG/f3/Cw8NRqVSCfPnqPELo+vXr7P3jD8KPHiXq6lWSk5NRqVR4tmuH7xtv8OZbb1V4k56KIDMzk3379rFnzx7t6qOdnR0jR46kR48eVb5vaGlITk5m7dq1nDp1CijYzB8+fDjdu3cXtUkvX77Mnl9/5VhQEOkPH6LIy8PG2hqPdu1o37Urb775JrVr166IWxW6SKEzc546dYoFM2YQGRnJIKWSjgoFLQArIBO4Apw2NWWXXE7r1q1ZuGKFtvqZkKSmpvLbb7+xb98+srKyAHB2dmbIkCG8+uqrov4wiZ1Tp06xceNG7ezJ3t6e4cOH4+/vL6rf64EDB/hi9mxu3bhB//x82ikUuAJmwGPgAnDKyoq/lUrefOMN/rt0aXkjpPRjzpycHObNmsWOzZtZkp3NUAr+UUWRC+wA5lhYMHzsWL5YvlznLQieJysri3/++YeQkJBnylO0bt2aIUOG0K5duyq5AqsLlEolR44cYdu2bdr1B3t7e4YNG4a/v7+gub2PHz9m2nvvcXzfPpZmZfEmUJyaVGCdkRFfm5nx+bJlTJw8uayfE92bMysri35+flhfvMh32dnUKcW5qcB4CwsyWrdmb0gIlpaWJTovPDycR48elbogdX5+PuHh4YSEhBAaGqpd8jc2Nsbb25vBgwfTvHnzUl1TouQolUqOHj3Ktm3btM/yNWrUwN/fn169euk9QCU5ORn/zp3pkJDAytxcrEtx7lVguKUlXUeM4OsNG8piUN2aU61W08/Pj5qhoXyfk0NZdjCVwBhzcx56e7M3JKTYf6RCoWDTpk389ttvdO/enY8//vil109PT+fChQtERETwzz//PNNVy8PDAz8/P7p27ar3zeaqjFKp5NixY/z888/P1Ozx8PCgV69e+Pj46LxcaHZ2Nl3atKHXrVt8npdXuFNewmOgh6UlPT74gMVLl5b2dN2ac/26dXz/8ceczMws1xJwPtDZyopx/04TCiMuLo4lS5Zo27U1adKE9evXv3Bcbm4uly9fJiIigvPnzxMTE/NMHdaGDRvi5+eHr68vdevWLYdqifKiVquJjo4mKCiIo0ePkpOTAxQkenfr1o1XXnmFVq1a6eTZ9D9TpxL33Xfsys4ukzE1pACtLSzYfegQXbp0Kc2pujNncnIy7s7OHM/KoiI2F64CPpaWXL11Czs7u2fe+/333/nf//73TGqPiYkJe/fuJSUlhZiYGG7cuEFUVBRXrlwhLy/vmeNatGhBmzZt6NixI02aNJGeJUVIZmYmR48eZf/+/Vy7dk37upWVFe3bt8fb21vbU7O8XLhwgZ6dO3MpO5uKCCbdA8x1dORKXFxpIuB0Z84ln3/OzS++4Lt/v+0KIxd4HwgG0oAmwBKgVxHHj7OwoOm8ecyeNw+Ahw8fsmzZsiKjTZydnV8oZSiTyXBxcaFt27Z4enrSokULvS82SZSPmJgYjh07RmhoKPHx8drX5XI5Hh4edOzYkRYtWuDi4lKmvcixQ4fiuns3nxRTozYNGAf8DdSh4HM7vJhrdrCxYcGOHfTp06ekMnRjTrVaTRN7e3YnJ1Nc9GEmsAwYDTQAgoBhwCWgUSHHhwOD7ey4ee8eZ86cYfny5Tx69KjI67u7u2uLZ7m4uNC0aVNat24tPT9WIhITEwkLCyM0NJTIyMhnij6bmJjQpEkT3N3dcXd3x83N7YVZ1/Okp6fToG5dbuTkFDtqDgNUwCYKtlH6AKeAFkUcvwXY060bew8fLuk/TTfmvHv3Lm1cXEjOySn1fL0VsAAYUMSN7czN+XDOHE6cOPHSaw0cOJD33ntPmqZWETIyMjhz5gznz58nOjqa+Pj4F/q61K5dm0aNGuHo6PjMj52dHXK5nJCQEP47YAAnnloYfJ5MoCZwGdCEyowE6gMBRZxzH2huYUFaZmZJP4+6KVMSERGBl6kpsmKmtIVxH7hO0d8+MsDT1BQLCwv69+9PREQEcXFxRV4vPj5eMmYVwtraGl9fX21PzYyMDKKjo4mKiuLq1atER0dr6/+cO3fumXNNTEyoX78+t2JjaZORUex9rlNgkqdj2FoDx4o5py5gJZMRGxurLRRWFsptzsTERBo8tehSEvKAEcAooLidRCeFApVKxbhx45g8eTJpaWlERERof54uvCR06XwJYbG2tqZdu3a0a9cOKEhUSExM5M6dOyQkJHD37l3tf6elpREXF8eta9fo85LKDRnA8w9G1YEnL9HTyMSExMREYc2pVqtLNZ1VUTAtMAW+ecmxeQoFW7Zs4fDhw9jZ2WmnJa6urvj5+SGTyYiLi+P8+fNERkaSnp4uPWNKAAULRg4ODpiammJmZoaZmRkmJiaYmZlhamqqbS3xss+uNfB85dp04GXrxDIodyOkcpvT1taWJBMTyM5+6bFqCla97lOwIPSyQK1EY2PtQ/29eyUiMVoAAB1iSURBVPe4d+/eC4WkzM3NcXV1pW/fvkRGRtKyZUuDrAsrUX7S0tK009qoqChu3Lih3S99HrlcjnXNmiQmJkIx6y7NKNh7vwE0/fe1ixT9OKbhvlJZ7qD4ci8I3bp1i64tW5Lwb5B4cUyiYLUrGEoUHlXf0pJ/Ll/G0dGRpKSkF6Ynd+/eLbRejYODA25ubri7u+Pl5WWwid0SRaNWq4mPj+fChQtaM967d++F42rWrImjoyP169fHyclJ+9/16tXj4MGDfPPOOxx8SVX3oRSMhN9R8PntTfGrtemAg6kpjzIzSxo0obutFIeaNTn6+DHFFbqMp2DLxIxnh+sNFDx/Pk808Fq1aiQ9elTsQs/Dhw+JiorSfmNev379hW/LBg0a4O3tTadOnXBzczPo8ihVmfz8fC5duqTdTnm+NbyFhQWurq7aL2Y3NzeqV69e5PXu379P84YNuZubS3GR3GnAWOAQUJuCVdri9jn/BJa3acOxkncp010Qwtz//Ifsr79mZTEFeUvLR6amWE2bxheljFNUKpXExsYSFRXFpUuXOHv27DN9PapXr06HDh3w9vamQ4cOgrd5lyierKwswsLCCAsL48yZMy/8Ldu1a0fLli1xc3OjUaNGpf7ifaNbN94+epSxFai5j7U1g9asYfTo0SU9RXfmjI+Px8vNjQvZ2VREfYM7QFsLC85FRZW7Lk9x37Y2Njb4+fnRu3dvnJ2dy6laoqJQq9VERUWxf//+Z+JsoeJnQX///TdT+/fnQmYmFRE7Fg70qVaNuHv3sLCwKOlpug18X/zZZ5wKDCQoK6tcwcNqoLelJV1mzeLThQvLcaVCrq1Wc/v2bUJDQzl+/Dg3btzQvte8eXN69epFt27dSvNLlahA0tPTCQ4OZv/+/c/sabds2ZJXXnmFTp06Vfj6gVqtZlCfPriEhBBQzplfLuBlZcW8jRsZNry4ie8L6NaceXl5vNK2LX7Xr/NFGdNu1MA8ExMOu7pyIiJC54m3MTExBAUFERISoq16YGFhga+vL0OGDNFrX4yqzK1bt9i5cyfHjx/XJirUqFGDHj160LNnT53ndiYnJ9O2eXNWPHzIkDJeQwmMMjcn19eXXfv2lTYgRvfJ1qmpqfh27MirCQksUyhKNU3IAT42NeWooyOHT5+mTp3SpGqXj5ycHI4fP05QUBBXrlwBCqrI+fv7M3z4cMmkOuLmzZts3bqVf/75ByhIVPDy8qJXr154e3vrtSpCZGQkr/v48Fl6OpNKuXefDow3N+dB69bsO3KkLDMv/ZQpSUtLY8KIEUSfOMHazExeLerOT93gGPC+pSVuPj78b9s2atWqVdrbVhjx8fHs3LmTkJAQVCoVcrlca1IHBwfBdFUmYmJi2Lp1KydPngQKwun69OnDgAEDBG0neO3aNYa/+Sa2d+6wJitLu69ZFCrgL2CKpSWvDxjA1xs3ljXrSX8FvtRqNbt27uSzmTMxT09nZEYG7YGW/H+Br8vAGeAna2tyq1VjUWAgg4cMEU18bEJCAtu3b3/GpN27d2fMmDF6HdUrE7dv32bTpk3aKnympqb06dOHwYMHi+Z3mpeXx7Ivv2Tl8uV4AUMyMmhHQZipMQVhexeAUJmMzZaWmNnZsXz9enr06FGe2+q3+h4UmDQkJITff/6Zc6dOcfXWLXLy8jA3MaFR3bq80r07bw8dqg3FEyN3795lx44dHDp0CJVKhaWlpbb2qrRfWjJyc3PZvn07u3btIj8/HzMzM/r27cugQYMqqrRkhZOdnc3u3bsJ2rWLs2fOEJeaikqtxsLEhFZNmtCuSxeGjRlD586dK+Kzq39zFseYMWPo3bs3gwYN0tUtKpTExEQ2bNig/dZv2rQp06ZNq5Q9RiuS06dP880332ijd3r16sXo0aMFfXQpDatWrSI9PZ358+ejVqt1Va9YPOZMTk5mxIgRmJiYsGbNmnJF7uubU6dO8c0335CSkoJMJqNv376MHTsWa+vS1Gur/KSkpPDtt99qc3GdnZ2ZNm0aLVq8LCpVPJw6dYoFCxZgY2PDL7/8ostC4oWaU5Cy5REREUDB/P7LL780qE5UnTt3ZtOmTQwePBiZTMaff/7JuHHjuHDhgtDSRENISAjjxo3jxIkTmJub895777Fu3TqDMuaDBw9YsWIFAE+ePHlmT1xfCGpOKFgk2LBhgxAyyoyFhQUTJkxg/fr1uLu7k5aWxieffMK2bdvKnSZkyCgUClatWkVAQADZ2dl4e3uzadMmBg0aJKqK7i9DrVazbNmyZ0qnPv2Z1Rd6N6dareb8cwHBf/75J2FhYfqWUm6cnZ1ZsWKFtuXdli1bmDdvXrG1jiord+/eZerUqfz111+YmJgwbdo0Fi5c+NI6PmJkz549L1RPqBLmjI2NLfTDGxgYyMOHD/Utp9xoWt59+eWXVKtWTdvp+vLly0JL0xvHjh3j/fff5+bNmzg4OPD111/Tt29f0a7AF8fNmzfZtGnTC69fuXJF749fejdnUd9Ajx49YtmyZS8UaTIU2rdvz7fffou7uzupqanMnDmTffv2CS1Lp6jVav73v//x+eefk5WVRdeuXVm3bh0uLi5CSysTubm5LFmy5Jlaxxry8vL0/oUrGnMCnD17lt9//12PaioWOzs7AgMDGThwICqVitWrV7Nt2zaD/cIpDqVSyfLly9m1axdGRkZ88MEHzJ8/HysrK6GllZmNGzc+Uxv3efQ9tdWrORUKxUu/fb777rtif0Fix9jYmIkTJzJt2jRkMhlbtmxhw4YNlWqhSKFQsGjRIv7++2/Mzc1ZvHgxb731lkFOYzWcPn2avXv3FnuMvs2p133OCxcu8J///Ef7/3K5nLp169KgQQNatGhB48aNady4Mba2FVEYX3iOHTtGQEAA+fn5+Pv7M3PmTIOPKsrMzOSzzz4jMjISGxsbPv/880rR4Ts/P587d+4QGxtLbGwsV69eJSEh4Zn1EZlMxu7du4utrlBGhA9COHbsGFFRUTg7O9O4cWPCw8PZvHkzb7zxBlOnTq3IW4mGs2fPsmjRInJycvD29mbevHkGW33h4cOHzJ07l5iYGGrVqkVAQEClTVKfNWsWFy9eZN68eVSvXl1r2t69e+tiv1Z4cz5PREQEn3zyCe7u7qxevVqXtxKUq1ev8umnn/LkyRO6dOnC/PnzDW4EzczMZMaMGcTGxuLg4EBAQEClTaVTqVS8/fbbZGVl8fPPP+sj/lc8EUIaNKt6sbGxKF9S3NeQcXd3JzAwEGtra06ePMnatWsNapEoLy+PRYsWERsbS/369Vm1alWlNSYUlGHNysqiZs2aggbmC2rOatWqUbduXXJycrTdjSsrzs7OLFq0CBMTE/7880927twptKQSoVarCQwMJCIigho1arBkyRJq1qwptCydognVE3pLSFBzAri5uQEFmeiVHQ8PD2bPno1MJmPTpk0cOnRIaEkvZfPmzYSEhGBubs4XX3xRqUdMDRcvXgT+/7MpFIKbs23btoAw4VFC4OPjw6RJk4CCqKjnw8TExN69e/n555+Ry+XMnz+fZs2avfykSoAmvNTT01NQHYKbU/MLuHjxYqV+7nya/v37M3DgQJRKJYsWLXqhOLIYuHjxImvXrgVg+vTpdOjQQWBF+iE5OZmEhAQsLS0Fz9UV3Jz29vbUq1ePjIwMYmJihJajNyZMmEDnzp3JysoiICBAVF9M6enpBAQEoFKpGDp0KD179hRakt7QjJqtWrUSPJNGcHPC/4+eVWVqCwUBGDNnzqROnTpcvXqVn376SWhJQMEC0IoVK0hNTcXd3b00VcsrBWKZ0oJIzFnVnjs1VKtWTbtAtH37du1ChJDs27ePkydPYmlpyZw5cwxuP7Y8PJ3OKJnzX9q0aQMIk5YjNK1bt2b48OGo1WoCAgJIf0nHK11y69Yt1q9fDxQ8ZwpZplII4uPjSUtLo1atWjRo0EBoOeIwZ/Xq1XFxcSEvL6/KjZ4AI0eO1KaarVixQpAABYVCwZdffolCoeD111/ntdde07sGoTl9+jRQMJMTQxC/KMwJBVsMAIcPHxZYif4xMjJizpw5WFpacvLkSUGqQvz666/ExcVRv359PvjgA73fXwxoPnuaz6LQiMacvr6+AISGhmr7llQl7O3tGTVqFADr169HUYHtFF9GSkoK27dvB2Dq1KlVspGTJrDdxsaG9u3bCy0HEJE569ati4eHB7m5udoy/VWNfv360bBhQxITE9mzZ4/e7vvdd9+Rk5PDK6+8IoqFECEICQkB4NVXX9Vrj5biEI05Afz8/AAIDg4WWIkwGBsbM3nyZAC2bdtGamqqzu95+fJlDh8+jKmpKRMnTtT5/cSISqXiyJEjwP9/BsWAqMzp4+ODiYkJFy5c4MGDB0LLEQQvLy+6dOlCTk4O3333nU7vpVQqtVFAgwcPrnKrsxouXbpESkoK9vb2oqqtKypz2tjY0KFDB1QqFUePHhVajmBMnDgRExMTQkJCtC0JdcGBAweIiYnB1taWIUPK2pnS8NHM1Hx9fUWxSqtBVOaE/59W7N+/v1LV3SkN9erV0/aQ+eGHH3Ryj7y8PLZu3QrAe++9V9bWdQZPZmYmx48fB/5/UVIsiM6cnTp1ok6dOsTHx3P27Fmh5QjGwIEDsbCw4Pz581y/fr3Crx8SEkJqaiqNGjUSzdaBEOzbt4+srCxatWpFw4YNhZbzDKIzp4mJCf379wcwmIRkXWBjY0OfPn0A2LVrV4VeW6VSsXv3bqDgWVOHDXpEjUKh0K6Ki3FaL8q/Sp8+fbC2tubSpUtcvXpVaDmC0b9/f4yNjTlx4gSJiYkVdt2wsDBu376Nra0t3bp1q7DrGhohISGkpaXRuHFj0extPo0ozWlpackbb7wBVPyoYUjY2tri6+uLSqXil19+qbDramYkAwYMEDwtSiienz2IaSFIgyjNCfD2229jYmLCqVOnuH37ttByBGPw4MEAHDx4sEJ6yVy+fJmrV69iY2ND7969y309Q+XUqVPcuXOHunXrijaOWLTmrFmzJj169ECtVlfp0bNhw4Z4e3ujUCj4448/yn09zWjRr1+/KhmmBwWpYZrZw8CBA0WbFidacwIMGjQIuVzOoUOHuHnzptByBEOzQBYcHFyu7aVHjx4RFhaGXC7nzTffrCh5Bsfx48eJjo6mevXqvP7660LLKRJRm7N+/fq8+eabqFQq1q1bZ1C1XiuSVq1aYWtry/3798sVlHD06FFUKhXt27ev9OUtiyInJ0fbrHnMmDGinj2I2pwA7777LtWrVycyMlK7WVzVkMvl2uAMTYB2WdCcK7bNdn2yc+dOUlJScHFxEX1tJNGb09ramjFjxgCwYcMGcnJyBFYkDBpzHjt2rEzpZAkJCURHR2NhYUHnzp0rWp5BcO/ePe36xQcffCDaZ00NojcnQM+ePXFxcSElJaXKBiY0atSIxo0bk5GRUabIKU3WxSuvvFJlQ/U2btyIQqHA19eXli1bCi3npRiEOTXNWaFg31OMdV71Qffu3YHST23VarU2uFtMKVH6JCIighMnTmBubs748eOFllMiDMKcAC1btsTX1xeFQiG6Oq/6olu3bshkMsLCwsjIyCjxedHR0SQmJlKrVi1tMbWqxJMnT1i+fDkAw4YNM5j+rwZjTih4TtDUedVkVFQl6tSpQ8uWLcnLy9OWcCwJmsJVXbt2Ff1zVkWjVqtZuXIlKSkpNG/eXBvUYQgYlDmrVavGJ598oq3zWhWaHz2Pl5cXQKnMqTlWc25VYv/+/Zw4cQJLS0vmzp1rUOGKBmVOKKhxO3ToUFQqleB1XoVAU4C7pObMzMwkOjoauVxOq1atdClNdMTHx7Nu3TqgoHCZoXVIMzhzQsHeZ/PmzUlJSWHlypVVKjjB1dUVS0tLEhISSE5OfunxkZGRqFQqmjdvjpWVlR4UigNNHd7c3Fz8/f0NciHMIM1pbGzM3LlzsbS05J9//qnQjA2xY2RkROvWrYGSjZ6aIt1VqaqeWq1mzZo1xMbG4uDgwJQpU4SWVCYM0pxQUMpj5syZQMH+VVWqOVSaqe2FCxeAqmXOrVu3cuDAAUxNTbVf4oaIwZoTCqr1TZgwAYClS5eKohGQPtAY7fz588VO6R88eEBcXBzm5uY0b95cX/IEZf/+/fz444/I5XLmzZsneI/N8mDQ5oSCzJW33nqLvLw8FixYwK1bt4SWpHMaNGhArVq1SEtLKzbXVfNl5eHhIZpCybrk9OnTrFq1CoApU6YYfJiiwZtTJpMxadIkXnnlFTIzM5k7dy4pKSlCy9IpMpkMNzc3AG7cuFHkcZrCYO7u7nrRJSTXrl3j888/R6VSMWzYMG0lDUPG4M0JBYsks2fPpkWLFqSmpvLJJ59UeoM2bdoUoNhu4Jr3NMdWVmJiYpg3bx45OTn4+/trEyUMnUphTgAzMzMWLVpEo0aNuHPnDtOnTychIUFoWTrDxcUF+P+RMy8vj/T0dNLS0oCCFUuNOTXHVkYiIyOZOXMmjx8/pn379syYMUOU9YDKguwle4QGt4GYnp7Op59+SlRUFDVq1GDJkiWV8sOZlJTE3LlzsbOzo2HDhty8eZPIyEiMjIzw8vLCycmJqKgocnNzWbt2baUM2zt16hRffPEFCoWCV199lY8//hhTU1OhZZWFQr9NKp05AbKzs1m4cCHnzp3D0tKSxYsXV4romF9++YXo6GhiY2O5e/duiUuWmJiY0LBhQ5ydnWnfvn2lKIf5999/ExgYiEqlok+fPnz44YeG/AVUqDkrzbT2aSwsLFi8eDGvvfYaWVlZzJkzp1K0FTQyMuLYsWPcuXOnVLWE8vLyiImJISQkhFq1aulQoe5Rq9Xs3r2bZcuWoVKpGDFiBNOmTTNkYxZJpRw5NSiVSr755hv27dsHwNChQxk9erRB/yHnzp1bZLK1sbEx+fn5RZ47ZMgQg8llLIysrCxWrlypDTiZPHmytviZgVN1prVPoymtuXnzZlQqFR4eHsydO5c6deoILa1MPHz4kPfee49Hjx698F6bNm24desWjx8/fuG9Zs2asXr1aoPKynia2NhYFi9eTEJCAhYWFsyYMUO09WbLQNWZ1j6NTCZjyJAhLF++nNq1a3Pp0iUmT57MuXPnhJZWJmrWrKkNW3weLy+vQpOpzc3NmTNnjkEaU61Ws3//fj788EMSEhJwdnZm7dq1lcmYRVLpzanBw8ODb7/9Fk9PTx49esScOXPYsmVLsdNAsdKpU6dCN9k9PT0LjaGdPHkyjo6O+pBWoWRlZbFs2TJWrFiBQqGgZ8+efP311zg5OQktTS9U+mnt8yiVSrZv385PP/2EWq2mUaNGTJs2zSAKPj1Nbm4u77//vjZ8r1q1auzevZuUlBTeeecd7XFdunThv//9r0Aqy4ZarebEiROsW7eOBw8eYGZmxtSpU+nRo4fQ0nRF1XzmLIoLFy6wcuVKbfeunj17MmHCBKpVqyawspITExPD1KlTycvLw8fHh/nz5wMwatQoEhMTqV27Nhs3bjSof1NSUhJr1qzRLno1b96cmTNn0qhRI2GF6Zaq+cxZFG3atGHjxo2MGDECY2NjDhw4wJgxYzhw4IDBJG+7uLhoQ9Wens56enoik8n4+OOPDcaYCoWCbdu2MX78eM6ePYuVlRVTp05l1apVld2YRVJlR86nuX37NmvWrNHmPrq7uzNq1Cjatm0r+lAwlUrFxIkTad++PSqVCplMxsOHD5HJZHzyySdCy3spSqWSEydO8OOPP3Lnzh2goHznxIkTq1LLCGlaWxxqtZrDhw+zfv167TZFixYtePfdd0Vp0tjYWNZ//TVbNm/GXKnE09iYunl5qIE4ExMiFApq1KjBxI8+Yuz48dSuXVtoyc+gVCo5duwY27Zt0z43Ozo68uGHH1apxPB/kcxZEjIzM/njjz/45ZdfePLkCVAwko4cORIvLy/BTZqbm8vnn33G+jVrGJ2fz8S8PAqLHFYDZ4BvLSwIMjLiq1WrGD12rOD6NabcunWrdqS0s7Nj2LBhvP7661Ui77QQJHOWhqysLK1JNRX+mjdvTr9+/fDx8cHMzEzvmu7du0fvV1/FKSGB9VlZlLSWXCQw2sqKxj4+bN2zR5B2DE+ePCEkJIS9e/dqTWlvb8+wYcPw9/evqqbUIJmzLGRlZbF37152796tNamVlRV+fn707t2bJk2a6EVHcnIyPu3aMSIpiU/z8wv/axaDAnjHwoKMDh34/e+/9ZK9oVariYyMZP/+/Rw/fpy8vDygwJTDhw/H39/fIAMjdIBkzvKQnZ3NkSNHCAoK4tq1a9rXXV1d6d27N6+++qrOSk+q1Wp6v/oqrcLC+OrfD3hZyAP6WVjgNWUKny9dWnECnyMtLY1Dhw6xf/9+7t69q33d09OT3r1706VLF8mUzyKZs6K4efMmQUFBhISEkJmZCRQEnbdq1Qpvb2+8vb2pW7duhd3v+02bWDNtGqczMynv5C8JaGNhQdCJExVWAV6tVhMfH09oaChhYWFERUVpt6Nq165Nz549ef311w2uqLMekcxZ0eTm5nL8+HEOHDjA5cuXn0njcnZ2xtvbm06dOuHq6opcXrYtZaVSiXPduvzy4AEdKkj3t8ABX1/+KEcj3ry8PC5dukRYWBihoaHcu3dP+56JiQnt2rWjV69edOjQwaCzgPSEZE5d8vjxY86cOUNoaCjh4eFkZ2dr37OysqJ58+a4ubnh7u5O8+bNsbGxKdF19+7dy5fvvEPYvyvHRfEOEAJkAvbAx0BRyWGZQANzcyKio2nYsGGJdKSlpREVFcXVq1eJiori+vXr5Obmat+vUaMGHTt2pFOnTnh5eYm6nbsIkcypLxQKBZGRkYSGhnL69Gnu37//wjENGjTA3d2dZs2a4eTkhKOjI7Vr135hq2Ps0KF47dzJBy+55xXABTADooHXgL+AoiauYy0s8Fq2TNv3VINSqSQ5OZmEhATu3LlDdHQ0UVFRz4yMGho1akSnTp3w9vbG1dVVGiHLjmROoUhJSXlm1Llx44Z25fJpzM3NqV+/Po6OjtqfD0eN4qfERNqV4n7XKDDnaqCohncbgAP+/kycMYOEhAQSEhK4e/cud+/eLVSbhYUFrq6uuLu74+7ujpubm8GEBhoAkjnFgkKh4ObNm0RFRREbG8udO3e4e/duoUnSR4KDeQKUZJL4PrAFyAbaAscB6yKOPQkMsrSkRSGFl2vXrq39cnBxccHd3Z2GDRtKI6PuKNSc0nq2AJiamuLm5qYtDK0hPT2du3fvakey27dvExIcXCJjAqwD1gChwFEKprhFYUnBCrOfn98zI7WDg4PB9hapbEgjp8gxNTbmsVJZYoNqmAS4A1OLeP8kMLN5c8KiosqlT6JCkFLGDBE3JyeulOG8fOBmMe9fBtz/bSUoIU4kc4qcdp06cfolxyQDPwMZgBI4COwAimsXe9rCAq+uXStGpIROkMwpct4aPpyfXrInKqMgsMARqAnMAlYB/Yo4PhP4Q62uFM1+KjPSM6fIUSqVNLa3Z1dqKh0r6JrfAgf9/Pg9OLiCrihRTqRnTkPEyMiIhV99xSQrK8oe8v7/JAELLCz4TIeB7xIVg2ROA2DUmDE4tGvHp+XMecwDxlhaMrFqVhswOKRprYGQkpKCj5cXw8uZz5nZsSO/HTxoqN24KivStNaQsbW15ciZM/zWuDFvWVqSVIpzLwIdraxQvfYav+7fLxnTQJDMaUDY29sTdukSraZMoZWFBbNMTSmq6bwaOA2MsrDA39qaqatXs/uvvwQpUSJRNqRprYESGxvLhjVr+H7TJsyerr4nkxFnbExEbi61atZk4vTpjBk3TnTV9ySeQQp8r4yo1Wpu3bpFREQEqampyOVy6tevj5eXF/b29kLLkygZkjklJESKtCAkIWFISOaUkBApkjklJESKZE4JCZEimVNCQqRI5pSQECmSOSUkRIpkTgkJkfKy6nvi6hgrIVGFkEZOCQmRIplTQkKkSOaUkBApkjklJESKZE4JCZEimVNCQqT8H52AICixeERnAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grafo com Laço\n",
        "grafo3 = Graph(edges = [(0,1),(1,2),(2,3),(3,0),(1,1)], directed = True)\n",
        "grafo3.vs['label'] = range(grafo3.vcount())\n",
        "plot(grafo3, target=plt.axes())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "H3vS01nCTqdS",
        "outputId": "06160fc1-2a3a-4563-84c7-b5bd174ad2aa"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa8e70ab2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAa+ElEQVR4nO3deXhU9b348ffJJENmEpayhE0M4BUNypawKKCGJNUf3AIW6wICgaLVW6R1Q5anC96LBsJtqxEKVooQQAWkgmAFzIQElTWkYAAtyHa17Mg+k23m/P4IoQmZNXMmc2bm83qe/MGc75z5QvLmnDnznYmiqipCCP2JCvYEhBDOSZxC6JTEKYROSZxC6JTEKYRORXvYLpdyhQg8xdmNcuQUQqckTiF0SuIUQqckTiF0SuIUQqckTiF0SuIUQqckTiF0ytMiBBECKisrOXjwIGfPnkVRFNq2bcttt91GVJT83xvKJM4QVVpayqpVq1j0xhvs2rePtkYjbQ0GVOD/Kiu5ZLczoE8fnn7xRX7yk58QHS3f6lCjeHiztSzf06EPP/yQSU89RQ+7nWevXmUQ0PSmMeeADcCfGzfmTHw8C997j9TU1Aafq/CK0+V7EmcIKSsrY8LIkRRt3Mi7Viv3enm/9cCzJhMjJ0xg9ptvyumu/kicoay8vJzhGRnEFxWRa7Nh8vH+PwAPm83cMWIEf8nNRVGc/jyI4JCF76Fs8qRJGIuKeL8eYQI0B/5utbL3b3/jjT/8QevpiQCQI2cIKCwsZNTgwZTYbDT3c1/fAveYTGzds4cuXbpoMT3hPzmtDVX9unbl5a+/5lGN9pcdFcXuwYNZsX69RnsUfpLT2lBUVFTE6ePHGeFmzFygN9AIGOfFPp9xONiUl8epU6e0mKIIEIlT51YsW8a40lIMbsa0A34D/NzLfTYFhkdFsXr1ar/nJwJH4tS5XYWF9Hc43I4ZATwMtPBhv/fabBQVFvozNRFgEqfOlRw8SI8A7Lcn8FVxcQD2LLQicerclbKyOqt/tNAUuGq1BmDPQisSp84ZDQbKArDfciBG1tvqmsSpc//Rvj3/DMB+vwFuv/32AOxZaEX+69S5lH79KDp6lL5uxlRe/7Jf/yql6hvr7pu7Q1E4Y7Xy/PPPEx8fT1JSEqmpqbRv3167yQu/yCIEnVu1ahXzfv5zCq5edTlmBvDqTbf9/vrtztiBW6Ki6JCSQtOmtZ/RDhw4kHHjxpGYmFjvOQufyQqhUFReXk5iQgKfXbrE3Rrtcz0w5ZZbeG/9ehRF4cKFC2zbto0tW7ZQUVFBbGwsv/3tb+nb193xWmhI4gxVf5ozh7Wvvkr+tWt+XySwAT3NZmYtW8ZPf/rTWtvOnz/PggULKCgowGAw8Prrr5OcnOznIwovSJyhym63c19yMo+UlPCSn7+J/FdGI2ceeogPPv7Y6XZVVZk/fz4fffQRZrOZd955h4SEBL8eU3gka2tDlcFg4LkpU/hvg4HF9dyHCsyMjmZTQgLz3n3X5ThFUXj22We55557sFqtfPDBB/V8ROEviTMEFBQUsGTJEu7q04cp8fE8bzTiy/KB88Bok4kVHTrw0IgRZGdn89lnn2Gz2ZyOj4qK4qmnngJg48aNWGWxQlBInDpXUFBAVlYWDoeDX/ziF+w/epSzQ4bQPS6OtwHX13CroswGuplMtMrMZMe+fQwdOpTi4mKys7N57LHHeP3119mxYwd2u73WfRMTE+nWrRvl5eVs27YtgH9D4Yq8zqljNcMcPXo0Y8eORVEUln/0Efn5+cydNYupW7aQ0qgRKVYrbSsrqz59LyaG7TEx7C0tpWf37qxbuJCUlBQABgwYQGxsLKWlpZSWlrJ582Y2b95Ms2bNSE1NJSMjgzvuuAOA5ORkSkpKOHbsWPD+ESKYxKlTrsKslpaWRlpaGmfPnmXXrl0UFxVx7ORJlKgo2nTowP0XLtBoxw7GjRt3I0wAk8nEgAEDsFgstR7v4sWLrFmzhjVr1tChQwfS0tJubHN4eFeMCAyJU4c8hVlTq1atGDJkCEOGDKl1+/vvv09xcTEVFRV17pOenl4nzpq+++47Lly4QLt27YCq11pFw5PnnDrjS5juVK/8+de//lVnW3JyMs2bu/40omHDhjFp0qQb923WrJnPjy/8J3HqiFZhAvTu3Ruo+piTa9eu1dpmMBhcfsD0Qw89xKRJk6isrOSLL74AoE+fPvWag/CPxKkTWoYJkJCQQM+ePSkrK2Pt2rV1tqenp9e5rVu3bmzZsoV9+/aRl5fHhQsXuPXWW+XdK0EicerA5s2bNQ2z2siRI4Gq55///GftN5516dKFW2+99cafhw0bRuvWrbHZbEyZMoUFCxYAMGrUKPkA6iCROINs8+bNzJo1S/MwAXr16sWDDz5IaWkp06dP58CBA7W2V1+RrX6O+fLLL9OvXz/Ky8u5du0aXbt2ld+vEkSGGTNmuNvudqPwTyDDhKqleH379uXw4cMcPnwYi8XCxYsX6dChA40bNyYhIQFVVXnuuec4d+4cK1asoLCwkMrKSgAuX75Mz549ZW1t4N38jj9AFr4HTaDDrMlutzNv3jzWrVt347bOnTvTsmVLFEXhhx9+4Ntvv6X6Z+GBBx5AURQKCgqIjY0lKyuLu+/W6g1rwgl5V4pe1AxzzJgxjB07tkEe9+jRo6xcuZIvv/yyzrpao9FIv379ePTRR0lKSsJutzNnzhwsFosEGngSpx4EK8yaysrKOHToEFeuXEFVVRo3bsxtt92G2WyuNU4CbTASZ7DpIUxfSaANQt7PGUyhGCZULViYPHky6enplJaWMm3aNPbt2xfsaUUEibMBhGqY1W4OdPr06RJoA5A4Ayw/Pz+kw6xWM1CbzSaBNgCJM4Dy8/OZPXt2yIdZTQJtWBJngIRbmNWqA01LS5NAA0ziDIBwDbOawWDglVdekUADTOLUWLiHWU0CDTyJU0OREmY1CTSwJE6NRFqY1STQwJE4NRCpYVaTQAND4vRTpIdZTQLVnsTpBwmzNglUWxJnPUmYzkmg2pE460HCdE8C1YbE6SMJ0zsSqP8kTh9ImL6RQP0jcXpJwqwfCbT+JE4vSJj+kUDrR+L0oGaYY8eOlTDrSQL1ncTpxs1hjhkzJthTCmnOAt2/f3+wp6VbEqcLFotFwgyAmwOdNm2aBOqCxOmExWIhOztbwgwQCdQ7EudNJMyGIYF6JnHWIGE2rOpABw0aJIE6IXFeJ2EGh8FgYMqUKRKoExInEmawSaDORXycEqY+SKB1RXScEqa+SKC1RWycEqY+3RxoJC9UiMg48/LyJEwdqxmo1WqN2EAjLs68vDzmzJkjYeqcBBphcUqYoSXSA42YOCXM0BTJgUZEnBJmaIvUQMM+TgkzPFQHmpqaGjGBhnWcEmZ4MRgMTJ06NWICDds4Jczw5CzQAwcOBHtaARGWcUqY4e3mQKdNmxaWgYZdnDXDzMzMlDDDVCQEGlZx1lz5k5mZyejRo4M9JRFA4R5o2MRZHaaqqhJmBAnnQMMiTgkzsoVroCEfp4QpIDwDDek4JUxRU7gFqvs4r1275vR2CVM4E06B6j7OnJwc1qxZU+s2CVO4Ey6B6jpOm83G1q1bmTdv3o1AJUzhjXAIVFFV1d12txsDbdOmTcyZM+fGn3/2s5+xevVqCVN4zW63M2vWLAoKCjCbzWRlZdG1a9dgT+tmitMb9RznlClTKC4urnVbt27dSE5OljCF10IgUKdx6va09vz58+zZs6fO7SUlJcTHxwdhRiJUheoprm7jzM/Px+FwON1W8zmoEN4IxUB1G6fFYnG7fd68eXz88ccNNBsRDkIt0IA/5zx48CAfr11LUUEBXx84gK20FFNsLEldu5LywAMMf/hhunTpUus+x44d4+mnn3a5z6SkJNLT00lNTaVp06b+TlFEGG+fg+7bt48Nn37K7sJCvj14kPKKChrHx9Otd2/63Hcfw4cPp0WLFlpMqWEvCG3dupXfv/giX331FY/a7fQrL+cuIA64BuwHdhiNrIyKokePHrz6xz/Sv39/ABYuXMiKFStq7a9du3ZkZGSQlpZG+/bt6zstIQD3gW7YsIHXpk7l6KFDjKispHd5OXcAjYBLwB5ga1wcm+x2hg8dyozsbDp27OjPdJzGiaqq7r58ZrPZ1BcnTlTbmkzqYlBLQVXdfJWC+i6obUwm9cWJE1Wr1aqOHDlSzcjIUB955BE1JydH3b9/f32mIoRblZWV6syZM9WMjAx12LBh6vbt29XMxx5TO5nN6ipQyz387J4F9VWDQW1hNqvz581THQ5HfafitD9Nj5xWq5Vh6enE793LQpuNlj7c9xzwlMnE2S5dyBg+nMGDB9OnTx8MBoMvUxDCJ3a7naysLD777DO+LipiaEUFb1ZU4MvrAQeAUWYz9z35JDlvv42iOD8QuhHY01pVVRmWns6Ptm3j3dJS6pOUHRgfG8uFe+/lY4ulPn9JIXx29epV7urYkcd/+IHZquriHNO9S8CDZjMPTpzI/2Rn+3r3wL7O+fb8+ZzZuZNF9QwTwAAsKi3l9M6d/GXBAq2mJoRbr06fTl+rtd5hAjQF1lut/HXuXL788ktN5qXJkfPMmTN07dSJLVYrWqy7OADcbzZz4OhREhISNNijEM7t2bOH/9e/PyU2G6002N/fgOm33ML+Y8d8eUoWuCPnX//yFx52ONyGWQZMABKBxkBP4FMXY7sCw1WVRe+8o8X0hHApZ9YsXigrcxvmD8BPqXqlIRF4z83YEUCTS5fYsGGD/5NzdaVI9fJqrcPhUDslJKhFHq5sXQX196AeBdUO6jpQ46//2dn4XaB2Skjw5wqYEG5dunRJbRobq57x8LP7BKiPgXoF1M9BbQLqPjfj3wV16KBBvkzFaX9+HzlPnDjBlcuXSfYwLg6YAXSk6nD9E6ATsNvF+BTgyuXLnDhxwt8pCuHUrl276Naokduj5jVgNfA/QDwwEBgGLHVzn8HA59u3o7p/yuiR33EWFxeTYjT6/ET6NHAQuMvFdgVIMRrZvdtVvkL4Z3dRESk2m9sxB4FooOYath5ULaJxpTUQpygcOXLEr/lpcuS8taLCp/tUAE8CmcCdbsbdWlnJqVOn/JidEK6dOHaMxPJyt2OuAk1uuq0pcMXDvjvGxPh91ud3nKqPl58dwBjACMz1MFa5vn8hAsGbn9144PJNt12m6qKmOwq4fFeVt/yOs1WrVpyMifFqrErVFdvTVJ3He7rXyehoWrb0ZZ2REN5r0aYNpz283NEFqAQO1bhtL66fjlU7bbf7vSje7ziTk5Mprqz0aux/AV8D6wCTF+N3V1aSnOzpUpMQ9dMrJYXiuDi3Y+Koennkd1RdHPoSWEvV2Z8rl4ET5eXceae7J22e+R1nx44dscfE8E8P444Db1O1or8NVacL8cByF+O/AezR0f6u9hfCpb59+7KzrAyrh3F/BmxAAjASmI/7I2chkNK1K9HR0X7Nz+84FUVh/NNPs8BodDsukarT2lKqnmRXfz3pYvwCo5EJzzwj62tFwLRu3ZqB997LBx7GNQfWUHXk/D9glIfxC+LjGf/rX/s9P02W7x0/fpyUpCT22Gzc4veU4Dugl8nE7q+/JjExUYM9CuHcpk2b+NWIEey5do1YDfZXBPxnkyYcO3UKk8mbJ29AIJfvJSYm8uuXX+Zps9nvj05QgV+YzTw/ebKEKQLuxz/+MXfffz8zPJz5eaMMGBcXxxvz5/sSpkuavWWsoqKCgb16kX7wIK9VVNRrdb8KvKIofJqYyD8OHiTGy6vAQvjjzJkz9LrzTv544QKP13MfdiAzNpaytDRWrl/v69OxwL5lLCYmhk8KCljfoQO/Mhop9fH+pcBz0dEsjo2lZWIihYWFWk1NCLcuXrzI+F/+kl83acJ8RfH57O8yMDI2lpM9epD74YeaXSfR9NP3WrZsScGuXZxISyMlLo4CPB96VaAASDabOZWRwcw//YmYmBiys7PJy8vTcnpC3HD69GmWL1/OhAkTmDhxIpcuXaJw504WdunCYLO51uuarjioelmwm9lMs0cf5ZOCAk1OZ6v5d63XiebNm/Ph3//OyhUreOall4i9fJkxV6/SB7ibf3/A1z5gJ7A0Pp6yJk347z/8gccefxxFUYiLi2PJkiU3fhVDRkaG1tMUEejKlSsUFhZisVjYv39/rdVn6enp3HHHHWwvKWHO66/T/3//lxTg8atX6U3VMtNoqpbt7QG2KQqLzGYaJSTwzoIFPPjgg5rPN6AfjamqKhaLhTUffMDurVs5cPQopRUVxMbE0LVTJ1L69+fhJ54gPT29zqnAsmXLWLJkCVFRUUyePFkCFfVSUVHB9u3bsVgs7Ny5kwon68ANBgMrVqyo9TGrNpuNVatWsXH1anYXFXHo5EkcqoopJobut91G7wEDGDl+PP3799fiNDb0fleKBCr8lZWVRX5+vtsx/fr1Y+bMmW7H3HiPZVRAPoc9tH5XCsDo0aPJzMzE4XAwZ84ceQ4qfPbSSy/Rp08ft2PS09M97kdRlECF6ZKu4wQJVPjHaDQyY8YMl4GazeYbH2auN7qPEyRQ4R+j0UhSUhK33357nW0DBw6kUaNGQZiVZyERJ0igov6WLl1Kbm4ux48fp2fPnrW2eXNKGywhEydIoMJ31WFGRUXxwgsv8Nprr904xW3ZsmWdWPXEMGPGDHfb3W4Mhu7duxMVFcWePXvYtm0bbdu2pXPnzsGeltChmmFWX+03GAzcd999HDp0iF69etG7d+9gTxPgVWc36vqlFHdq/sO/8soruj49EQ3PWZg1lZeXc/nyZb180kbovc7piQQqnPEUpg45jVPz5XsNacyYqg+LyM3NJfv6L4+RQCNbCIbpUkjHCRKo+LdwChPCIE6QQEX4hQlhEidIoJEsHMOEMIoTJNBIFM4XBcMqTpBAI0k4hwlhGCdIoJEg3MOEMI0TJNBwFglhQhjHCRJoOIqUMCHM44S6gSqKQlpaWpBnJeojksKECIgTagc6e/ZsAAk0xERamBAhcYIEGsoiMUyIoDhBAg1FkRomRFicIIGGkpphTpkyJeK+TxEXJ0igoSA3N5elS5dGbJgQoXGCBKpnEmaViI0TqgJVVZWlS5dKoDohYf5bRMcJMHbsWAAJVAckzNoiPk6QQPVAwqxL4rxOAg0eCdM5ibMGCbThSZiuSZw3kUAbjoTpnsTphAQaeBKmZxKnCxJo4EiY3pE43ZBAtSdhek/i9EAC1Y6E6RuJ0wsSqP8kTN9JnF6SQOtPwqwfidMHEqjvJMz6kzh9JIF6T8L0j8RZDzcHqigKgwYNCvKs9EXC9J/EWU81A501axaABHqdhKkNidMPEmhdNcOcOnVqxP97+EPi9NPYsWNRVZVly5ZFfKASprYkTg1UH0EjOVAJU3sSpwYURYnYQFVVJTc3l2XLlkmYGpM4NRKJgUqYgSVxaiiSApUwA0/i1FgkBCphNgyJMwDCOVAJs+FInAHiLFBFUUhNTQ3uxPwgYTYsiTOAbg40KysLICQDvTnMadOmheTfI5RInAFWHaiqqixfvjwkA5Uwg0PibACKopCZmQkQcoFKmMEjcTaQUAxUwgwuibMBhVKgqqqyZMkSli9fLmEGicTZwEIhUAlTH6KCPYFIVB3ok08+icPhICsri4KCgjrjli9fjsPhaNC5SZj6IXEGiadAc3JyWLx4MXv37m2wOUmY+iKntUHk6hT3q6++Yt26dQBYLBZ69eoV8LlImPqjqKrqbrvbjUIbNcPo1q0bJSUlN7aZzWZWrlxJo0aNGuTxJcygUJzdKKe1OlB9BB04cGCtMAGsVivbtm0L2GNLmPolcerEW2+9xRdffOF0m8ViCchjSpj6JnHqQE5Ozo3nmM4UFRVx6dIlTR9TwtQ/uSAUZCdPnuTMmTMYDAbsdrvTMZWVlRQUFDB8+PA621RV5fDhw/zjH//g/PnzKIpCu3btSElJoV27dk73J2GGBrkgpBMXL16koKAAi8XCN998U2d7UlISOTk5N/585MgRFuTksHjRImIdDpINBlpXVKACx2Ni2F1eTrNmzXjm+ef5+VNP0aJFC0DC1CmnF4QkTh36/vvvsVgs5Ofnc+LEiRu3L1myhBYtWjDzd79jwVtvMa6ykmcqKvgPJ/tQgZ3AfJOJvxsMzH7jDTLHjyc3N1fC1B+JMxQdOHCAvLw8CgsLSU1N5d25c+nw/fcssFpp6+U+vgLGxcVh7NwZc8uWxMTESJj6InGGshMnTnB/SgqZ587xm8pK599NN8qBR6Oi2N20KYtXriQjIyMQ0xT1I69zhipVVZnwxBM8cv48v61HmABG4EOHg65WKwWbNmk9RREAEmcIWLxoEaeLi5lZUeHXfmKAJWVlvDN3Lrt379ZmciJg5LRW5+x2O51at+bD8+fpq9E+5wMb0tJYG6DFDcJnclobij755BPalZd7DHM00BZoAnQBFroZOxb4YutWjh8/rtEsRSBInDq35r33GHPlisdx04BjwGXgY+A3gKsT1zhguKKwfv16jWYpAkHi1LndO3bQz4txdwHV71tRrn8ddjO+n83G7s8/93d6IoAkTp37+rvvuMvLsb8EzMCdVJ3iDnEz9m7gQAO+kVv4TuLUMbvdTqXdjsnL8X8GrgCfAyP495HUGTNQWlrq5wxFIEmcOmYwGIg2GLD5ch9gIPA9VVdlXbECsbGx/kxPBJjEqXNJHTqwvx73q8T9c859QNcePeo3KdEgJE6d633PPezwMOYM8AFwFbADG4H3gXQ399lhMpFy333aTFIEhMSpcw+PGsXSxo3djlGoOoW9BfgR8DLwBjDMxfhrwFpVZejQoRrOVGhNVgjpnN1up3ObNqw8d86rl1S8MR/YmJ7Omrw8jfYo/CQrhEKRwWDg1dmzeTYuDv9W1lY5CfzeZOJ32dka7E0EksQZAjLHj6dd7978JibGr/1UAOPNZp6ZNInk5GRtJicCRk5rQ8TZs2e5PyWFUSdP1vv9nKNNJq7168dHGzdiNBoDMU1RP3JaG8patWrF5p07+ahzZx42mznpw333Av3i4nCkprL6008lzBAhcYaQNm3asL2khO7PPUd3k4mXjUYOuRirAjuATJOJH8fH86s332TVJ5/IwoMQIqe1IerIkSO8/dZbvPvXv9LIbic5Orrq0/cUhWPR0RSXldH8Rz/imRdeYPyECTc+fU/oknyGUDhSVZWjR49SXFzMuXPniIqKon379qSkpNCmTZtgT094R+IUQqfkgpAQoUTiFEKnJE4hdEriFEKnJE4hdEriFEKnJE4hdEriFEKnPP1m6/r8zhwhhAbkyCmETkmcQuiUxCmETkmcQuiUxCmETkmcQujU/weQ0lSAJMR3CgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação do quarto grafo\n",
        "grafo4 = Graph(edges = [(0,1),(1,2),(2,3),(3,0),(1,1)], directed = True)\n",
        "# adicionamos vertice isolado\n",
        "grafo4.add_vertex(5)\n",
        "grafo4.vs['label'] = range(grafo4.vcount())\n",
        "plot(grafo4,target=plt.axes())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "WkRKECSoT4ni",
        "outputId": "a942bdfc-4b61-4561-ec61-a3e8be404f48"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa8e6f56ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}